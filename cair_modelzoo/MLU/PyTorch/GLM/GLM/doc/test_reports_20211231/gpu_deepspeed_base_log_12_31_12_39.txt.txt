Warning: Permanently added '10.0.2.18' (ECDSA) to the list of known hosts.
[2021-12-31 12:39:27,112] [INFO] [runner.py:291:main] Using IP address of 10.0.2.18 for node 10.0.2.18
[2021-12-31 12:39:27,114] [INFO] [multinode_runner.py:51:get_cmd] Running on the following workers: 10.0.2.18,10.0.2.17
[2021-12-31 12:39:27,114] [INFO] [runner.py:360:main] cmd = pdsh -f 1024 -w 10.0.2.18,10.0.2.17 export NCCL_VERSION=2.8.4; export NCCL_SOCKET_IFNAME=eth0; export NCCL_DEBUG=info; export OMPI_MCA_pml=^ucx; export PYTHONIOENCODING=utf-8; export OMPI_MCA_btl_tcl_if_include=eth0; export LD_LIBRARY_PATH=/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64; export NCCL_IB_DISABLE=1; export PATH=/opt/conda/bin:/usr/local/nvm/versions/node/v15.2.1/bin:/opt/conda/bin:/opt/conda/bin:/opt/cmake-3.14.6-Linux-x86_64/bin/:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin; export PYTHONPATH=/home/kongxiyu/GLM2;  cd /home/kongxiyu/GLM2; /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyIxMC4wLjIuMTgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICIxMC4wLjIuMTciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --node_rank=%n --master_addr=10.0.2.18 --master_port=10738 pretrain_glm.py --block-lm --bert-prob '1.0' --experiment-name 'blocklm-blank' --model-parallel-size '1' --num-layers '12' --hidden-size '768' --num-attention-heads '12' --seq-length '512' --max-position-embeddings '512' --train-iters '9375' --resume-dataloader --train-data 'bert-base' --tokenizer-type 'BertWordPieceTokenizer' --tokenizer-model-type 'bert-base-uncased' --split '949,50,1' --save '/home/kongxiyu/GLM2' --distributed-backend 'nccl' --lr-decay-style 'cosine' --lr-decay-iters '120000' --lr-decay-ratio '0.05' --warmup '.05' --log-interval '1' --eval-interval '1000' --eval-iters '100' --fp16
10.0.2.18: Warning: Permanently added '10.0.2.18' (ECDSA) to the list of known hosts.
10.0.2.17: Warning: Permanently added '10.0.2.17' (ECDSA) to the list of known hosts.
10.0.2.18: [2021-12-31 12:39:28,041] [INFO] [launch.py:73:main] 0 NCCL_VERSION 2.8.4
10.0.2.18: [2021-12-31 12:39:28,041] [INFO] [launch.py:73:main] 0 NCCL_SOCKET_IFNAME eth0
10.0.2.18: [2021-12-31 12:39:28,041] [INFO] [launch.py:73:main] 0 NCCL_DEBUG info
10.0.2.18: [2021-12-31 12:39:28,041] [INFO] [launch.py:73:main] 0 NCCL_IB_DISABLE 1
10.0.2.18: [2021-12-31 12:39:28,041] [INFO] [launch.py:80:main] WORLD INFO DICT: {'10.0.2.18': [0, 1, 2, 3, 4, 5, 6, 7], '10.0.2.17': [0, 1, 2, 3, 4, 5, 6, 7]}
10.0.2.18: [2021-12-31 12:39:28,041] [INFO] [launch.py:86:main] nnodes=2, num_local_procs=8, node_rank=0
10.0.2.18: [2021-12-31 12:39:28,041] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'10.0.2.18': [0, 1, 2, 3, 4, 5, 6, 7], '10.0.2.17': [8, 9, 10, 11, 12, 13, 14, 15]})
10.0.2.18: [2021-12-31 12:39:28,041] [INFO] [launch.py:102:main] dist_world_size=16
10.0.2.18: [2021-12-31 12:39:28,041] [INFO] [launch.py:106:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
10.0.2.17: [2021-12-31 12:39:28,203] [INFO] [launch.py:73:main] 1 NCCL_VERSION 2.8.4
10.0.2.17: [2021-12-31 12:39:28,203] [INFO] [launch.py:73:main] 1 NCCL_SOCKET_IFNAME eth0
10.0.2.17: [2021-12-31 12:39:28,203] [INFO] [launch.py:73:main] 1 NCCL_DEBUG info
10.0.2.17: [2021-12-31 12:39:28,203] [INFO] [launch.py:73:main] 1 NCCL_IB_DISABLE 1
10.0.2.17: [2021-12-31 12:39:28,203] [INFO] [launch.py:80:main] WORLD INFO DICT: {'10.0.2.18': [0, 1, 2, 3, 4, 5, 6, 7], '10.0.2.17': [0, 1, 2, 3, 4, 5, 6, 7]}
10.0.2.17: [2021-12-31 12:39:28,203] [INFO] [launch.py:86:main] nnodes=2, num_local_procs=8, node_rank=1
10.0.2.17: [2021-12-31 12:39:28,203] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'10.0.2.18': [0, 1, 2, 3, 4, 5, 6, 7], '10.0.2.17': [8, 9, 10, 11, 12, 13, 14, 15]})
10.0.2.17: [2021-12-31 12:39:28,203] [INFO] [launch.py:102:main] dist_world_size=16
10.0.2.17: [2021-12-31 12:39:28,204] [INFO] [launch.py:106:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
10.0.2.18: torch.cuda.device_count() 8
10.0.2.18: torch.cuda.device_count() 8
10.0.2.18: torch.cuda.device_count() 8
10.0.2.18: torch.cuda.device_count() 8
10.0.2.18: using world size: 16 and model-parallel size: 1 
10.0.2.18:  > using dynamic loss scaling
10.0.2.18: torch.cuda.device_count() 8
10.0.2.18: torch.cuda.device_count() 8
10.0.2.18: torch.cuda.device_count() 8
10.0.2.18: torch.cuda.device_count() 8
10.0.2.17: torch.cuda.device_count() 8
10.0.2.17: torch.cuda.device_count() 8
10.0.2.17: torch.cuda.device_count() 8
10.0.2.17: torch.cuda.device_count() 8
10.0.2.17: torch.cuda.device_count() 8
10.0.2.17: torch.cuda.device_count() 8
10.0.2.17: torch.cuda.device_count() 8
10.0.2.17: torch.cuda.device_count() 8
10.0.2.18: > initializing model parallel with size 1
10.0.2.18: > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
10.0.2.18: loading BertWordPieceTokenizer ( bert-base-uncased ) from cache_dir  None
10.0.2.18: loaded bert-base-uncased
10.0.2.18: > padded vocab (size: 30524) with 68 dummy tokens (new size: 30592)
10.0.2.18: > found end-of-document token: 0
10.0.2.18: d3cbd79f2fa3:1498:1498 [3] NCCL INFO Bootstrap : Using eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1498:1498 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.18: d3cbd79f2fa3:1498:1498 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.18: d3cbd79f2fa3:1498:1498 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1498:1498 [3] NCCL INFO Using network Socket
10.0.2.18: NCCL version 2.8.4+cuda11.2
10.0.2.18: d3cbd79f2fa3:1499:1499 [4] NCCL INFO Bootstrap : Using eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1499:1499 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.18: d3cbd79f2fa3:1499:1499 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.18: d3cbd79f2fa3:1499:1499 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1499:1499 [4] NCCL INFO Using network Socket
10.0.2.18: NCCL version 2.8.4+cuda11.2
10.0.2.18: d3cbd79f2fa3:1501:1501 [6] NCCL INFO Bootstrap : Using eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1501:1501 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.18: d3cbd79f2fa3:1501:1501 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.18: d3cbd79f2fa3:1501:1501 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1501:1501 [6] NCCL INFO Using network Socket
10.0.2.18: NCCL version 2.8.4+cuda11.2
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 00/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 01/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 02/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 03/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 04/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 05/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 06/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1496 [1] NCCL INFO Bootstrap : Using eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 07/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 08/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 09/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 10/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 11/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 12/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 13/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 14/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 15/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 16/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 17/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 18/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 19/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 20/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 21/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 22/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 23/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 24/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 25/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 26/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 27/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 28/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 29/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1500 [5] NCCL INFO Bootstrap : Using eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 30/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Channel 31/32 :    0
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1496:1496 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.18: d3cbd79f2fa3:1500:1500 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.18: d3cbd79f2fa3:1496:1496 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.18: d3cbd79f2fa3:1500:1500 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.18: d3cbd79f2fa3:1496:1496 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1500:1500 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1496:1496 [1] NCCL INFO Using network Socket
10.0.2.18: d3cbd79f2fa3:1500:1500 [5] NCCL INFO Using network Socket
10.0.2.18: NCCL version 2.8.4+cuda11.2
10.0.2.18: NCCL version 2.8.4+cuda11.2
10.0.2.18: d3cbd79f2fa3:1497:1497 [2] NCCL INFO Bootstrap : Using eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1497:1497 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.18: d3cbd79f2fa3:1497:1497 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.18: d3cbd79f2fa3:1497:1497 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1497:1497 [2] NCCL INFO Using network Socket
10.0.2.18: NCCL version 2.8.4+cuda11.2
10.0.2.17: f738527b48a8:893:893 [7] NCCL INFO Bootstrap : Using eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:893:893 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.17: f738527b48a8:893:893 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.17: f738527b48a8:893:893 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:893:893 [7] NCCL INFO Using network Socket
10.0.2.17: NCCL version 2.8.4+cuda11.2
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 00/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 01/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 02/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 03/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 04/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 05/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 06/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 07/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 08/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 09/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 10/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 11/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 12/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 13/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 14/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 15/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 16/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 17/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 18/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 19/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 20/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 21/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 22/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 23/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 24/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 25/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 26/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 27/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 28/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 29/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 30/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Channel 31/32 :    0
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Setting affinity for GPU 4 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1495:1495 [0] NCCL INFO Bootstrap : Using eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1495:1495 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.18: d3cbd79f2fa3:1495:1495 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.18: d3cbd79f2fa3:1495:1495 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1495:1495 [0] NCCL INFO Using network Socket
10.0.2.18: NCCL version 2.8.4+cuda11.2
10.0.2.18: d3cbd79f2fa3:1502:1502 [7] NCCL INFO Bootstrap : Using eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1502:1502 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.18: d3cbd79f2fa3:1502:1502 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.18: d3cbd79f2fa3:1502:1502 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.18<0>
10.0.2.18: d3cbd79f2fa3:1502:1502 [7] NCCL INFO Using network Socket
10.0.2.18: NCCL version 2.8.4+cuda11.2
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 00/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 01/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 02/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 03/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 04/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 05/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 06/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 07/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 08/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 09/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 10/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 11/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 12/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 13/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 14/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 15/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 16/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 17/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 18/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 19/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 20/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 21/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 22/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 23/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 24/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 25/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 26/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 27/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 28/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 29/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 30/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Channel 31/32 :    0
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Setting affinity for GPU 6 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1498:1555 [3] NCCL INFO comm 0x7f5b5c008e10 rank 0 nranks 1 cudaDev 3 busId 1e000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1499:1559 [4] NCCL INFO comm 0x7ff03c008e10 rank 0 nranks 1 cudaDev 4 busId 3d000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1501:1563 [6] NCCL INFO comm 0x7fcbb0008e10 rank 0 nranks 1 cudaDev 6 busId 40000 - Init COMPLETE
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 00/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 01/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 02/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 03/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 04/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 05/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 06/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 07/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 08/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 09/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 10/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 11/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 12/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 13/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 14/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 15/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 16/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 17/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 18/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 19/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 20/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 21/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 22/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 23/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 24/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 25/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 26/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 27/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 28/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 29/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 30/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Channel 31/32 :    0
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 00/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 01/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 02/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 03/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 04/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 05/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 06/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 07/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 08/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 09/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 10/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 11/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 12/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 13/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 14/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 15/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 16/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 17/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 18/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 19/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 20/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 21/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 22/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 23/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 24/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 25/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 26/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 27/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 28/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 29/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 30/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Channel 31/32 :    0
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Setting affinity for GPU 5 to ff,ffff0000,00ffffff
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 00/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 01/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 02/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 03/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 04/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 05/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 06/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 07/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 08/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 09/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 10/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 11/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 12/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 13/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 14/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 15/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 16/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 17/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 18/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 19/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 20/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 21/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 22/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 23/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 24/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 25/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 26/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 27/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 28/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 29/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 30/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Channel 31/32 :    0
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1496:1569 [1] NCCL INFO comm 0x7f4004008e10 rank 0 nranks 1 cudaDev 1 busId 1b000 - Init COMPLETE
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1500:1571 [5] NCCL INFO comm 0x7f2d44008e10 rank 0 nranks 1 cudaDev 5 busId 3e000 - Init COMPLETE
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 00/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 01/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 02/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 03/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 04/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 05/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 06/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 07/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 08/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 09/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 10/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 11/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 12/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 13/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 14/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 15/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 16/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 17/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 18/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 19/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 20/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 21/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 22/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 23/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 24/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 25/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 26/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 27/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 28/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 29/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 30/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Channel 31/32 :    0
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1497:1573 [2] NCCL INFO comm 0x7f1fcc008e10 rank 0 nranks 1 cudaDev 2 busId 1d000 - Init COMPLETE
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 00/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 01/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 02/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 03/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 04/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 05/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 06/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 07/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 08/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 09/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 10/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 11/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 12/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 13/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 14/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 15/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 16/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 17/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 18/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 19/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 20/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 21/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 22/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 23/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 24/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 25/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 26/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 27/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 28/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 29/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 30/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Channel 31/32 :    0
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Setting affinity for GPU 7 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1495:1576 [0] NCCL INFO comm 0x7effd0008e10 rank 0 nranks 1 cudaDev 0 busId 1a000 - Init COMPLETE
10.0.2.18: configuring data
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1502:1579 [7] NCCL INFO comm 0x7f9330008e10 rank 0 nranks 1 cudaDev 7 busId 41000 - Init COMPLETE
10.0.2.17: f738527b48a8:888:888 [3] NCCL INFO Bootstrap : Using eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:888:888 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.17: f738527b48a8:888:888 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.17: f738527b48a8:888:888 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:888:888 [3] NCCL INFO Using network Socket
10.0.2.17: NCCL version 2.8.4+cuda11.2
10.0.2.17: f738527b48a8:886:886 [1] NCCL INFO Bootstrap : Using eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:886:886 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.17: f738527b48a8:886:886 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.17: f738527b48a8:886:886 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:886:886 [1] NCCL INFO Using network Socket
10.0.2.17: NCCL version 2.8.4+cuda11.2
10.0.2.17: f738527b48a8:887:887 [2] NCCL INFO Bootstrap : Using eth0:10.0.2.17<0>
10.0.2.17: 
10.0.2.17: f738527b48a8:893:944 [7] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.17: f738527b48a8:887:887 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.17: f738527b48a8:887:887 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.17: f738527b48a8:887:887 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:887:887 [2] NCCL INFO Using network Socket
10.0.2.17: NCCL version 2.8.4+cuda11.2
10.0.2.17: 
10.0.2.17: f738527b48a8:893:944 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 00/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 01/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 02/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 03/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 04/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 05/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 06/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 07/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 08/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 09/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 10/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 11/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 12/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 13/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 14/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 15/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 16/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 17/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 18/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 19/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 20/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 21/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 22/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 23/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 24/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 25/32 :    0
10.0.2.17: f738527b48a8:885:885 [0] NCCL INFO Bootstrap : Using eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 26/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 27/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 28/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 29/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 30/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Channel 31/32 :    0
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Setting affinity for GPU 7 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:885:885 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.17: f738527b48a8:885:885 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.17: f738527b48a8:889:889 [4] NCCL INFO Bootstrap : Using eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:885:885 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:885:885 [0] NCCL INFO Using network Socket
10.0.2.17: f738527b48a8:889:889 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.17: NCCL version 2.8.4+cuda11.2
10.0.2.17: f738527b48a8:889:889 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.17: f738527b48a8:889:889 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:889:889 [4] NCCL INFO Using network Socket
10.0.2.17: NCCL version 2.8.4+cuda11.2
10.0.2.17: f738527b48a8:890:890 [5] NCCL INFO Bootstrap : Using eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:890:890 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.17: f738527b48a8:890:890 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.17: f738527b48a8:890:890 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:890:890 [5] NCCL INFO Using network Socket
10.0.2.17: NCCL version 2.8.4+cuda11.2
10.0.2.17: f738527b48a8:891:891 [6] NCCL INFO Bootstrap : Using eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:891:891 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
10.0.2.17: f738527b48a8:891:891 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
10.0.2.17: f738527b48a8:891:891 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.2.17<0>
10.0.2.17: f738527b48a8:891:891 [6] NCCL INFO Using network Socket
10.0.2.17: NCCL version 2.8.4+cuda11.2
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.17: f738527b48a8:893:944 [7] NCCL INFO comm 0x7f67b0008e10 rank 0 nranks 1 cudaDev 7 busId 41000 - Init COMPLETE
10.0.2.17: 
10.0.2.17: f738527b48a8:887:952 [2] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.17: 
10.0.2.17: f738527b48a8:887:952 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:953 [3] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 00/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 01/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 02/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 03/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 04/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 05/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 06/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 07/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 08/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 09/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 10/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 11/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 12/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 13/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 14/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 15/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 16/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 17/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 18/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 19/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 20/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 21/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 22/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 23/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 24/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 25/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 26/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 27/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 28/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 29/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 30/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Channel 31/32 :    0
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Setting affinity for GPU 2 to 3fff,fff00000,03ffffff
10.0.2.17: 
10.0.2.17: f738527b48a8:886:955 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.17: 
10.0.2.17: f738527b48a8:888:953 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:955 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 00/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 01/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 02/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 03/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 04/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 05/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 06/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 07/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 08/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 09/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 10/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 11/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 12/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 13/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 14/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 15/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 16/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 17/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 18/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 19/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 20/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 21/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 22/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 23/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 24/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 25/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 26/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 27/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 28/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 29/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 30/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Channel 31/32 :    0
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Setting affinity for GPU 3 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 00/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 01/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 02/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 03/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 04/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 05/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 06/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 07/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 08/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 09/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 10/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 11/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 12/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 13/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 14/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 15/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 16/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 17/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 18/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 19/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 20/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 21/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 22/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 23/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 24/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 25/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 26/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 27/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 28/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 29/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 30/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Channel 31/32 :    0
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Setting affinity for GPU 1 to 3fff,fff00000,03ffffff
10.0.2.17: 
10.0.2.17: f738527b48a8:885:958 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.17: 
10.0.2.17: f738527b48a8:889:959 [4] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.17: 
10.0.2.17: f738527b48a8:885:958 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:959 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 00/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 01/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 02/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 03/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 04/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 05/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 06/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 07/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 08/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 09/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 10/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 11/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 12/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 13/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 14/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 15/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 16/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 17/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 18/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 19/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 20/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 21/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 22/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 23/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 24/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 25/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 26/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 27/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 28/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 29/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 30/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Channel 31/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 00/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 01/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 02/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 03/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 04/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 05/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 06/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 07/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 08/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 09/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 10/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 11/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 12/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 13/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 14/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 15/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 16/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 17/32 :    0
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Setting affinity for GPU 0 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 18/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 19/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 20/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 21/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 22/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 23/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 24/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 25/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 26/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 27/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 28/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 29/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 30/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Channel 31/32 :    0
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Setting affinity for GPU 4 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.17: f738527b48a8:887:952 [2] NCCL INFO comm 0x7f673c008e10 rank 0 nranks 1 cudaDev 2 busId 1d000 - Init COMPLETE
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.17: f738527b48a8:886:955 [1] NCCL INFO comm 0x7ff954008e10 rank 0 nranks 1 cudaDev 1 busId 1b000 - Init COMPLETE
10.0.2.17: 
10.0.2.17: f738527b48a8:891:964 [6] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.17: 
10.0.2.17: f738527b48a8:890:965 [5] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.17: f738527b48a8:888:953 [3] NCCL INFO comm 0x7ff12c008e10 rank 0 nranks 1 cudaDev 3 busId 1e000 - Init COMPLETE
10.0.2.17: 
10.0.2.17: f738527b48a8:891:964 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 00/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 01/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 02/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 03/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 04/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 05/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 06/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 07/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 08/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 09/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 10/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 11/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 12/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 13/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 14/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 15/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 16/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 17/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 18/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 19/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 20/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 21/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 22/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 23/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 24/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 25/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 26/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 27/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 28/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 29/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 30/32 :    0
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Channel 31/32 :    0
10.0.2.17: 
10.0.2.17: f738527b48a8:890:965 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Setting affinity for GPU 6 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 00/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 01/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 02/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 03/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 04/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 05/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 06/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 07/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 08/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 09/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 10/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 11/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 12/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 13/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 14/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 15/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 16/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 17/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 18/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 19/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 20/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 21/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 22/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 23/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 24/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 25/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 26/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 27/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 28/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 29/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 30/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Channel 31/32 :    0
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Setting affinity for GPU 5 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.17: f738527b48a8:885:958 [0] NCCL INFO comm 0x7f79a0008e10 rank 0 nranks 1 cudaDev 0 busId 1a000 - Init COMPLETE
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.17: f738527b48a8:889:959 [4] NCCL INFO comm 0x7fe23c008e10 rank 0 nranks 1 cudaDev 4 busId 3d000 - Init COMPLETE
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.17: f738527b48a8:891:964 [6] NCCL INFO comm 0x7f72c4008e10 rank 0 nranks 1 cudaDev 6 busId 40000 - Init COMPLETE
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
10.0.2.17: f738527b48a8:890:965 [5] NCCL INFO comm 0x7f188c008e10 rank 0 nranks 1 cudaDev 5 busId 3e000 - Init COMPLETE
10.0.2.18: Create dataset bert-base with 6345098 documents
10.0.2.18: [7296, 1062, 2953, 28370, 2531, 2193, 4175, 2892, 22104, 7296, 1062, 2953, 28370, 1010, 1037, 3128, 3109, 8625, 1010, 2001, 2141, 1999, 10556, 6894, 10760, 2050, 1010, 7571, 1999, 5483, 1006, 3109, 3022, 1007, 2012, 3845, 1012, 3166, 1998, 2010, 2470, 2147, 2031, 2042, 5182, 2011, 1037, 2843, 1997, 2880, 4411, 1010, 1998, 16410, 1010, 1999, 5483, 1998, 2035, 2058, 1996, 2088, 1012, 1996, 3166, 2038, 2626, 2062, 2084, 1017, 1010, 8698, 2808, 1010, 8698, 2604, 2399, 1010, 13757, 22477, 1998, 13427, 3729, 21716, 2015, 1013, 4966, 21716, 2015, 2055, 3418, 1998, 2715, 2381, 1999, 1996, 4249, 1997, 5543, 1010, 4087, 1010, 2604, 2399, 1010, 7761, 2840, 1010, 4007, 1010, 2293, 3821, 1010, 10768, 21369, 14680, 2913, 1010, 2470, 1010, 2553, 2913, 1010, 4083, 4155, 1010, 8154, 5149, 28987, 6169, 1010, 5110, 2470, 4385, 1012, 2004, 1037, 6398, 1010, 2013, 2010, 13496, 1010, 1996, 3166, 2038, 2517, 2116, 4790, 1999, 2116, 6399, 1010, 7298, 4385, 1012, 1998, 2001, 3559, 1999, 2708, 1999, 2070, 1997, 2068, 1012, 27338, 2031, 2042, 4844, 1013, 3970, 2013, 1996, 3757, 1997, 2495, 1010, 3757, 1997, 3226, 1010, 23122, 2390, 1010, 3757, 1997, 3097, 3821, 1010, 12239, 1006, 14255, 16652, 2271, 1998, 3470, 1007, 1010, 7842, 2063, 1010, 4385, 1012, 2573, 2031, 2042, 4236, 1999, 9385, 4822, 1999, 5483, 1010, 3915, 1998, 2710, 1012, 2116, 2982, 1998, 6495, 2105, 1996, 2088, 1012, 9385, 1075, 2418, 7296, 1062, 2953, 28370, 2035, 2916, 9235, 1012, 1052, 1012, 1051, 1012, 3482, 9683, 19841, 1010, 24665, 1011, 21364, 2692, 10556, 6894, 10760, 2050, 1010, 5483, 4144, 2892, 18351, 2053, 1012, 1015, 1049, 1047, 1053, 1056, 1043, 1051, 1050, 1049, 1038, 1056, 1037, 1050, 1052, 1048, 1052, 1044, 1054, 1054, 1060, 1060, 1039, 1039, 1047, 1040, 1057, 1038, 1042, 1057, 1047, 1054, 1054, 1061, 1050, 1054, 1047, 1052, 1043, 1060, 1048, 1057, 1054, 1056, 1053, 1038, 1059, 1056, 1042, 1046, 1046, 1059, 1046, 1038, 1058, 1061, 1049, 1048, 1040, 1053, 1054, 1043, 1047, 1051, 1045, 1037, 1048, 1045, 1049, 1055, 1049, 1040, 1049, 1061, 1061, 1060, 1055, 1052, 1038, 1052, 1062, 1051, 1041, 1057, 1044, 1041, 1048, 1039, 1049, 1061, 1059, 1062, 1049, 1055, 1043, 1058, 1037, 1055, 1062, 1051, 1049, 1039, 1062, 1046, 1059, 1057, 1060, 1038, 1052, 1044, 1062, 1044, 1053, 1042, 1037, 1037, 1060, 1041, 1041, 1037, 1050, 1053, 1054, 1041, 1054, 1042, 1062, 1041, 1062, 1039, 1045, 1057, 1056, 1049, 1054, 1038, 1047, 1043, 1054, 1053, 1039, 1038, 1055, 1060, 1050, 1056, 1049, 1062, 1052, 1044, 1037, 1055, 1058, 1052, 1057, 1046, 1061, 1047, 1046, 1050, 1046, 1060, 1055, 1042, 1044, 1059, 1040, 1045, 1050, 1040, 1057, 1061, 1046, 1053, 1046, 1059, 1052, 1059, 1037, 1050, 1047, 1042, 1057, 1058, 1054, 1044, 1041, 1056, 1043, 1049, 1047, 1055, 1044, 1052, 1042, 1041, 1049, 4144, 2892, 18351, 2053, 1012, 1016, 1055, 1059, 1049, 1055, 1062, 1045, 1037, 1047, 1054, 1062, 1037, 1046, 1041, 1042, 1042, 1056, 1048, 1059, 1059, 1055, 1060, 1039, 1056, 1039, 1049, 1042, 1049, 1047, 1049, 1044, 1052, 1044, 1047, 1041, 1056, 1054, 1038, 1038, 1056, 1054, 1060, 1044, 1057, 1043, 1058, 1048, 1047, 1057, 1059, 1038, 1044, 1056, 1048, 1042, 1049, 1044, 1037, 1050, 1049, 1055, 1051, 1050, 1045, 1062, 1048, 1058, 1053, 1038, 1051, 1046, 1037, 1055, 1061, 1049, 1058, 1045, 1060, 1059, 1059, 1055, 1037, 1043, 1060, 1049, 1056, 1047, 1056, 1054, 1055, 1039, 1049, 1057, 1037, 1040, 1055, 1051, 1038, 1038, 1048, 1038, 1056, 1044, 1050, 1046, 1061, 1055, 1047, 1055, 1042, 1042, 1038, 1051, 1051, 1055, 1054, 1062, 1039, 1037, 1040, 1037, 1059, 1041, 1053, 1049, 1062, 1037, 1047, 1055, 1047, 1059, 1057, 1038, 1049, 1055, 1044, 1059, 1048, 1040, 1061, 1055, 1038, 1050, 1059, 1048, 1049, 1057, 1050, 1052, 1043, 1050, 1040, 1043, 1048, 1043, 1045, 1059, 1056, 1045, 1052, 1041, 1046, 1056, 1046, 1057, 1043, 1045, 1049, 1052, 1056, 1059, 1052, 1046, 1041, 1048, 1039, 1043, 1058, 1044, 1049, 1058, 1057, 1051, 1055, 1038, 1051, 1045, 1062, 1048, 1057, 1044, 1043, 1049, 1055, 1052, 1043, 4144, 2892, 18351, 2053, 1012, 1017, 1047, 1043, 1054, 1040, 1058, 1057, 1055, 1061, 1048, 1043, 1062, 1047, 1048, 1056, 1055, 1047, 1050, 1047, 1051, 1051, 1048, 1048, 1062, 1057, 1040, 1061, 1047, 1059, 1062, 1051, 1047, 1059, 1052, 1037, 1038, 1054, 1039, 1051, 1057, 1038, 1061, 1054, 1061, 1037, 1061, 1062, 1054, 1038, 1040, 1053, 1047, 1062, 1054, 1061, 1057, 1050, 1039, 1044, 1060, 1046, 1058, 1058, 1057, 1039, 1061, 1052, 1039, 1053, 1046, 1052, 1044, 1054, 1055, 1056, 1040, 1048, 1057, 1055, 1060, 1056, 1054, 1040, 1047, 1055, 1059, 1043, 1052, 1060, 1037, 1054, 1045, 1057, 1037, 1045, 1061, 1044, 1062, 1039, 1047, 1044, 1049, 1058, 1046, 1038, 1044, 1040, 1049, 1043, 1059, 1049, 1057, 1047, 1055, 1045, 1042, 1059, 1054, 1055, 1052, 1050, 1056, 1045, 1056, 1042, 1038, 1062, 1038, 1046, 1052, 1042, 1058, 1057, 1045, 1060, 1041, 1047, 1045, 1044, 1051, 1053, 1038, 1037, 1040, 1040, 1046, 1062, 1054, 1047, 1048, 1049, 1058, 1047, 1039, 1041, 1061, 1057, 1057, 1053, 1037, 1044, 1038, 1038, 1047, 1060, 1058, 1054, 1042, 1039, 1049, 1058, 1051, 1053, 1045, 1056, 1046, 1051, 1038, 1056, 1058, 1042, 1039, 1059, 1062, 1048, 1045, 1057, 1040, 1056, 1059, 1058, 1050, 1042, 1055, 1044, 1037, 4144, 2892, 18351, 2053, 1012, 1018, 1040, 1062, 1043, 1039, 1049, 1041, 1040, 1043, 1057, 1047, 1038, 1048, 1061, 1039, 1062, 1038, 1061, 1058, 1048, 1057, 1056, 1056, 1047, 1060, 1044, 1062, 1037, 1049, 1062, 1054, 1051, 1059, 1058, 1062, 1058, 1060, 1047, 1038, 1044, 1043, 1052, 1053, 1045, 1050, 1062, 1040, 1039, 1038, 1050, 1062, 1044, 1060, 1044, 1052, 1062, 1060, 1044, 1039, 1046, 1044, 1054, 1054, 1046, 1054, 1052, 1061, 1047, 1058, 1038, 1045, 1039, 1042, 1058, 1056, 1053, 1056, 1041, 1056, 1043, 1042, 1038, 1054, 1062, 1062, 1056, 1045, 1051, 1051, 1061, 1062, 1058, 1051, 1047, 1054, 1038, 1046, 1053, 1046, 1053, 1047, 1058, 1046, 1042, 1059, 1044, 1053, 1042, 1056, 1039, 1055, 1037, 1052, 1057, 1038, 1038, 1055, 1057, 1060, 1052, 1060, 1037, 1042, 1048, 1050, 1054, 1055, 1049, 1042, 1061, 1057, 1038, 1038, 1058, 1052, 1058, 1038, 1055, 1046, 1044, 1038, 1042, 1046, 1048, 1048, 1046, 1042, 1061, 1039, 1056, 1059, 1043, 1053, 1042, 1055, 1042, 1057, 1061, 1041, 1047, 1054]
10.0.2.18: b'gregory zorzos 100 number count crosswords gregory zorzos , a native hellene , was born in kallithea , athens in greece ( hellas ) at 1958 . author and his research work have been distinguished by a lot of official organizations , and ministries , in greece and all over the world . the author has wrote more than 3 , 350 books , 350 board games , 650 dvds and 280 cdroms / dvdroms about ancient and modern history in the fields of economics , technical , board games , martial arts , software , love affairs , feasibilities studies , research , case studies , learning languages , logodynamics , inner research etc . as a reporter , from his teens , the author has written many articles in many newspapers , magazines etc . and was editor in chief in some of them . researches have been approved / accepted from the ministry of education , ministry of culture , hellenic army , ministry of foreign affairs , unesco ( piraeus and islands ) , sae , etc . works have been register in copyright offices in greece , usa and canada . many awards and credits around the world . copyright \xc2\xa9 2017 gregory zorzos all rights reserved . p . o . box 75070 , gr - 17610 kallithea , greece letters crossword no . 1 m k q t g o n m b t a n p l p h r r x x c c k d u b f u k r r y n r k p g x l u r t q b w t f j j w j b v y m l d q r g k o i a l i m s m d m y y x s p b p z o e u h e l c m y w z m s g v a s z o m c z j w u x b p h z h q f a a x e e a n q r e r f z e z c i u t m r b k g r q c b s x n t m z p h a s v p u j y k j n j x s f h w d i n d u y j q j w p w a n k f u v r h e t g m k s h p f e m letters crossword no . 2 s w m s z i a k r z a j e f f t l w w s x c t c m f m k m h p h k e t r b b t r x h u g v l k u w b h t l f m h a n m s o n i z l v q b o j a s y m v i x w w s a g x m t k t r s c m u a d s o b b l b t h n j y s k s f f b o o s r z c a d a w e q m z a k s k w u b m s h w l d y s b n w l m u n p g n d g l g i w t i p e j t j u g i m p t w p j e l c g v h m v u o s b o i z l u h g m s p g letters crossword no . 3 k g r d v u s y l g z k l t s k n k o o l l z u d y k w z o k w p a b r c o u b y r y a y z r b d q k z r y u n c h x j v v u c y p c q j p h r s t d l u s x t r d k s w g p x a r i u a i y h z c k h m v j b h d m g w m u k s i f w r s p n t i t f b z b j p f v u i x e k i h o q b a d d j z r k l m v k c e y u u q a h b b k x v r f c m v o q i t j o b t v f c w z l i u d t w v n f s h a letters crossword no . 4 d z g c m e d g u k b l y c z b y v l u t t k x h z a m z r o w v z v x k b h g p q i n z d c b n z h x h p z x h c j h r r j r p y k v b i c f v t q t e t g f b r z z t i o o y z v o k r b j q j q k v j f w h q f t c s a p u b b s u x p x a f l n r s m f y u b b v p v b s j h b f j l l j f y c t w g q f s f u y e k r'
10.0.2.18: [1008, 1008, 1008, 1001, 1001, 2028, 4595, 4210, 1037, 2198, 9660, 3117, 2928, 11026, 25151, 3179, 1008, 1008, 1008, 1001, 1001, 1001, 9385, 1075, 2928, 11026, 2286, 1037, 2304, 3899, 4640, 26885, 1012, 2034, 2405, 1999, 2307, 3725, 1999, 2286, 2011, 2304, 3899, 26885, 2034, 2405, 1999, 2286, 2011, 2304, 3899, 2023, 26885, 2405, 1999, 2286, 2011, 2304, 3899, 4289, 3436, 2011, 14955, 6843, 2271, 2996, 1996, 7191, 2157, 1997, 2928, 11026, 2000, 2022, 4453, 2004, 1996, 3166, 1997, 2023, 2147, 2038, 2042, 13647, 2011, 2032, 1999, 10388, 2007, 1996, 9385, 1010, 5617, 1998, 13979, 2552, 2997, 1012, 2035, 1996, 3494, 1999, 2023, 2338, 2024, 23577, 1010, 1998, 2151, 14062, 2000, 5025, 5381, 2542, 2030, 2757, 2003, 11850, 19680, 15758, 1012, 2035, 2916, 9235, 1012, 2053, 2112, 1997, 2023, 4772, 2089, 2022, 22296, 1010, 8250, 1999, 1037, 26384, 2291, 2030, 11860, 1999, 2151, 2433, 2030, 2011, 2151, 2965, 1010, 2302, 1996, 3188, 6656, 1999, 3015, 1997, 1996, 6674, 1010, 4496, 2000, 2022, 4728, 17640, 1999, 2151, 2433, 1997, 8031, 2030, 3104, 2060, 2084, 2008, 1999, 2029, 2009, 2003, 2405, 2302, 1037, 2714, 4650, 1010, 2164, 2023, 4650, 1010, 2108, 9770, 2006, 1996, 4745, 5309, 2099, 1012, 2093, 2847, 2046, 1996, 3462, 1998, 2002, 11323, 2002, 2001, 2055, 2000, 2031, 1996, 3959, 2153, 1012, 1996, 6644, 2001, 4251, 1024, 12278, 5985, 1010, 8974, 2366, 1010, 4597, 11737, 7583, 1012, 2074, 1996, 6706, 18465, 1997, 1996, 5209, 1012, 1996, 2060, 5467, 2020, 19613, 1010, 2070, 1997, 2068, 2927, 2000, 3637, 1012, 2002, 2584, 2005, 2010, 18353, 1998, 2404, 2009, 2000, 2010, 2970, 1012, 2010, 2192, 3184, 1025, 1996, 3256, 14291, 2015, 19252, 2114, 1996, 2217, 1997, 1996, 3221, 1012, 2009, 2106, 2025, 2272, 2411, 2085, 1012, 2002, 2018, 2081, 2009, 2008, 2126, 1010, 2007, 1996, 2486, 1997, 2010, 2097, 1010, 2664, 1010, 2006, 2216, 6642, 2043, 1996, 3959, 2106, 9462, 2032, 1010, 2009, 2234, 2007, 2035, 2049, 2214, 3997, 1998, 6819, 3995, 3126, 1012, 2002, 2354, 1996, 5751, 1024, 2008, 5220, 3110, 1997, 2108, 8892, 2098, 2041, 1010, 2019, 4064, 6258, 2046, 2029, 2009, 2052, 10364, 1012, 16342, 11855, 2010, 16828, 1010, 1998, 2002, 2018, 2025, 7771, 2005, 2048, 2420, 1012, 2002, 7757, 2010, 2159, 3844, 1998, 9672, 1996, 2849, 28533, 2015, 2061, 7371, 2008, 2010, 13513, 2317, 7228, 1012, 2010, 4065, 5299, 1998, 1996, 6650, 2369, 2010, 5042, 1010, 1998, 1999, 2010, 28023, 1010, 8371, 1012, 2002, 26719, 2067, 2046, 1996, 2835, 1010, 2667, 2000, 7200, 5373, 2021, 4209, 2008, 2002, 2001, 26546, 2075, 2169, 3052, 1012, 2002, 2001, 13346, 1010, 17727, 12184, 3372, 1010, 1998, 11498, 2135, 6924, 1012, 7567, 1012, 2002, 7757, 2010, 2159, 12347, 1010, 2061, 2524, 2008, 4714, 9231, 18098, 6799, 18217, 1997, 2417, 1998, 3756, 2422, 16690, 2094, 2114, 2010, 26122, 1012, 1996, 3959, 8255, 2875, 2032, 2066, 1996, 6510, 2304, 2677, 1997, 1037, 5234, 1010, 1999, 10288, 6525, 3468, 1998, 14477, 6767, 8524, 3468, 1010, 1998, 1010, 3402, 1010, 2002, 2001, 16687, 2046, 2009, 1012, 2009, 2001, 2004, 14954, 2004, 4507, 1012, 2004, 2009, 2318, 2000, 4895, 13102, 13669, 1010, 2066, 1037, 5220, 2143, 2002, 2699, 2000, 5342, 2185, 1999, 1037, 12727, 3482, 1010, 2010, 11581, 2568, 2001, 2583, 2000, 11949, 1998, 14358, 2009, 1010, 2000, 12826, 2009, 2007, 1996, 2627, 1010, 1998, 2000, 13399, 2008, 2002, 2001, 2521, 2013, 21391, 1012, 1996, 5532, 1012, 1996, 2352, 1012, 1996, 12993, 2050, 1012, 1996, 2336, 1012, 1996, 10036, 6081, 2374, 1010, 25430, 25164, 1999, 1996, 3612, 1012, 1996, 2402, 2879, 1012, 1996, 4946, 1010, 2746, 1999, 3435, 1998, 2659, 1010, 1996, 11950, 1997, 2049, 5209, 17142, 2083, 1996, 3028, 1012, 2013, 1024, 1026, 2417, 18908, 2098, 1028, 2000, 1024, 1026, 2417, 18908, 2098, 1028, 3058, 1024, 6928, 1010, 2337, 2403, 1010, 1019, 1012, 4583, 1052, 1012, 1049, 1012, 3395, 1024, 1040, 18098, 2243, 6203, 3097, 3187, 1010, 1996, 1052, 1012, 1049, 1012, 2356, 2005, 2582, 2592, 2006, 2197, 3204, 1005, 1055, 4491, 1012, 1045, 3568, 22476, 1037, 3189, 7940, 2011, 2358, 8609, 29278, 2029, 4593, 23283, 2054, 2057, 6878, 2000, 2022, 2995, 1012, 1045, 3602, 2008, 2256, 2137, 2814, 2031, 2584, 1996, 2168, 7091, 1010, 1998, 2008, 2027, 3745, 2256, 9135, 2012, 1996, 17727, 19496, 3723, 2007, 2029, 1996, 1040, 18098, 2243, 2003, 3772, 1999, 2023, 7634, 1012, 2027, 9530, 10841, 2099, 2007, 2149, 2008, 1996, 2051, 2038, 2272, 2000, 2292, 2068, 2113, 2008, 2045, 2003, 1037, 2417, 2240, 3458, 2029, 2027, 2442, 2025, 2892, 1010, 1998, 2008, 8465, 2097, 4834, 2065, 2027, 2079, 1012, 1045, 2113, 2008, 1996, 6059, 2038, 2988, 2122, 23541, 2000, 2017, 1012, 2065, 2045, 2003, 2151, 3582, 1011, 2039, 2320, 1996, 1052, 1012, 1049, 1012, 2038, 2641, 2023, 4454, 3531, 2079, 1010, 2004, 2412, 1010, 2292, 2033, 2113, 1012, 25664, 1010, 1049, 1012, 1028, 1028, 1028, 4269, 1008, 1008, 1008, 2159, 2069, 1008, 1008, 1008, 4772, 1024, 4106, 1013, 4281, 2012, 18886, 29446, 1024, 2358, 8609, 29278, 3120, 6412, 1024, 2167, 4759, 11125, 3120, 15258, 1024, 1038, 8875, 21553, 1024, 1016, 4353, 1024, 6541, 3120, 28213, 1024, 7065, 2050, 1040, 18098, 2243, 4216, 6592, 2197, 3204, 1005, 1055, 5294, 16941, 1011, 2886, 2006, 5085, 1998, 2865, 3316, 2802, 15315, 1998, 1996, 2225, 2001, 3740, 1998, 6472, 1999, 1052, 14001, 6292, 5654, 1012, 15315, 5085, 2164, 12277, 4819, 1010, 2512, 5603, 10513, 2361, 1998, 15333, 9103, 1010, 2362, 2007, 2694, 18706, 21677, 2015, 1010, 27262, 1998, 1061, 2102, 2078, 2020, 2035, 2579, 2125, 4179, 2004, 3642, 5360, 12800, 4466, 2243, 27019, 2006, 2037, 6125, 1012, 3350, 7127, 1996, 2886, 7940, 2007, 1040, 18098, 2243, 1005, 1055, 2236, 8967, 4879, 1013, 2510, 4454, 2407, 1012, 1996, 2886, 3659, 1000, 13387, 2099, 1000, 15451, 8059, 1011, 1011, 2315, 8183, 22272, 1011, 1011, 2008, 17159, 1996, 3040, 9573, 2636, 2013, 27019, 1998, 4692, 2000, 3972, 12870, 6702, 2013, 19998, 1013, 11603, 14903, 1012, 2023, 12950, 3025, 1040, 18098, 2243, 23707, 7060, 1012, 1055, 1012, 1047, 1012, 3757, 1997, 2671, 1010, 2592, 1010, 3274, 2974, 1998, 2925, 4041, 1006, 5796, 2594, 24475, 2361, 1007, 23283, 16406, 1997, 3350, 1998, 10744, 1012, 4515, 1026, 1026, 1026, 2013, 1024, 1026, 2417, 18908, 2098, 1028, 2000, 1024, 1026, 2417, 18908, 2098, 1028, 3058, 1024, 9857, 1010, 2337, 2321, 1010, 1018, 1012, 2423, 1052]
10.0.2.18: b'* * * # # one thousand yards a john milton novel mark dawson smashwords edition * * * # # # copyright \xc2\xa9 mark dawson 2013 a black dog publishing ebook . first published in great britain in 2013 by black dog ebook first published in 2013 by black dog this ebook published in 2013 by black dog formatting by polgarus studio the moral right of mark dawson to be identified as the author of this work has been asserted by him in accordance with the copyright , designs and patents act 1988 . all the characters in this book are fictitious , and any resemblance to actual persons living or dead is purely coincidental . all rights reserved . no part of this publication may be reproduced , stored in a retrieval system or transmitted in any form or by any means , without the prior permission in writing of the publisher , nor to be otherwise circulated in any form of binding or cover other than that in which it is published without a similar condition , including this condition , being imposed on the subsequent purchaser . three hours into the flight and he realised he was about to have the dream again . the cabin was quiet : meals cleared , drinks served , lights dimmed . just the steady drone of the engines . the other passengers were relaxing , some of them beginning to sleep . he reached for his gin and put it to his lips . his hand shook ; the ice cubes rattled against the side of the glass . it did not come often now . he had made it that way , with the force of his will , yet , on those occasions when the dream did overcome him , it came with all its old strength and vigour . he knew the signs : that familiar feeling of being hollowed out , an empty vessel into which it would pour . fatigue weakened his defences , and he had not slept for two days . he squeezed his eyes shut and gripped the armrests so tightly that his knuckles whitened . his shoulders locked and the muscles behind his knees , and in his calves , tightened . he sagged back into the seat , trying to breathe normally but knowing that he was gulping each breath . he was helpless , impotent , and paralysed . trapped . he squeezed his eyes tighter , so hard that tiny pinprick explosions of red and yellow light cascaded against his lids . the dream raced towards him like the pitch black mouth of a tunnel , inexorable and unavoidable , and , suddenly , he was plunged into it . it was as vivid as reality . as it started to unspool , like a familiar film he tried to hide away in a dusty box , his rational mind was able to observe and assess it , to compare it with the past , and to acknowledge that he was far from cured . the desert . the village . the madrasa . the children . the cheap plastic football , swerving in the wind . the young boy . the plane , coming in fast and low , the roar of its engines echoing through the valley . from : < redacted > to : < redacted > date : monday , february 14 , 5 . 55 p . m . subject : dprk dear foreign secretary , the p . m . asked for further information on last month \' s attacks . i therefore attach a report originated by stratfor which apparently confirms what we suspected to be true . i note that our american friends have reached the same conclusion , and that they share our frustration at the impunity with which the dprk is acting in this regard . they concur with us that the time has come to let them know that there is a red line beyond which they must not cross , and that consequences will flow if they do . i know that the ambassador has reported these sentiments to you . if there is any follow - up once the p . m . has considered this intelligence please do , as ever , let me know . sincerely , m . > > > begins * * * eyes only * * * publication : analysis / background attribution : stratfor source description : north korean diplomat source reliability : b item credibility : 2 distribution : alpha source handler : reva dprk sources suggest last month \' s massive cyber - attack on banks and media companies throughout sk and the west was planned and executed in pyongyang . sk banks including shinhan , nonghyup and jeju , together with tv broadcasters kbs , mbc and ytn were all taken offline as code affected circa 48k pcs on their networks . evidence indicates the attack originated with dprk \' s general reconnaissance bureau / military intelligence division . the attack spread " wiper " malware - - named jokra - - that deleted the master boot records from pcs and attempted to delete volumes from unix / linux servers . this resembles previous dprk hacking patterns . s . k . ministry of science , information , computer technology and future planning ( msictfp ) confirms validity of evidence and hypothesis . ends < < < from : < redacted > to : < redacted > date : tuesday , february 15 , 4 . 25 p'
10.0.2.18: [1001, 2184, 4436, 2339, 1996, 9680, 11244, 2442, 2022, 2187, 2369, 1001, 1001, 1055, 1012, 1040, 1012, 9959, 1001, 1001, 1001, 1001, 11419, 4640, 100, 8912, 1010, 2821, 9385, 1075, 2325, 2011, 4459, 1040, 1012, 9959, 2035, 2916, 9235, 1012, 2053, 2112, 1997, 2023, 2338, 2089, 2022, 22296, 1999, 2151, 2433, 2030, 2011, 2151, 4816, 2030, 6228, 2965, 1010, 2164, 2592, 5527, 1998, 26384, 3001, 1010, 2302, 2517, 6656, 2013, 1996, 3166, 1010, 3272, 2005, 4766, 20563, 9285, 1012, 26885, 3175, 1024, 4891, 1011, 1015, 1011, 6191, 16576, 2549, 1011, 10630, 1011, 1023, 13611, 3175, 1024, 4891, 1011, 1015, 1011, 6191, 16576, 2549, 1011, 12904, 1011, 1020, 8001, 3179, 1006, 10476, 1007, 1012, 1008, 1008, 5860, 19771, 5017, 1024, 1008, 1008, 1996, 5328, 5228, 1999, 2023, 2338, 2079, 2025, 8339, 1996, 2783, 9029, 1997, 2049, 3166, 1010, 4496, 2515, 2009, 2444, 2039, 2000, 1996, 3115, 1997, 6566, 4846, 1999, 2101, 2573, 1012, 2174, 1010, 1996, 3793, 3464, 14477, 21928, 2098, 1010, 3272, 2005, 1037, 2261, 8368, 3431, 1010, 1999, 2023, 8001, 3179, 1012, 1996, 3452, 6685, 2003, 2145, 6025, 1998, 11763, 2011, 1996, 3166, 1010, 2007, 2069, 3576, 2685, 1997, 18185, 1010, 2029, 2079, 2025, 11477, 1996, 11174, 1997, 1996, 3793, 1012, 1996, 3166, 2052, 2066, 2000, 3602, 2008, 2023, 2338, 2003, 2019, 2220, 1010, 5399, 26838, 2147, 1997, 6566, 1012, 1001, 1001, 1001, 8417, 4955, 2702, 4436, 1015, 1012, 5896, 11137, 2135, 4895, 21001, 1016, 1012, 7145, 9962, 1017, 1012, 9686, 17695, 2964, 1018, 1012, 1037, 3571, 1011, 5533, 4695, 1019, 1012, 1996, 9229, 2110, 1997, 1996, 2088, 1020, 1012, 18204, 2964, 1006, 3532, 2014, 3549, 13765, 14606, 1007, 1021, 1012, 20316, 18204, 2964, 1006, 28810, 2014, 3549, 13765, 14606, 1007, 1022, 1012, 1037, 2117, 1006, 1998, 2353, 1029, 1007, 2746, 1023, 1012, 2566, 16874, 2075, 4441, 2184, 1012, 2566, 16874, 2075, 4441, 1005, 3260, 2044, 18351, 6749, 3752, 16614, 2005, 1037, 17772, 2925, 1001, 4955, 1001, 1001, 1001, 1037, 2978, 1997, 2026, 2466, 1996, 9680, 11244, 11171, 2033, 2004, 1037, 2879, 1012, 1045, 3342, 2116, 2086, 3283, 1037, 3327, 2305, 1997, 3637, 3238, 1010, 15035, 12812, 1012, 1045, 3373, 2007, 2035, 2026, 2540, 2008, 4441, 2001, 4192, 2008, 2305, 1010, 1998, 1045, 2354, 1045, 2134, 1005, 1056, 2215, 2000, 3335, 2009, 1012, 2004, 1045, 9652, 3592, 2041, 2026, 3332, 17858, 8074, 1996, 2709, 1997, 4828, 1010, 1045, 14283, 2008, 2643, 2052, 2025, 5293, 2033, 2030, 2681, 2033, 2369, 1012, 1045, 2018, 2657, 1996, 3441, 1010, 1045, 2354, 2054, 2001, 2746, 2279, 1012, 2009, 2001, 2126, 2627, 2026, 2793, 7292, 1010, 2021, 1045, 4370, 8300, 2146, 2046, 1996, 2305, 1010, 2026, 2210, 2540, 2440, 1997, 19725, 17626, 1012, 2021, 2498, 3047, 1012, 1996, 9680, 11244, 2134, 1005, 1056, 2272, 1012, 1045, 2939, 2105, 2082, 1996, 2279, 2154, 3038, 2000, 2870, 1010, 1000, 2023, 3475, 1005, 1056, 2613, 1012, 2651, 5807, 1005, 1056, 4839, 1012, 2197, 2305, 2001, 4011, 2000, 2022, 1996, 2203, 1997, 1996, 2088, 1012, 1000, 2066, 2116, 2402, 3337, 2040, 3473, 2039, 1999, 1037, 3017, 4044, 1010, 1045, 2001, 15677, 2007, 1996, 9680, 11244, 1012, 1045, 2001, 2196, 1037, 2200, 28675, 6331, 8068, 1010, 2021, 2043, 2009, 2234, 2000, 1996, 2338, 1997, 11449, 1010, 1045, 2001, 16265, 5533, 1012, 1045, 2052, 3191, 2008, 2338, 2153, 1998, 2153, 1998, 2153, 7143, 2000, 2424, 2049, 5023, 3574, 1012, 2009, 2001, 2066, 1037, 11989, 1010, 2019, 26757, 4588, 3074, 1997, 12018, 2187, 2005, 2033, 2000, 3275, 2041, 1012, 1045, 2097, 2196, 5293, 2008, 2305, 1010, 1998, 1996, 2116, 2060, 5312, 1997, 7404, 1045, 2371, 3652, 2039, 1999, 1996, 5192, 1997, 1996, 9680, 11244, 1012, 2009, 2347, 1005, 1056, 2127, 2026, 2267, 2086, 2008, 1045, 2211, 2000, 2817, 1996, 22481, 2062, 5667, 1012, 2000, 2026, 13769, 12208, 1998, 5213, 1010, 1045, 2574, 3603, 2129, 2210, 2045, 2001, 2000, 2067, 2039, 2026, 6772, 1999, 1996, 9680, 11244, 1012, 1998, 2004, 1045, 3273, 2062, 1010, 2026, 4752, 1999, 1996, 9680, 11244, 2855, 8105, 1012, 2026, 10069, 2020, 7653, 1012, 2021, 2025, 3071, 2038, 2272, 2000, 2023, 7091, 1012, 2116, 1010, 2926, 2651, 1999, 2637, 1010, 2145, 2444, 2104, 1996, 6772, 2008, 2012, 2151, 2617, 4441, 2097, 2272, 2067, 1998, 11891, 2035, 1996, 1000, 2995, 8135, 1000, 2039, 2046, 1996, 3712, 1998, 2681, 1996, 2717, 1997, 8438, 2006, 3011, 2000, 9015, 2307, 13012, 28507, 3508, 1012, 1998, 2008, 2003, 2339, 1045, 1005, 2310, 2517, 2023, 2338, 1012, 2009, 2001, 1037, 2210, 2058, 1037, 2095, 3283, 2085, 2008, 1045, 2034, 4207, 2026, 2047, 1011, 2179, 4824, 1997, 1996, 9680, 11244, 1999, 2019, 3720, 2006, 2026, 4037, 1012, 2009, 2855, 2150, 2028, 1997, 1996, 2087, 3191, 1045, 1005, 2310, 2517, 1012, 2061, 1045, 3651, 2045, 2001, 1037, 2342, 2041, 2045, 2008, 1045, 2071, 6039, 1012, 2026, 2466, 2003, 2025, 2019, 7275, 2028, 1012, 2116, 2500, 3745, 2026, 3325, 1012, 2009, 1005, 1055, 1037, 2502, 3066, 2005, 2033, 2059, 2000, 2113, 2008, 2054, 1045, 2234, 2000, 7523, 1999, 2026, 2219, 2166, 2453, 2036, 2393, 2619, 2842, 1999, 17156, 1012, 1998, 3383, 2008, 1005, 1055, 2339, 2017, 1005, 2310, 3856, 2039, 2023, 2338, 1012, 2672, 2017, 2031, 3980, 2055, 1996, 9680, 11244, 1010, 2672, 2054, 2320, 2790, 2061, 3154, 2053, 2936, 3849, 2008, 2126, 4902, 1012, 1045, 3246, 2026, 2466, 1998, 1996, 15306, 1045, 1005, 2310, 2272, 2000, 2097, 2393, 2017, 2681, 1996, 9680, 11244, 2369, 2005, 2204, 1012, 1045, 2113, 2034, 11774, 2054, 2009, 1005, 1055, 2066, 2000, 2507, 2039, 1996, 21877, 18719, 23738, 2594, 9680, 11244, 1998, 2156, 2643, 1005, 1055, 17772, 2203, 1012, 2000, 2031, 3246, 2005, 1996, 2925, 1010, 2000, 2113, 2008, 1996, 2088, 2097, 2022, 24910, 1998, 2025, 3908, 1012, 1045, 2113, 1996, 6569, 1045, 2371, 2043, 1045, 2633, 2187, 1996, 9680, 11244, 2369, 1012, 1045, 3246, 2000, 3745, 2008, 4335, 2007, 3071, 1045, 2064, 1012, 2054, 2017, 2903, 2055, 1996, 2203, 5609, 1012, 2009, 5609, 2138, 2009, 3431, 2129, 2017, 2444, 2157, 2085, 1010, 1998, 2054, 4066, 1997, 2166, 2017, 3857, 2005, 4826, 1012, 1045, 2556, 2182, 2702, 4436, 2339, 1996, 9680, 11244, 2442, 2022, 1000, 2187, 2369, 1000, 1012, 1045, 2113, 2025, 3071, 2097, 2022, 6427, 1010, 1998, 1045, 1005, 1049, 2469, 1999, 2107, 1037, 2460, 2338, 2045, 2097, 2022, 2116, 14477, 3619, 13777, 2098]
10.0.2.18: b'# 10 reasons why the rapture must be left behind # # s . d . morrison # # # # beloved publishing [UNK] columbus , oh copyright \xc2\xa9 2015 by stephen d . morrison all rights reserved . no part of this book may be reproduced in any form or by any electronic or mechanical means , including information storage and retrieval systems , without written permission from the author , except for brief quotations . ebook isbn : 978 - 1 - 63174 - 115 - 9 paperback isbn : 978 - 1 - 63174 - 116 - 6 revised edition ( 2019 ) . * * disclaimer : * * the views expressed in this book do not reflect the current beliefs of its author , nor does it live up to the standard of scholarship employed in later works . however , the text remains unaltered , except for a few editorial changes , in this revised edition . the overall argument is still retained and endorsed by the author , with only minor points of disagreement , which do not alter the intentions of the text . the author would like to note that this book is an early , somewhat immature work of scholarship . # # # contents introduction ten reasons 1 . scripturally unfounded 2 . historically absent 3 . escapism 4 . a fear - driven philosophy 5 . the improving state of the world 6 . literalism ( poor hermeneutics ) 7 . inconsistent literalism ( sloppy hermeneutics ) 8 . a second ( and third ? ) coming 9 . perverting jesus 10 . perverting jesus \' mission afterword recommended reading quotes for a hopeful future # introduction # # # a bit of my story the rapture haunted me as a boy . i remember many years ago a particular night of sleepless , restless agony . i believed with all my heart that jesus was returning that night , and i knew i didn \' t want to miss it . as i desperately stared out my window eagerly expecting the return of christ , i prayed that god would not forget me or leave me behind . i had heard the stories , i knew what was coming next . it was way past my bedtime , but i stayed awake long into the night , my little heart full of fearful expectation . but nothing happened . the rapture didn \' t come . i walked around school the next day saying to myself , " this isn \' t real . today shouldn \' t exist . last night was supposed to be the end of the world . " like many young boys who grew up in a christian environment , i was fascinated with the rapture . i was never a very disciplined bible reader , but when it came to the book of revelation , i was fiercely driven . i would read that book again and again and again desperate to find its hidden meaning . it was like a puzzle , an enigmatic collection of visions left for me to figure out . i will never forget that night , and the many other moments of terror i felt growing up in the shadow of the rapture . it wasn \' t until my college years that i began to study the scriptures more seriously . to my profound delight and shock , i soon discovered how little there was to back up my belief in the rapture . and as i studied more , my faith in the rapture quickly faded . my fears were relieved . but not everyone has come to this conclusion . many , especially today in america , still live under the belief that at any moment jesus will come back and suck all the " true christians " up into the sky and leave the rest of humanity on earth to suffer great tribulation . and that is why i \' ve written this book . it was a little over a year ago now that i first shared my new - found understanding of the rapture in an article on my website . it quickly became one of the most read i \' ve written . so i realized there was a need out there that i could fill . my story is not an isolated one . many others share my experience . it \' s a big deal for me then to know that what i came to discover in my own life might also help someone else in theirs . and perhaps that \' s why you \' ve picked up this book . maybe you have questions about the rapture , maybe what once seemed so clear no longer seems that way anymore . i hope my story and the conclusions i \' ve come to will help you leave the rapture behind for good . i know firsthand what it \' s like to give up the pessimistic rapture and see god \' s hopeful end . to have hope for the future , to know that the world will be reborn and not destroyed . i know the joy i felt when i finally left the rapture behind . i hope to share that relief with everyone i can . what you believe about the end matters . it matters because it changes how you live right now , and what sort of life you build for tomorrow . i present here ten reasons why the rapture must be " left behind " . i know not everyone will be convinced , and i \' m sure in such a short book there will be many unanswered'
10.0.2.18: [1015, 1011, 8840, 4571, 12952, 9541, 4143, 7409, 1010, 2053, 9509, 2011, 23564, 8458, 16207, 6643, 7231, 4430, 9385, 2286, 2405, 2011, 23564, 8458, 16207, 6643, 7231, 4430, 1006, 1062, 2361, 1007, 2012, 25151, 18877, 1024, 7592, 1012, 2083, 2643, 1005, 1055, 4519, 1010, 23564, 8458, 16207, 6643, 7231, 4430, 1006, 2643, 3268, 1998, 8847, 1007, 2003, 2023, 8840, 4571, 12952, 9541, 4143, 7409, 1010, 2033, 1012, 1006, 5487, 10790, 1024, 2322, 1007, 1000, 2005, 2009, 2003, 2025, 6300, 2008, 3713, 1010, 2021, 1996, 4382, 1997, 2115, 2269, 2029, 3713, 11031, 1999, 2017, 1012, 1000, 8840, 4571, 12952, 9541, 4143, 7409, 2003, 2995, 1998, 11633, 1012, 2272, 2247, 2007, 2033, 1010, 2004, 1045, 2425, 2017, 1037, 2261, 8840, 4571, 12952, 9541, 4143, 16507, 2015, 9605, 2026, 2166, 1012, 2108, 6628, 1998, 8546, 2011, 2643, 1005, 1055, 4382, 1010, 14488, 2010, 2097, 2022, 11633, 2135, 2864, 1999, 1998, 2083, 2023, 2147, 1012, 2089, 2010, 3606, 1010, 19556, 2791, 1010, 11633, 2791, 1010, 3425, 1010, 8673, 1010, 2293, 1998, 4519, 2022, 3929, 6913, 2000, 1996, 8489, 1010, 8294, 1998, 13301, 1997, 2256, 2643, 1998, 2269, 1010, 2010, 2365, 4441, 4828, 1010, 1998, 2010, 4151, 4382, 2306, 2149, 1012, 1006, 22728, 2620, 2475, 1024, 1020, 1007, 1000, 1045, 2031, 2056, 1010, 6300, 2024, 5932, 1025, 1998, 2035, 1997, 2017, 2024, 2336, 1997, 1996, 2087, 2152, 1012, 1000, 2795, 1997, 4180, 1024, 1015, 1011, 2773, 2373, 1016, 1011, 2466, 4622, 1017, 1011, 2256, 2269, 1018, 1011, 5454, 2166, 1019, 1011, 2643, 1996, 4151, 4382, 1020, 1011, 3606, 2921, 3647, 1021, 1011, 3950, 4142, 1022, 1011, 4752, 1010, 3246, 1998, 2293, 1023, 1011, 2713, 1998, 4335, 2184, 1011, 2894, 2340, 1011, 4301, 2260, 1011, 4000, 2410, 1011, 2767, 2403, 1011, 2147, 2321, 1011, 16724, 2385, 1011, 3256, 2459, 1011, 28496, 2324, 1011, 5223, 4763, 2539, 1011, 4458, 1997, 1996, 2154, 2322, 1011, 3959, 2538, 1011, 2159, 2570, 1011, 15514, 2603, 1011, 14522, 2484, 1011, 3252, 2423, 1011, 26881, 2656, 1011, 2166, 2676, 1011, 9866, 2654, 1011, 2048, 2021, 2028, 2756, 1011, 12611, 24297, 2382, 1011, 3233, 13399, 8163, 1024, 3967, 1024, 18850, 6079, 2184, 1045, 2097, 6551, 2128, 5558, 6610, 1999, 1996, 2935, 1010, 2026, 3969, 4618, 2022, 6569, 3993, 1999, 2026, 2643, 1025, 2005, 2002, 6045, 2232, 24963, 2033, 2007, 1996, 21902, 1997, 12611, 1010, 2002, 6045, 2232, 3139, 2033, 2007, 1996, 11111, 1997, 19556, 2791, 1010, 2004, 1037, 8959, 16523, 17650, 5877, 11031, 2370, 2007, 24005, 1010, 1998, 2004, 1037, 8959, 4748, 23846, 2705, 2841, 2007, 2014, 15565, 1012, 2340, 2005, 2004, 1996, 3011, 3288, 11031, 5743, 2014, 13007, 1010, 1998, 2004, 1996, 3871, 3426, 2705, 1996, 2477, 2008, 2024, 2061, 7962, 1999, 2009, 2000, 3500, 5743, 1025, 2061, 1996, 2935, 2643, 2097, 3426, 19556, 2791, 1998, 8489, 2000, 3500, 5743, 2077, 2035, 1996, 3741, 1012, 2198, 1017, 1022, 1996, 3612, 6271, 11031, 2073, 2009, 2862, 11031, 1010, 1998, 15223, 2963, 4355, 1996, 2614, 21739, 1010, 2021, 18484, 2102, 2025, 2425, 2043, 3401, 2009, 15699, 2232, 1010, 1998, 1059, 16584, 5886, 2009, 2175, 11031, 1024, 2061, 2003, 2296, 2028, 2008, 2003, 2141, 1997, 1996, 4382, 1012, 10900, 1019, 1015, 3568, 2108, 15123, 2011, 4752, 1010, 2057, 2031, 3521, 2007, 2643, 2083, 2256, 2935, 4441, 4828, 1012, 1015, 1011, 2773, 2373, 2011, 1024, 1062, 2361, 2616, 9375, 2070, 4301, 1010, 4784, 1012, 2616, 4671, 6699, 1010, 5346, 1012, 2616, 3749, 14954, 3861, 5328, 1012, 2616, 2681, 1037, 2261, 1997, 2068, 1010, 2022, 7606, 2098, 1012, 2616, 3443, 2529, 4668, 1012, 2616, 17708, 6567, 1012, 2302, 2616, 1010, 2000, 5009, 1998, 3622, 2057, 2052, 2074, 2022, 1010, 2041, 1997, 6123, 1012, 8840, 4571, 12952, 9541, 4143, 2003, 2019, 9313, 2030, 5866, 2518, 1010, 2711, 1010, 2030, 2724, 1025, 2019, 11813, 2742, 2030, 6013, 1012, 1006, 16948, 1007, 1996, 3800, 1997, 2023, 2338, 2003, 2000, 16636, 3246, 1998, 2000, 15470, 4441, 1005, 3094, 1010, 1006, 5487, 2629, 1024, 2385, 1007, 1000, 2292, 2115, 2422, 2061, 12342, 2077, 2273, 1010, 2008, 2027, 2089, 2156, 2115, 2204, 2573, 1010, 1998, 1043, 10626, 8757, 2115, 2269, 2029, 2003, 1999, 6014, 1012, 1000, 2023, 2166, 1998, 2338, 2024, 4056, 2000, 1996, 9338, 1997, 2068, 2119, 1024, 2069, 2011, 2010, 4519, 2024, 2027, 2081, 2825, 1012, 1006, 5355, 2487, 1024, 4261, 1007, 1000, 1012, 1012, 1012, 2005, 2007, 2643, 2035, 2477, 2024, 2825, 1012, 1000, 1000, 3606, 2003, 7985, 2084, 4349, 1010, 2021, 2009, 2003, 2138, 4349, 2003, 14723, 2000, 6293, 2000, 12020, 1025, 3606, 3475, 1005, 1056, 1012, 1000, 1006, 2928, 24421, 1007, 1006, 4958, 15689, 7066, 2549, 1024, 2410, 1007, 1000, 6229, 2057, 2035, 2272, 1999, 1996, 8499, 1997, 1996, 4752, 1010, 1998, 1997, 1996, 3716, 1997, 1996, 2365, 1997, 2643, 1010, 19662, 1037, 3819, 2158, 1010, 19662, 1996, 5468, 1997, 1996, 21120, 1997, 1996, 2440, 2791, 1997, 4828, 1024, 1000, 2077, 1045, 2211, 2000, 4339, 1010, 1045, 2018, 1037, 3959, 2073, 2619, 2003, 4760, 1037, 2450, 1010, 2019, 10828, 1012, 2044, 3752, 2009, 2016, 2758, 1010, 1000, 1996, 2878, 26803, 2003, 15315, 7974, 2098, 999, 1000, 12447, 1010, 1045, 2246, 2039, 26803, 1998, 2179, 2008, 26803, 2003, 1996, 2817, 1997, 1996, 4761, 1997, 2616, 1998, 1996, 26803, 1997, 1037, 2773, 2003, 2049, 12158, 2381, 1012, 1045, 2253, 2006, 2000, 1005, 2298, 2039, 1005, 15315, 7974, 2098, 1998, 2179, 2009, 2000, 2812, 1005, 1037, 5573, 2689, 1997, 3257, 2030, 2597, 1010, 1037, 9792, 2030, 2735, 1012, 1005, 5870, 2135, 1010, 1045, 5382, 2119, 1010, 2026, 2516, 1998, 2338, 2024, 3802, 24335, 10091, 2135, 15315, 7974, 2098, 1012, 8840, 4571, 12952, 9541, 4143, 1010, 1037, 4659, 2047, 2773, 1010, 2038, 2042, 2109, 2144, 2889, 2005, 1996, 2171, 1997, 1037, 3074, 1997, 9426, 2189, 2108, 3421, 2083, 2367, 4996, 1999, 2028, 3295, 1012, 1996, 3574, 1997, 8840, 4571, 12952, 9541, 4143, 1999, 1996, 3784, 21435, 9206, 2003, 1005, 1037, 8150, 1010, 2030, 18414, 19661, 1997, 2477, 1010, 2035, 6908, 2362, 1012, 1005, 2429, 2000, 1996, 2616, 16700, 1012, 7327, 9206, 1010, 8840, 4571, 12952, 9541, 4143, 2003, 2019, 11900, 15156, 3574, 1005, 2019, 5151, 1010, 6034, 1010, 2030, 25506, 2742, 1997, 2049, 2785, 1012, 1005, 16948, 1005, 1055, 26803, 2930, 1010, 2758, 2008, 8840, 4571, 12952, 9541, 4143, 2003, 1005, 2019, 9313, 2030, 5866, 2518]
10.0.2.18: b'1 - lollapalooza witness , no consequence by zaphnath paaneah copyright 2013 published by zaphnath paaneah ( zp ) at smashwords prologue : hello . through god \' s grace , zaphnath paaneah ( god lives and speaks ) is this lollapalooza witness , me . ( matthew10 : 20 ) " for it is not ye that speak , but the spirit of your father which speaketh in you . " lollapalooza witness is true and faithful . come along with me , as i tell you a few lollapalooza coincidences comprising my life . being encouraged and guided by god \' s spirit , praying his will be faithfully performed in and through this work . may his truth , righteousness , faithfulness , justice , mercy , love and grace be fully displayed to the praise , glory and blessing of our god and father , his son jesus christ , and his holy spirit within us . ( psalm82 : 6 ) " i have said , ye are gods ; and all of you are children of the most high . " table of content : 1 - word power 2 - story remembered 3 - our father 4 - choose life 5 - god the holy spirit 6 - truth kept safe 7 - buried alive 8 - faith , hope and love 9 - release and relief 10 - alone 11 - thoughts 12 - tears 13 - friend 14 - work 15 - enlightenment 16 - ice 17 - eater 18 - hate evil 19 - passing of the day 20 - dream 21 - eyes 22 - refined 23 - persecution 24 - structure 25 - cynical 26 - life 27 - wisdom 28 - two but one 29 - salvation epilogue 30 - stand acknowledgements : contact : isaiah 61 10 i will greatly rejoice in the lord , my soul shall be joyful in my god ; for he hath clothed me with the garments of salvation , he hath covered me with the robe of righteousness , as a bridegroom decketh himself with ornaments , and as a bride adorneth herself with her jewels . 11 for as the earth bringeth forth her bud , and as the garden causeth the things that are sown in it to spring forth ; so the lord god will cause righteousness and praise to spring forth before all the nations . john 3 8 the wind bloweth where it listeth , and thou hearest the sound thereof , but canst not tell whence it cometh , and whither it goeth : so is every one that is born of the spirit . romans 5 1 therefore being justified by faith , we have peace with god through our lord jesus christ . 1 - word power by : zp words define some thoughts , ideas . words express emotions , feelings . words offer vivid picture views . words leave a few of them , bemused . words create human reaction . words manipulate decisions . without words , to guide and direct we would just be , out of context . lollapalooza is an extraordinary or unusual thing , person , or event ; an exceptional example or instance . ( wikipedia ) the purpose of this book is to convey hope and to obey jesus \' command , ( matthew5 : 16 ) " let your light so shine before men , that they may see your good works , and glorify your father which is in heaven . " this life and book are dedicated to the maker of them both : only by his grace are they made possible . ( luke1 : 37 ) " . . . for with god all things are possible . " " truth is stranger than fiction , but it is because fiction is obliged to stick to possibilities ; truth isn \' t . " ( mark twain ) ( ephesians4 : 13 ) " till we all come in the unity of the faith , and of the knowledge of the son of god , unto a perfect man , unto the measure of the stature of the fullness of christ : " before i began to write , i had a dream where someone is showing a woman , an autobiography . after reading it she says , " the whole etymology is skewed ! " waking , i looked up etymology and found that etymology is the study of the origin of words and the etymology of a word is its linguistic history . i went on to \' look up \' skewed and found it to mean \' a sudden change of direction or position , a twist or turn . \' laughingly , i realize both , my title and book are etymologically skewed . lollapalooza , a relatively new word , has been used since 1991 for the name of a collection of varied music being represented through different bands in one location . the meaning of lollapalooza in the online slang dictionary is \' a mixture , or jumble of things , all thrown together . \' according to the wordsense . eu dictionary , lollapalooza is an informal noun meaning \' an outstanding , extreme , or outrageous example of its kind . \' wikipedia \' s etymology section , says that lollapalooza is \' an extraordinary or unusual thing'
10.0.2.18: [2184, 2062, 3441, 2011, 12305, 8840, 17791, 9385, 1075, 2325, 2011, 12305, 1043, 1012, 8840, 17791, 2035, 2916, 9235, 1012, 2023, 2338, 2030, 2151, 4664, 21739, 2089, 2025, 2022, 22296, 2030, 2109, 1999, 2151, 5450, 18971, 2302, 1996, 4671, 2517, 6656, 1997, 1996, 6674, 3272, 2005, 1996, 2224, 1997, 4766, 20563, 9285, 1999, 1037, 2338, 3319, 1012, 2022, 2469, 2000, 4638, 2041, 2026, 9927, 2073, 1045, 2695, 1037, 2843, 1997, 2460, 3441, 1998, 2060, 2477, 1024, 1026, 8299, 1024, 1013, 1013, 13109, 11020, 10128, 2072, 1012, 23012, 11008, 1012, 4012, 1013, 1028, 8417, 12436, 5302, 9232, 2043, 1996, 16985, 4305, 24170, 2015, 2234, 2027, 2056, 2009, 2001, 1037, 5119, 24581, 13888, 1996, 2034, 4796, 3224, 1997, 1996, 11541, 5325, 2601, 19918, 1996, 24018, 1996, 3897, 7600, 12436, 5302, 9232, 1045, 2123, 1005, 1056, 2066, 2023, 2103, 1010, 1045, 2123, 1005, 1056, 2066, 12783, 1998, 1045, 5791, 2123, 1005, 1056, 2066, 2108, 2648, 2012, 2305, 1999, 1037, 2173, 2066, 2023, 1012, 2035, 1996, 29526, 1997, 2554, 2024, 2041, 1998, 2055, 1998, 2619, 2004, 3671, 2004, 2033, 2074, 2515, 2025, 7141, 1012, 1045, 2074, 2031, 2070, 2449, 2008, 3791, 11121, 2000, 1012, 2122, 4534, 2012, 2305, 2024, 2066, 1996, 5409, 3033, 1997, 2529, 2139, 6914, 6906, 5666, 5507, 2039, 2066, 7136, 1012, 2017, 2288, 2115, 3671, 4319, 1011, 16743, 1998, 20833, 2076, 1996, 2154, 1010, 2021, 2012, 2305, 2027, 2763, 4468, 2023, 2173, 2205, 1012, 2017, 2453, 2228, 2009, 1005, 1040, 2022, 5875, 2065, 2017, 9554, 13886, 2006, 2037, 4037, 2021, 2108, 1999, 1996, 12930, 2005, 2613, 2003, 2074, 2205, 2172, 1012, 2045, 1005, 1055, 1037, 3124, 1999, 1037, 2327, 6045, 1998, 5495, 1010, 1998, 2498, 2842, 1010, 2010, 2227, 2003, 4993, 2066, 1037, 6548, 1012, 2002, 1005, 1055, 5613, 1999, 7925, 2004, 2065, 2002, 1005, 1055, 2667, 2000, 2191, 2370, 14849, 1012, 2058, 2045, 2003, 1037, 2450, 1999, 1037, 2156, 1011, 2083, 9065, 1010, 4147, 2498, 2021, 2152, 1011, 8265, 1010, 2019, 9140, 1997, 5200, 2006, 1037, 2235, 2795, 1999, 2392, 1997, 2014, 1012, 2005, 1037, 2235, 7408, 2016, 1005, 2222, 2404, 2006, 1037, 1000, 2265, 1000, 2005, 2017, 1012, 1045, 2562, 3788, 1010, 2559, 3442, 3805, 1012, 2045, 2003, 1037, 5294, 2158, 3788, 3805, 1997, 2033, 1010, 2010, 2067, 2003, 2019, 4816, 4908, 1012, 4871, 3048, 2105, 1010, 6475, 1010, 2130, 2440, 2678, 1012, 2010, 2972, 5041, 2067, 2003, 2028, 2502, 27159, 2098, 4942, 1011, 4315, 9067, 2419, 3898, 1012, 1045, 4797, 2116, 2111, 1999, 1996, 4306, 2024, 4699, 1999, 19300, 1011, 4982, 1010, 2053, 3043, 2129, 4264, 13675, 10696, 2009, 1012, 2633, 1045, 3962, 1996, 2210, 3347, 1010, 2559, 2041, 1997, 2173, 2302, 16231, 5751, 1998, 2678, 7923, 1010, 2471, 2246, 2701, 1012, 1045, 13781, 2503, 1998, 2132, 2000, 1996, 3347, 1012, 1037, 13472, 2158, 2525, 2012, 1996, 3347, 2074, 26663, 2033, 1010, 1996, 5870, 2678, 7412, 2006, 2010, 12170, 3401, 2361, 16826, 2041, 1997, 1996, 2460, 15114, 1012, 1999, 1996, 2067, 1045, 2156, 1037, 4338, 1999, 1996, 2601, 2008, 3504, 2066, 1996, 2711, 1045, 2001, 2182, 2000, 3113, 1012, 1000, 2074, 2507, 2033, 2028, 2522, 1011, 12436, 23228, 1012, 1000, 1045, 2425, 1996, 15812, 2040, 11473, 2015, 2009, 2039, 2855, 1012, 1045, 2202, 1996, 4392, 1998, 2132, 2000, 1996, 2795, 1999, 1996, 2067, 1012, 2002, 2001, 5307, 1996, 2067, 2813, 1998, 2043, 1045, 2938, 2091, 1045, 2052, 2022, 2583, 2000, 2156, 1996, 2878, 3347, 1012, 1000, 2003, 2115, 2171, 5828, 1029, 1000, 1045, 3198, 1012, 2002, 3368, 1012, 2002, 2584, 2046, 2010, 5435, 4979, 1998, 2766, 2041, 1996, 7570, 4135, 1011, 14291, 1998, 4201, 2009, 2006, 1996, 2795, 1012, 2002, 1005, 1055, 1996, 1005, 2292, 1005, 1055, 2074, 2131, 2023, 2589, 1005, 2828, 1012, 1000, 1045, 2215, 2438, 1040, 2615, 2000, 2131, 2083, 1996, 14684, 2618, 1012, 1000, 1045, 2360, 2000, 2032, 1012, 1000, 2064, 1005, 1056, 4872, 9542, 1010, 2295, 1012, 2017, 2202, 2054, 2017, 2064, 2131, 1012, 2065, 2017, 2215, 2205, 2172, 1010, 2017, 1005, 2222, 2196, 2131, 2125, 1996, 2598, 1012, 1000, 2002, 2056, 1999, 1037, 2784, 3759, 2100, 2376, 1012, 1045, 2298, 2000, 1996, 2187, 1998, 4897, 2026, 2159, 1010, 5828, 2001, 9391, 2066, 2026, 3611, 1012, 1045, 2359, 2125, 2023, 6517, 1010, 28353, 22208, 3560, 2088, 1012, 2045, 2020, 2111, 2041, 2045, 4855, 2608, 1998, 3456, 2000, 2064, 3490, 10264, 2015, 2043, 2027, 2743, 2041, 1997, 5271, 1011, 2583, 11595, 1010, 2005, 6933, 2041, 5189, 1012, 2045, 2001, 2053, 2746, 2067, 2013, 2023, 5357, 3226, 1010, 10585, 2006, 2023, 4774, 2001, 2757, 1012, 1045, 2734, 2000, 2131, 2000, 2028, 1997, 1996, 8355, 1010, 1045, 2134, 1005, 1056, 2729, 2129, 10968, 2027, 2020, 1012, 1045, 2736, 1996, 4392, 2044, 5828, 2165, 1996, 2769, 1998, 2150, 2908, 1012, 1045, 2701, 2026, 2159, 1998, 5632, 1996, 2757, 7406, 1997, 1996, 5177, 3255, 1012, 3773, 1037, 2554, 5996, 2013, 2503, 2001, 2025, 3733, 1010, 1998, 2096, 1045, 2134, 1005, 1056, 2729, 2055, 2122, 2111, 1045, 2106, 2729, 2005, 1996, 2427, 1012, 2044, 2009, 5078, 2125, 2438, 2005, 2033, 2000, 2994, 12042, 1045, 2681, 2000, 2132, 2067, 2000, 1996, 9350, 1011, 4920, 14901, 1012, 1045, 8568, 1996, 29213, 8917, 2100, 1999, 1996, 2395, 1010, 1996, 6745, 13675, 10936, 2063, 2027, 2170, 1000, 23488, 8197, 17305, 1000, 1012, 2320, 1045, 3362, 1996, 14901, 1998, 2357, 2006, 2070, 2189, 2000, 19549, 2041, 1996, 22255, 14950, 2013, 1996, 2279, 2282, 1045, 2165, 1996, 7570, 4135, 1011, 14291, 1998, 4201, 2009, 2006, 1037, 2795, 2327, 1012, 1045, 8878, 2009, 2007, 2026, 7223, 1011, 4012, 2361, 1998, 1037, 6706, 5460, 1997, 2951, 2596, 1999, 1996, 2250, 2682, 2009, 1012, 2059, 2045, 2001, 2019, 3746, 1997, 1037, 2235, 1010, 13174, 2176, 1011, 2158, 2911, 1012, 2009, 2001, 2214, 1012, 2028, 1997, 1996, 6388, 4275, 1999, 1996, 2220, 2420, 1997, 3653, 1011, 2422, 1012, 2045, 2001, 2053, 27124, 1010, 2053, 27998, 2030, 5527, 1012, 2009, 2001, 2074, 1037, 2176, 1011, 2835, 10338, 1011, 6770, 1998, 5209, 1012, 2009, 2052, 2031, 2000, 2147, 2144, 2009, 2001, 2035, 1045, 2071, 8984, 1012, 4606, 1010, 2009, 2001, 2025, 5068, 1012, 1037, 2911, 2008, 2235, 2052, 2022, 5457, 2005, 1037, 10382, 2013, 2028, 1997, 1996, 3469, 3719, 2030, 2013, 1996, 4651, 2276, 2993, 1012, 2009, 2001, 2235, 1998, 2422, 2438, 2000, 7540, 2046]
10.0.2.18: b'10 more stories by floyd looney copyright \xc2\xa9 2015 by floyd g . looney all rights reserved . this book or any portion thereof may not be reproduced or used in any manner whatsoever without the express written permission of the publisher except for the use of brief quotations in a book review . be sure to check out my blog where i post a lot of short stories and other things : < http : / / flscifi . blogspot . com / > contents vamoose when the tardigrades came they said it was a clock skyscraper archipelago the first gate forest of the genres crisis dark envoy the keepers the gray tigers vamoose i don \' t like this city , i don \' t like crowds and i definitely don \' t like being outside at night in a place like this . all the freaks of society are out and about and someone as normal as me just does not belong . i just have some business that needs tended to . these streets at night are like the worst parts of human degeneracy lit up like vegas . you got your normal drug - dealers and prostitutes during the day , but at night they probably avoid this place too . you might think it \' d be interesting if you accidentally clicked on their website but being in the midst for real is just too much . there \' s a guy in a top hat and tie , and nothing else , his face is painted like a devil . he \' s dancing in circles as if he \' s trying to make himself dizzy . over there is a woman in a see - through booth , wearing nothing but high - heels , an array of objects on a small table in front of her . for a small fee she \' ll put on a " show " for you . i keep walking , looking straight ahead . there is a massive man walking ahead of me , his back is an electronic billboard . images moving around , advertising , even full video . his entire broad back is one big implanted sub - dermal led screen . i doubt many people in the crowd are interested in vita - grow , no matter how plants crave it . finally i spot the little bar , looking out of place without neon signs and video boards , almost looked closed . i ducked inside and head to the bar . a muscular man already at the bar just ignores me , the laughing video skull on his bicep poked out of the short sleeves . in the back i see a shape in the dark that looks like the person i was here to meet . " just give me one co - va mixer . " i tell the bartender who whips it up quickly . i take the drink and head to the table in the back . he was facing the back wall and when i sat down i would be able to see the whole bar . " is your name carlos ? " i ask . he nodded . he reached into his coat pocket and pulled out the holo - cube and laid it on the table . he \' s the \' let \' s just get this done \' type . " i want enough dv to get through the chute . " i say to him . " can \' t promise luxury , though . you take what you can get . if you want too much , you \' ll never get off the ground . " he said in a deep throaty voice . i look to the left and roll my eyes , carlos was sounding like my dad . i wanted off this sad , cadaverous world . there were people out there selling arms and legs to cannibals when they ran out of sell - able organs , for crying out loud . there was no coming back from this fallen culture , civilization on this planet was dead . i needed to get to one of the colonies , i didn \' t care how primitive they were . i finished the drink after carlos took the money and became gone . i closed my eyes and enjoyed the deadening of the mental pain . seeing a society dying from inside was not easy , and while i didn \' t care about these people i did care for the species . after it wore off enough for me to stay balanced i leave to head back to the rat - hole motel . i ignore the impromptu orgy in the street , the latest craze they called " caterpillar " . once i reach the motel and turned on some music to drown out the banging noises from the next room i took the holo - cube and laid it on a table top . i activated it with my wrist - comp and a steady stream of data appeared in the air above it . then there was an image of a small , rusty four - man ship . it was old . one of the experimental models in the early days of pre - light . there was no galley , no compartments or storage . it was just a four - seat cock - pit and engines . it would have to work since it was all i could afford . plus , it was not registered . a ship that small would be confused for a shuttle from one of the larger ships or from the transfer station itself . it was small and light enough to slip into'
10.0.2.18: [2023, 2862, 1997, 13747, 3121, 1999, 4021, 6938, 24581, 2015, 2029, 2024, 2012, 2560, 4206, 1012, 1996, 13747, 2311, 1999, 4021, 1006, 1998, 1996, 13747, 1999, 1996, 2088, 1007, 2003, 20934, 2099, 3501, 27925, 1010, 2029, 4832, 2029, 2001, 2441, 2006, 2254, 1018, 1010, 2230, 1999, 11558, 1010, 2142, 5424, 14041, 1012, 3053, 2093, 1011, 7728, 1997, 1996, 2753, 13747, 24581, 2015, 1999, 1996, 2088, 2024, 2284, 1999, 4021, 1012, 2077, 1996, 2810, 8797, 1997, 24581, 2015, 1999, 4021, 2144, 2722, 1010, 2087, 1997, 1996, 13747, 24581, 2015, 2020, 2328, 1999, 2167, 2637, 1012, 2859, 2038, 2328, 5417, 1997, 1996, 13747, 24581, 2015, 1999, 1996, 2088, 1999, 1996, 2197, 3174, 2086, 1012, 1996, 17641, 2038, 2036, 2328, 3365, 24581, 2015, 1999, 1996, 2197, 3174, 2086, 1010, 1998, 1996, 2103, 1997, 11558, 2038, 1996, 2087, 24581, 2015, 1999, 1996, 2327, 5595, 2862, 1012, 1996, 2034, 2862, 2950, 24581, 2015, 2029, 2024, 2593, 2949, 2030, 9370, 2041, 2429, 2000, 14931, 8569, 2232, 9181, 1012, 1996, 2117, 2862, 2216, 3121, 2029, 2024, 3818, 2030, 2104, 2810, 2429, 2000, 14931, 8569, 2232, 9181, 1012, 2023, 2862, 6938, 2949, 2030, 9370, 2041, 3121, 1999, 4021, 2008, 3233, 2012, 2560, 5539, 1049, 1006, 26667, 3027, 1007, 4206, 2429, 2000, 14931, 8569, 2232, 9181, 1012, 3121, 2008, 2031, 2042, 1996, 13747, 1999, 1996, 2088, 2024, 3491, 1999, 7782, 12172, 1012, 2023, 2930, 3397, 2862, 1997, 24581, 2015, 12283, 2084, 2104, 2810, 2030, 3818, 2429, 2000, 14931, 8569, 2232, 9181, 1012, 2023, 2862, 6938, 24581, 2015, 3005, 2810, 2003, 2006, 2907, 2008, 2024, 3740, 2000, 4125, 2058, 3998, 3620, 1006, 5818, 2549, 3027, 1007, 1012]
10.0.2.18: b'this list of tallest buildings in asia ranks skyscrapers which are at least tall . the tallest building in asia ( and the tallest in the world ) is burj khalifa , which stands which was opened on january 4 , 2010 in dubai , united arab emirates . nearly three - quarters of the 50 tallest skyscrapers in the world are located in asia . before the construction boom of skyscrapers in asia since 1997 , most of the tallest skyscrapers were built in north america . china has built fifteen of the tallest skyscrapers in the world in the last twenty years . the uae has also built numerous skyscrapers in the last twenty years , and the city of dubai has the most skyscrapers in the top fifty list . the first list includes skyscrapers which are either completed or topped out according to ctbuh criteria . the second list those buildings which are proposed or under construction according to ctbuh criteria . this list ranks completed or topped out buildings in asia that stand at least 250 m ( 820 ft ) tall according to ctbuh criteria . buildings that have been the tallest in the world are shown in boldface . this section contains list of skyscrapers taller than under construction or proposed according to ctbuh criteria . this list ranks skyscrapers whose construction is on hold that are planned to rise over 300 metres ( 984 ft ) .'
10.0.2.18: [2728, 5070, 12456, 2386, 1006, 2337, 2603, 1010, 4006, 7959, 19892, 24384, 1017, 1010, 25682, 1007, 2001, 2019, 2137, 5160, 1998, 2678, 2208, 3237, 1012, 2002, 2499, 2004, 1037, 5160, 1999, 2899, 1010, 1040, 1012, 1039, 1012, 1998, 2001, 2920, 1999, 1037, 9446, 4193, 1996, 2924, 1997, 4923, 1998, 6236, 2248, 1012, 1999, 2639, 1010, 2002, 1998, 5696, 14077, 2631, 16729, 9581, 2595, 2865, 2004, 1996, 6687, 3173, 2194, 2005, 7014, 2229, 2850, 3730, 9316, 1010, 1037, 2678, 2208, 9722, 14077, 2018, 2631, 3041, 1012, 12456, 2386, 2366, 2004, 16729, 9581, 2595, 2865, 1005, 1055, 2708, 3237, 2961, 1998, 3472, 2127, 2010, 2331, 1012, 2002, 2001, 2036, 1037, 2266, 1997, 1996, 7319, 2604, 1997, 1996, 2577, 2899, 2118, 2375, 2082, 1012, 2728, 5070, 12456, 2386, 2001, 2141, 1999, 2899, 1010, 1040, 1012, 1039, 1012, 1010, 2006, 2337, 2603, 1010, 4006, 1012, 2010, 2269, 1010, 5879, 1055, 1012, 12456, 2386, 1006, 1011, 2722, 1007, 1010, 2001, 1037, 4619, 1997, 5765, 2375, 2082, 1010, 1037, 2613, 3776, 5160, 1998, 14316, 1010, 1037, 2231, 5160, 2076, 1996, 2047, 3066, 1010, 1998, 1037, 2522, 1011, 3910, 1997, 1996, 2375, 3813, 1047, 3217, 14573, 1998, 12456, 2386, 1012, 2010, 2388, 1010, 8234, 1038, 1012, 12456, 2386, 1006, 7663, 6157, 1025, 1011, 2263, 1007, 1010, 2001, 1037, 4619, 1997, 7996, 2375, 2082, 1010, 1037, 2547, 3135, 1010, 1998, 2580, 1996, 2565, 1000, 2009, 1005, 1055, 3834, 1000, 1999, 3777, 1012, 2728, 1037, 1012, 12456, 2386, 2018, 2093, 5208, 1024, 9965, 1054, 1012, 11867, 24449, 3619, 1006, 1011, 2294, 1007, 1010, 6294, 12456, 2386, 1010, 1998, 7912, 12456, 2386, 1012, 2728, 1037, 1012, 12456, 2386, 2001, 2992, 1999, 1996, 6044, 2380, 5101, 1997, 2899, 1010, 1040, 1012, 1039, 1012, 1010, 1998, 3852, 2013, 23954, 4267, 2152, 2082, 1012, 2002, 4663, 1037, 5065, 1005, 1055, 3014, 2012, 1996, 2118, 1997, 5273, 1999, 3380, 1998, 2513, 2000, 1040, 1012, 1039, 1012, 2000, 5463, 2577, 2899, 2118, 2375, 2082, 1010, 7414, 1037, 27551, 3460, 3014, 1999, 3411, 1012, 12456, 2386, 9051, 2375, 2005, 2116, 2086, 1999, 2899, 1010, 1040, 1012, 1039, 1012, 2004, 1037, 4256, 1997, 5215, 13894, 1010, 1037, 2280, 2142, 2163, 3187, 1997, 3639, 1999, 1996, 2375, 3813, 1997, 13894, 1998, 11582, 3489, 1012, 12456, 2386, 2101, 2441, 2010, 2219, 2375, 3813, 1010, 1996, 2375, 4822, 1997, 2728, 12456, 2386, 2073, 13894, 2001, 1997, 9517, 1012, 2004, 1037, 2899, 1010, 1040, 1012, 1039, 1012, 5160, 1010, 12456, 2386, 3421, 2350, 3316, 2077, 2976, 10738, 6736, 1010, 2077, 3519, 1010, 2030, 1999, 15382, 1012, 2013, 3301, 2000, 3196, 1010, 12456, 2386, 1998, 13894, 3421, 1037, 2177, 1997, 7272, 5424, 17353, 1010, 2164, 2372, 1997, 1996, 2548, 2155, 2013, 8273, 23153, 1998, 8174, 9264, 1999, 2037, 4073, 2000, 9878, 1037, 4800, 1011, 2110, 2924, 3173, 2194, 1010, 3361, 2236, 5085, 8167, 2229, 1012, 1996, 5424, 9387, 2109, 1037, 2329, 2924, 1010, 2924, 1997, 4923, 1998, 6236, 2248, 1006, 4647, 6895, 1007, 2004, 2037, 3361, 8619, 1999, 2023, 12598, 1012, 2206, 1996, 7654, 1010, 12456, 2386, 2150, 2343, 1997, 3361, 2236, 2029, 2001, 4096, 2034, 2137, 3840, 1012, 1999, 2889, 1010, 2009, 2001, 6884, 2008, 4647, 6895, 1010, 1996, 3361, 11747, 2000, 1996, 5424, 15337, 1998, 2037, 1000, 4806, 4957, 1000, 2018, 3734, 2011, 2965, 1997, 12195, 10940, 2008, 2020, 1999, 12398, 1010, 1996, 6661, 1997, 1996, 5424, 9387, 1999, 2034, 2137, 1012, 3980, 2020, 2992, 3251, 1996, 5424, 9387, 2018, 23123, 3421, 2000, 2924, 25644, 1996, 2995, 6095, 1997, 2034, 2137, 1012, 2076, 1996, 13831, 9751, 1010, 12456, 2386, 1998, 13894, 14914, 2012, 3091, 2077, 3519, 1010, 2976, 1998, 2110, 2882, 18414, 5134, 1010, 1998, 1996, 2976, 3914, 1012, 15727, 2015, 1997, 2034, 2137, 2011, 1996, 2976, 3914, 1010, 2436, 1997, 1996, 4012, 13876, 26611, 1010, 1998, 2110, 8169, 6736, 4484, 2008, 1996, 2924, 2018, 2042, 3498, 2104, 12456, 2386, 1005, 1055, 2968, 2302, 2151, 4647, 6895, 3747, 1012, 1999, 2826, 1010, 13894, 1998, 12456, 2386, 2020, 5338, 1999, 24265, 2015, 2011, 1996, 2047, 2259, 2212, 4905, 1998, 1996, 2533, 1997, 3425, 1010, 2004, 2092, 2004, 2108, 2315, 1999, 1037, 2942, 4848, 2011, 1996, 2976, 3914, 1012, 13894, 1010, 2059, 1999, 3532, 2740, 1010, 2001, 16574, 2013, 1996, 2553, 2004, 2002, 2001, 8186, 4039, 2000, 2175, 2000, 3979, 1012, 12456, 2386, 5224, 2010, 12660, 1010, 4188, 4107, 1997, 1037, 14865, 2000, 10663, 1996, 3572, 1010, 1998, 7278, 2006, 2183, 2000, 3979, 1012, 1999, 1996, 2621, 1997, 2857, 1010, 2044, 1037, 2274, 1011, 3204, 3979, 1010, 1996, 2457, 7219, 1996, 2430, 4175, 1999, 1996, 24265, 1997, 27748, 1010, 3038, 2053, 3350, 2018, 2042, 3591, 2011, 1996, 2231, 2000, 2490, 2009, 1012, 12456, 2386, 6430, 2000, 2556, 1037, 3639, 2553, 1998, 2001, 18538, 2011, 1996, 6467, 1997, 2035, 3588, 5571, 1012, 1996, 2533, 1997, 3425, 7219, 1996, 7452, 2976, 24265, 1012, 1996, 2942, 4848, 2011, 1996, 2976, 3914, 2001, 3876, 2007, 12456, 2386, 16191, 2000, 2022, 7917, 8642, 2013, 8169, 1012, 2002, 2001, 8047, 2011, 1037, 3297, 2317, 1011, 9127, 4735, 3639, 5160, 27973, 10625, 1012, 2044, 1996, 4647, 6895, 3979, 1010, 12456, 2386, 7943, 2010, 2899, 1010, 1040, 1012, 1039, 1012, 3423, 3218, 1012, 1999, 2639, 1010, 2002, 2522, 1011, 2631, 16729, 9581, 2595, 2865, 2007, 7014, 2229, 2850, 3730, 9316, 3910, 5696, 14077, 2004, 1037, 2047, 6687, 2194, 1997, 7014, 2229, 2850, 1012, 12456, 2386, 2001, 2716, 1999, 2004, 5766, 2007, 14077, 3529, 2004, 14931, 2080, 1012, 14077, 2001, 3724, 2041, 1997, 2019, 6515, 2535, 1999, 2526, 1010, 1998, 2002, 6406, 1037, 3141, 9870, 2008, 2001, 3876, 2041, 1997, 2457, 1012, 12456, 2386, 2108, 1996, 4256, 1997, 5215, 13894, 2109, 2010, 7264, 2004, 1037, 5160, 2000, 9991, 16729, 9581, 2595, 1005, 1055, 7319, 2604, 2007, 2107, 2152, 6337, 2576, 4481, 2066, 6609, 22432, 15859, 16020, 1010, 2577, 1046, 1012, 6395, 1998, 4116, 24873, 28061, 2007, 22432, 15859, 16020, 1998, 6395, 5241, 1996, 7319, 2604, 1999, 2456, 2096, 24873, 28061, 2587, 1999, 2541, 1012, 12456, 2386, 2001, 3644, 1012, 2006, 2254, 2756, 1010, 3118, 1010, 2002, 2496, 2280, 1000, 4687, 2450, 1000, 3883, 1048, 6038, 2850, 5708, 1012, 2362, 2027, 2018, 2048, 2336, 1010, 2508, 1998, 8201, 12456, 2386, 1012, 2027, 2973, 1999, 18854, 1010, 5374, 1012, 2508, 12456, 2386, 2573, 2012, 2010, 2269, 1005]
10.0.2.18: b'robert alan altman ( february 23 , 1947february 3 , 2021 ) was an american lawyer and video game executive . he worked as a lawyer in washington , d . c . and was involved in a scandal surrounding the bank of credit and commerce international . in 1999 , he and christopher weaver founded zenimax media as the parent holding company for bethesda softworks , a video game developer weaver had founded earlier . altman served as zenimax media \' s chief executive officer and chairman until his death . he was also a member of the advisory board of the george washington university law school . robert alan altman was born in washington , d . c . , on february 23 , 1947 . his father , norman s . altman ( - 1997 ) , was a graduate of harvard law school , a real estate lawyer and investor , a government lawyer during the new deal , and a co - founder of the law firm krooth and altman . his mother , sophie b . altman ( nee robinson ; - 2008 ) , was a graduate of yale law school , a television producer , and created the program " it \' s academic " in 1961 . robert a . altman had three sisters : janet r . spragens ( - 2006 ) , susan altman , and nancy altman . robert a . altman was raised in the cleveland park neighborhood of washington , d . c . , and graduated from woodrow wilson high school . he obtained a bachelor \' s degree at the university of wisconsin in 1968 and returned to d . c . to attend george washington university law school , earning a juris doctor degree in 1971 . altman practiced law for many years in washington , d . c . as a partner of clark clifford , a former united states secretary of defense in the law firm of clifford and warnke . altman later opened his own law firm , the law offices of robert altman where clifford was of counsel . as a washington , d . c . lawyer , altman represented major companies before federal regulatory agencies , before congress , or in litigation . from 1978 to 1982 , altman and clifford represented a group of wealthy arab businessmen , including members of the royal family from abu dhabi and saudi arabia in their efforts to acquire a multi - state bank holding company , financial general bankshares . the arab investors used a british bank , bank of credit and commerce international ( bcci ) as their financial advisor in this transaction . following the acquisition , altman became president of financial general which was renamed first american corporation . in 1991 , it was alleged that bcci , the financial adviser to the arab shareholders and their " communications link " had acquired by means of offshore loans that were in default , the shares of the arab investors in first american . questions were raised whether the arab investors had falsely represented to bank regulators the true ownership of first american . during the ensuing investigations , altman and clifford testified at length before congress , federal and state grand juries , and the federal reserve . audits of first american by the federal reserve , office of the comptroller , and state banking agencies confirmed that the bank had been operated under altman \' s management without any bcci influence . in 1992 , clifford and altman were charged in indictments by the new york district attorney and the department of justice , as well as being named in a civil suit by the federal reserve . clifford , then in poor health , was severed from the case as he was physically unable to go to trial . altman maintained his innocence , refused offers of a plea to resolve the cases , and insisted on going to trial . in the summer of 1993 , after a five - month trial , the court dismissed the central count in the indictment of bribery , saying no evidence had been presented by the government to support it . altman declined to present a defense case and was acquitted by the jury of all remaining charges . the department of justice dismissed the companion federal indictment . the civil suit by the federal reserve was settled with altman agreeing to be banned permanently from banking . he was defended by a famous white - collar criminal defense lawyer gustave newman . after the bcci trial , altman resumed his washington , d . c . legal practice . in 1999 , he co - founded zenimax media with bethesda softworks founder christopher weaver as a new parent company of bethesda . altman was brought in as ceo with weaver serving as cto . weaver was pushed out of an operational role in 2002 , and he filed a related lawsuit that was settled out of court . altman being the partner of clark clifford used his connections as a lawyer to stack zenimax \' s advisory board with such high profile political figures like terry mcauliffe , george j . mitchell and tony coelho with mcauliffe and mitchell joining the advisory board in 2000 while coelho joined in 2001 . altman was jewish . on january 29 , 1984 , he married former " wonder woman " actress lynda carter . together they had two children , james and jessica altman . they lived in potomac , maryland . james altman works at his father \''
10.0.2.18: [1999, 1996, 10867, 7716, 18279, 22924, 1010, 1037, 3558, 3200, 2003, 2151, 3200, 2008, 2003, 2033, 28329, 1010, 1998, 3005, 3643, 5577, 1037, 2110, 1997, 1037, 3558, 2291, 1012, 1996, 10867, 7716, 18279, 7712, 5144, 2024, 4225, 2004, 8281, 2838, 1997, 1037, 2291, 1010, 5214, 1997, 20648, 2075, 1996, 2291, 1005, 1055, 2110, 1012, 2070, 5377, 2015, 1010, 2107, 2004, 1996, 7812, 3806, 5377, 1010, 1010, 2079, 2025, 6235, 1996, 2110, 1997, 1037, 2291, 1010, 1998, 2061, 2024, 2025, 5144, 1012, 2006, 1996, 2060, 2192, 1010, 2070, 5377, 2015, 1010, 2107, 2004, 1006, 1996, 12809, 2391, 6245, 5377, 1010, 2030, 5390, 2891, 26461, 5377, 1007, 1010, 12530, 2006, 1996, 4767, 1997, 1037, 9415, 1010, 1998, 2061, 2089, 2022, 2641, 2000, 6235, 1996, 2110, 1997, 1037, 2291, 1010, 1998, 3568, 2089, 2022, 2641, 3558, 5144, 1012, 1000, 3563, 1000, 5144, 2024, 5228, 2006, 1037, 2566, 3742, 3978, 1012, 2065, 1996, 3197, 2020, 2904, 2013, 2566, 3742, 2000, 1010, 2005, 2742, 1010, 2566, 16709, 1010, 1996, 3200, 2052, 3961, 2004, 2009, 2001, 1006, 1045, 1012, 1041, 1012, 1010, 11806, 2030, 4866, 1007, 1012, 2147, 1998, 3684, 2024, 2025, 1996, 10867, 7716, 18279, 7712, 5144, 1010, 2021, 2738, 1000, 2832, 12450, 1024, 1000, 6223, 1997, 2943, 2408, 1037, 2291, 6192, 1012, 3001, 2079, 2025, 1000, 5383, 1000, 2147, 1010, 2021, 2064, 1000, 4685, 1000, 2147, 1010, 1998, 10655, 1010, 1999, 5337, 1996, 10867, 7716, 18279, 22924, 1010, 3001, 2079, 2025, 1000, 5383, 1000, 3684, 1010, 2021, 2064, 1000, 4651, 1000, 3684, 1012, 21858, 1010, 2174, 1010, 1037, 4489, 1999, 1996, 2943, 1997, 1037, 2291, 2008, 5158, 9578, 2138, 1997, 1037, 4489, 1999, 2049, 4860, 2003, 4141, 2170, 1000, 3684, 1000, 1010, 1998, 1996, 2943, 2008, 6223, 2408, 1037, 6192, 2004, 1037, 2765, 1997, 1037, 4860, 4489, 2003, 1000, 3684, 1000, 1012, 7998, 1006, 2030, 6678, 1007, 2003, 2788, 2025, 1037, 1996, 10867, 7716, 18279, 7712, 3200, 1012, 7998, 2064, 2393, 20648, 1996, 3295, 1997, 1037, 2291, 1010, 2021, 2008, 2515, 2025, 6235, 1996, 2110, 1997, 1996, 2291, 1012, 2019, 6453, 2052, 2022, 2065, 1996, 3466, 1997, 8992, 2342, 2000, 2022, 2641, 1999, 2344, 2000, 6235, 1037, 2110, 1010, 1999, 2029, 2553, 7998, 2071, 5262, 2022, 1037, 1996, 10867, 7716, 18279, 7712, 3200, 1012]
10.0.2.18: b'in thermodynamics , a physical property is any property that is measurable , and whose value describes a state of a physical system . thermodynamic properties are defined as characteristic features of a system , capable of specifying the system \' s state . some constants , such as the ideal gas constant , , do not describe the state of a system , and so are not properties . on the other hand , some constants , such as ( the freezing point depression constant , or cryoscopic constant ) , depend on the identity of a substance , and so may be considered to describe the state of a system , and therefore may be considered physical properties . " specific " properties are expressed on a per mass basis . if the units were changed from per mass to , for example , per mole , the property would remain as it was ( i . e . , intensive or extensive ) . work and heat are not thermodynamic properties , but rather " process quantities : " flows of energy across a system boundary . systems do not " contain " work , but can " perform " work , and likewise , in formal thermodynamics , systems do not " contain " heat , but can " transfer " heat . informally , however , a difference in the energy of a system that occurs solely because of a difference in its temperature is commonly called " heat " , and the energy that flows across a boundary as a result of a temperature difference is " heat " . altitude ( or elevation ) is usually not a thermodynamic property . altitude can help specify the location of a system , but that does not describe the state of the system . an exception would be if the effect of gravity need to be considered in order to describe a state , in which case altitude could indeed be a thermodynamic property .'
10.0.2.18: [1996, 2299, 2027, 6369, 1012, 1012, 1012, 2043, 4199, 3062, 2003, 1996, 2526, 2834, 2713, 2011, 8839, 1011, 2241, 2137, 3220, 1011, 6009, 9617, 2483, 6395, 1012, 1996, 2201, 2001, 2081, 2076, 1996, 3220, 1005, 1055, 1020, 1011, 3204, 2994, 1999, 5899, 1010, 3146, 1010, 1998, 2001, 2680, 1999, 1037, 2309, 5027, 1012, 2009, 3774, 1997, 6395, 2652, 2014, 6490, 2858, 1998, 4823, 2007, 20288, 2537, 1012, 1996, 2501, 2003, 2747, 2041, 1997, 6140, 1998, 2003, 2025, 14964, 2426, 1996, 2717, 1997, 6395, 1005, 1055, 4042, 2006, 2014, 2609, 1005, 1055, 12532, 12565, 2930, 1012]
10.0.2.18: b"the song they sang . . . when rome fell is the 2002 debut release by vermont - based american singer - songwriter anais mitchell . the album was made during the singer ' s 6 - month stay in austin , texas , and was recorded in a single afternoon . it consists of mitchell playing her acoustic guitar and singing with sparse production . the record is currently out of print and is not referenced among the rest of mitchell ' s albums on her site ' s discography section ."
10.0.2.18: [1996, 5223, 2869, 25043, 2003, 1037, 8011, 4038, 2778, 3794, 1000, 21766, 4502, 5313, 1005, 1055, 8011, 2679, 1000, 10584, 1010, 4114, 2011, 6264, 1004, 2848, 2556, 1012, 2778, 4616, 8676, 1997, 1996, 13618, 3459, 1997, 8011, 8603, 1000, 3752, 1000, 1010, 2030, 22608, 23979, 1010, 2037, 3507, 3459, 15416, 1010, 12330, 1998, 12746, 1012, 2028, 2266, 1997, 1996, 3459, 2788, 3248, 1996, 2535, 1997, 3677, 1010, 10449, 1996, 9567, 2169, 2305, 1012, 1999, 2233, 10476, 1010, 7124, 4202, 2187, 1996, 2778, 2004, 1037, 3696, 1997, 14657, 2044, 12256, 3388, 1060, 2689, 2001, 3718, 2005, 4394, 1037, 2644, 2000, 5589, 1999, 1996, 2189, 2678, 2005, 11284, 1005, 1055, 1000, 2643, 2491, 1000, 1012]
10.0.2.18: b'the haters roast is a drag comedy tour featuring " rupaul \' s drag race " contestants , organized by murray & peter present . tour performances consist of the rotating cast of drag queens " reading " , or playfully insulting , their fellow castmates , celebrities and peers . one member of the cast usually plays the role of host , introducing the performers each night . in march 2019 , trinity taylor left the tour as a sign of solidarity after monet x change was removed for missing a stop to participate in the music video for madonna \' s " god control " .'
10.0.2.18: Dataset document count 6021498, token count 4444327018, non sentence start0.0
10.0.2.18: Dataset document count 317254, token count 241486522, non sentence start0.0
10.0.2.18: Dataset document count 6345, token count 4986126, non sentence start0.0
10.0.2.18: BERT prob 1.0, gap sent prob 0.0, GPT prob 0.0, infill prob 0.5
10.0.2.18: generation min ratio 0.5, block ratio 0.15, gap sent ratio 0.15
10.0.2.18: block length distribution [0.14936120510359185, 0.22404180765538775, 0.22404180765538775, 0.16803135574154085, 0.10081881344492458, 0.05040940672246224, 0.02160403145248382, 0.008101511794681432, 0.002700503931560479, 0.0008101511794681439, 0.00022095032167312998, 5.523758041828258e-05, 1.2747133942680616e-05, 2.7315287020029775e-06, 5.463057404005949e-07, 1.0243232632511163e-07, 1.807629288090209e-08, 3.0127154801503496e-09, 4.756919179184761e-10, 7.135378768777153e-11, 1.01933982411102e-11, 1.3900088510604783e-12, 1.8130550231223652e-13, 2.26631877890296e-14, 2.719582534683569e-15, 3.1379798477117986e-16, 3.486644275235373e-17, 3.735690294894986e-18, 3.8645072016155465e-19, 3.864507201615528e-20, 3.739845678982777e-21, 3.5061053240463625e-22, 3.18736847640571e-23, 2.8123839497698246e-24, 2.410614814088421e-25, 2.0088456784069862e-26, 1.6287937933030137e-27, 1.285889836818143e-28, 9.89146028321656e-30]
10.0.2.18: block mask prob 0.0, context mask ratio 0.0
10.0.2.18: BERT prob 1.0, gap sent prob 0.0, GPT prob 0.0, infill prob 0.5
10.0.2.18: generation min ratio 0.5, block ratio 0.15, gap sent ratio 0.15
10.0.2.18: block length distribution [0.14936120510359185, 0.22404180765538775, 0.22404180765538775, 0.16803135574154085, 0.10081881344492458, 0.05040940672246224, 0.02160403145248382, 0.008101511794681432, 0.002700503931560479, 0.0008101511794681439, 0.00022095032167312998, 5.523758041828258e-05, 1.2747133942680616e-05, 2.7315287020029775e-06, 5.463057404005949e-07, 1.0243232632511163e-07, 1.807629288090209e-08, 3.0127154801503496e-09, 4.756919179184761e-10, 7.135378768777153e-11, 1.01933982411102e-11, 1.3900088510604783e-12, 1.8130550231223652e-13, 2.26631877890296e-14, 2.719582534683569e-15, 3.1379798477117986e-16, 3.486644275235373e-17, 3.735690294894986e-18, 3.8645072016155465e-19, 3.864507201615528e-20, 3.739845678982777e-21, 3.5061053240463625e-22, 3.18736847640571e-23, 2.8123839497698246e-24, 2.410614814088421e-25, 2.0088456784069862e-26, 1.6287937933030137e-27, 1.285889836818143e-28, 9.89146028321656e-30]
10.0.2.18: block mask prob 0.0, context mask ratio 0.0
10.0.2.18: BERT prob 1.0, gap sent prob 0.0, GPT prob 0.0, infill prob 0.5
10.0.2.18: generation min ratio 0.5, block ratio 0.15, gap sent ratio 0.15
10.0.2.18: block length distribution [0.14936120510359185, 0.22404180765538775, 0.22404180765538775, 0.16803135574154085, 0.10081881344492458, 0.05040940672246224, 0.02160403145248382, 0.008101511794681432, 0.002700503931560479, 0.0008101511794681439, 0.00022095032167312998, 5.523758041828258e-05, 1.2747133942680616e-05, 2.7315287020029775e-06, 5.463057404005949e-07, 1.0243232632511163e-07, 1.807629288090209e-08, 3.0127154801503496e-09, 4.756919179184761e-10, 7.135378768777153e-11, 1.01933982411102e-11, 1.3900088510604783e-12, 1.8130550231223652e-13, 2.26631877890296e-14, 2.719582534683569e-15, 3.1379798477117986e-16, 3.486644275235373e-17, 3.735690294894986e-18, 3.8645072016155465e-19, 3.864507201615528e-20, 3.739845678982777e-21, 3.5061053240463625e-22, 3.18736847640571e-23, 2.8123839497698246e-24, 2.410614814088421e-25, 2.0088456784069862e-26, 1.6287937933030137e-27, 1.285889836818143e-28, 9.89146028321656e-30]
10.0.2.18: block mask prob 0.0, context mask ratio 0.0
10.0.2.18: building GPT2 model ...
10.0.2.18:  > number of parameters on model parallel rank 0: 109338624
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:980 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:979 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:973 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:974 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:975 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:977 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:978 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:976 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:980 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:979 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:973 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:975 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:974 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:977 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:978 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:976 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:980 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:979 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:973 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:975 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:974 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:977 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:978 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:976 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:980 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:979 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:973 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:975 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:974 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:977 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:978 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:976 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:980 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:979 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:973 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:975 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:974 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:977 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:978 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:976 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:980 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:979 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:973 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:975 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:974 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:977 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:978 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:976 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:980 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:979 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:973 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:975 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:974 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:977 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:978 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:976 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:980 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:979 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:973 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:975 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:974 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:977 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:978 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:976 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO Trees [0] 12/-1/-1->11->10 [1] 12/-1/-1->11->10
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO Setting affinity for GPU 3 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO Setting affinity for GPU 6 to 3fff,fff00000,03ffffff
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO Setting affinity for GPU 6 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO Trees [0] 13/-1/-1->12->11 [1] 13/-1/-1->12->11
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO Setting affinity for GPU 7 to ff,ffff0000,00ffffff
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO Setting affinity for GPU 5 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO Setting affinity for GPU 4 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] 10/-1/-1->9->8
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Trees [0] 9/-1/-1->8->0 [1] 9/0/-1->8->-1
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO Setting affinity for GPU 1 to 3fff,fff00000,03ffffff
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO Setting affinity for GPU 5 to ff,ffff0000,00ffffff
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Setting affinity for GPU 0 to 3fff,fff00000,03ffffff
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO Setting affinity for GPU 2 to 3fff,fff00000,03ffffff
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO Setting affinity for GPU 4 to ff,ffff0000,00ffffff
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO Setting affinity for GPU 7 to 3fff,fff00000,03ffffff
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Trees [0] 1/8/-1->0->-1 [1] 1/-1/-1->0->8
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Channel 00 : 7[41000] -> 8[1a000] [receive] via NET/Socket/0
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO Channel 00 : 11[1e000] -> 12[3d000] via P2P/IPC
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO Channel 00 : 14[40000] -> 15[41000] via P2P/IPC
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO Channel 00 : 13[3e000] -> 14[40000] via P2P/IPC
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO Channel 00 : 9[1b000] -> 10[1d000] via P2P/IPC
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO Channel 00 : 10[1d000] -> 11[1e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO Channel 00 : 1[1b000] -> 2[1d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO Channel 00 : 3[1e000] -> 4[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO Channel 00 : 5[3e000] -> 6[40000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO Channel 00 : 4[3d000] -> 5[3e000] via P2P/IPC
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO Channel 01 : 11[1e000] -> 12[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO Channel 00 : 6[40000] -> 7[41000] via P2P/IPC
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO Channel 00 : 12[3d000] -> 13[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO Channel 00 : 2[1d000] -> 3[1e000] via P2P/IPC
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO Channel 01 : 14[40000] -> 15[41000] via P2P/IPC
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO Channel 01 : 9[1b000] -> 10[1d000] via P2P/IPC
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO Channel 01 : 13[3e000] -> 14[40000] via P2P/IPC
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO Channel 01 : 10[1d000] -> 11[1e000] via P2P/IPC
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO Channel 01 : 12[3d000] -> 13[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Channel 00 : 15[41000] -> 0[1a000] [receive] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO Channel 01 : 1[1b000] -> 2[1d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO Channel 01 : 3[1e000] -> 4[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO Channel 01 : 5[3e000] -> 6[40000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO Channel 01 : 4[3d000] -> 5[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO Channel 01 : 6[40000] -> 7[41000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO Channel 01 : 2[1d000] -> 3[1e000] via P2P/IPC
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Channel 01 : 7[41000] -> 8[1a000] [receive] via NET/Socket/0
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Channel 00 : 8[1a000] -> 9[1b000] via P2P/IPC
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Channel 01 : 8[1a000] -> 9[1b000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO Channel 00 : 7[41000] -> 8[1a000] [send] via NET/Socket/0
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO Channel 00 : 15[41000] -> 0[1a000] [send] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Channel 01 : 15[41000] -> 0[1a000] [receive] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Channel 00 : 0[1a000] -> 1[1b000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Channel 01 : 0[1a000] -> 1[1b000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO Channel 01 : 7[41000] -> 8[1a000] [send] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO Channel 00 : 4[3d000] -> 3[1e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO Channel 01 : 4[3d000] -> 3[1e000] via P2P/IPC
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO Channel 01 : 15[41000] -> 0[1a000] [send] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO Channel 00 : 12[3d000] -> 11[1e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO Channel 00 : 2[1d000] -> 1[1b000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO Channel 01 : 2[1d000] -> 1[1b000] via P2P/IPC
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO Channel 01 : 12[3d000] -> 11[1e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO Channel 00 : 7[41000] -> 6[40000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO Channel 01 : 7[41000] -> 6[40000] via P2P/IPC
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Channel 00 : 8[1a000] -> 0[1a000] [receive] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Channel 00 : 0[1a000] -> 8[1a000] [receive] via NET/Socket/0
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO Channel 00 : 5[3e000] -> 4[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO Channel 00 : 6[40000] -> 5[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO Channel 00 : 1[1b000] -> 0[1a000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO Channel 00 : 3[1e000] -> 2[1d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO Channel 01 : 5[3e000] -> 4[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO Channel 01 : 6[40000] -> 5[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO Channel 01 : 1[1b000] -> 0[1a000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO Channel 01 : 3[1e000] -> 2[1d000] via P2P/IPC
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO Channel 00 : 13[3e000] -> 12[3d000] via P2P/IPC
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO Channel 00 : 10[1d000] -> 9[1b000] via P2P/IPC
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO Channel 00 : 11[1e000] -> 10[1d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1502:1589 [7] NCCL INFO comm 0x7f9330099880 rank 7 nranks 16 cudaDev 7 busId 41000 - Init COMPLETE
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Channel 01 : 0[1a000] -> 8[1a000] [receive] via NET/Socket/0
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO Channel 01 : 13[3e000] -> 12[3d000] via P2P/IPC
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO Channel 01 : 10[1d000] -> 9[1b000] via P2P/IPC
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO Channel 01 : 11[1e000] -> 10[1d000] via P2P/IPC
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Channel 01 : 8[1a000] -> 0[1a000] [receive] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1500:1591 [5] NCCL INFO comm 0x7f2d44099880 rank 5 nranks 16 cudaDev 5 busId 3e000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1501:1590 [6] NCCL INFO comm 0x7fcbb0099880 rank 6 nranks 16 cudaDev 6 busId 40000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1499:1592 [4] NCCL INFO comm 0x7ff03c099880 rank 4 nranks 16 cudaDev 4 busId 3d000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1498:1586 [3] NCCL INFO comm 0x7f5b5c099880 rank 3 nranks 16 cudaDev 3 busId 1e000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1497:1587 [2] NCCL INFO comm 0x7f1fcc099880 rank 2 nranks 16 cudaDev 2 busId 1d000 - Init COMPLETE
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO Channel 00 : 15[41000] -> 14[40000] via P2P/IPC
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Channel 00 : 8[1a000] -> 0[1a000] [send] via NET/Socket/0
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Channel 00 : 0[1a000] -> 8[1a000] [send] via NET/Socket/0
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO Channel 01 : 15[41000] -> 14[40000] via P2P/IPC
10.0.2.17: f738527b48a8:889:973 [4] NCCL INFO comm 0x7fe23c099880 rank 12 nranks 16 cudaDev 4 busId 3d000 - Init COMPLETE
10.0.2.17: f738527b48a8:888:977 [3] NCCL INFO comm 0x7ff12c099600 rank 11 nranks 16 cudaDev 3 busId 1e000 - Init COMPLETE
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO Channel 00 : 9[1b000] -> 8[1a000] via P2P/IPC
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO Channel 01 : 9[1b000] -> 8[1a000] via P2P/IPC
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO Channel 00 : 14[40000] -> 13[3e000] via P2P/IPC
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO Channel 01 : 14[40000] -> 13[3e000] via P2P/IPC
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Channel 01 : 8[1a000] -> 0[1a000] [send] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Channel 01 : 0[1a000] -> 8[1a000] [send] via NET/Socket/0
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:887:976 [2] NCCL INFO comm 0x7f673c099880 rank 10 nranks 16 cudaDev 2 busId 1d000 - Init COMPLETE
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:893:975 [7] NCCL INFO comm 0x7f67b0099880 rank 15 nranks 16 cudaDev 7 busId 41000 - Init COMPLETE
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:890:979 [5] NCCL INFO comm 0x7f188c099880 rank 13 nranks 16 cudaDev 5 busId 3e000 - Init COMPLETE
10.0.2.17: f738527b48a8:891:980 [6] NCCL INFO comm 0x7f72c4099880 rank 14 nranks 16 cudaDev 6 busId 40000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1495:1585 [0] NCCL INFO comm 0x7efb2c008e10 rank 0 nranks 16 cudaDev 0 busId 1a000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1495:1495 [0] NCCL INFO Launch mode Parallel
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1496:1588 [1] NCCL INFO comm 0x7f4004099880 rank 1 nranks 16 cudaDev 1 busId 1b000 - Init COMPLETE
10.0.2.17: f738527b48a8:885:974 [0] NCCL INFO comm 0x7f79a0099880 rank 8 nranks 16 cudaDev 0 busId 1a000 - Init COMPLETE
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:886:978 [1] NCCL INFO comm 0x7ff954099880 rank 9 nranks 16 cudaDev 1 busId 1b000 - Init COMPLETE
10.0.2.18: Optimizer = FusedAdam
10.0.2.18: Optimizer = FusedAdam
10.0.2.18: Optimizer = FusedAdam
10.0.2.18: Optimizer = FusedAdam
10.0.2.18: Optimizer = FusedAdam
10.0.2.18: learning rate decaying style cosine, ratio 20.0
10.0.2.18: Optimizer = FusedAdam
10.0.2.18: Optimizer = FusedAdam
10.0.2.18: Optimizer = FusedAdam
10.0.2.17: Optimizer = FusedAdam
10.0.2.17: Optimizer = FusedAdam
10.0.2.17: Optimizer = FusedAdam
10.0.2.17: Optimizer = FusedAdam
10.0.2.17: Optimizer = FusedAdam
10.0.2.17: Optimizer = FusedAdam
10.0.2.17: Optimizer = FusedAdam
10.0.2.17: Optimizer = FusedAdam
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:999 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:997 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:1000 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:1002 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:1001 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:1003 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:1004 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:998 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:999 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:997 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:1000 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:1002 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:1001 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:1004 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:1003 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:998 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:999 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:997 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:1000 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:1002 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:1001 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:1004 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:1003 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:998 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:999 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:997 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:1000 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:1002 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:1001 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:1004 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:1003 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.17: 
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: f738527b48a8:893:998 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:999 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:997 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:1000 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:1002 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:1001 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:1004 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:1003 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:998 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.18: 
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:999 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:997 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:1000 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:1002 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:1001 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:1004 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:1003 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:998 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:999 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:997 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:1000 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:1002 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:1001 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:1004 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:1003 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:998 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:885:999 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:886:997 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:889:1000 [4] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:890:1002 [5] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:888:1001 [3] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:887:1004 [2] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:891:1003 [6] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: 
10.0.2.17: f738527b48a8:893:998 [7] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO Setting affinity for GPU 7 to 3fff,fff00000,03ffffff
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Trees [0] 1/8/-1->0->-1 [1] 1/-1/-1->0->8
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO Setting affinity for GPU 4 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO Setting affinity for GPU 6 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO Setting affinity for GPU 5 to ff,ffff0000,00ffffff
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO Setting affinity for GPU 7 to ff,ffff0000,00ffffff
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] 10/-1/-1->9->8
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO Setting affinity for GPU 2 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO Setting affinity for GPU 1 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Trees [0] 9/-1/-1->8->0 [1] 9/0/-1->8->-1
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO Setting affinity for GPU 6 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Setting affinity for GPU 0 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO Setting affinity for GPU 5 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO Trees [0] 13/-1/-1->12->11 [1] 13/-1/-1->12->11
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO Setting affinity for GPU 4 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO Trees [0] 12/-1/-1->11->10 [1] 12/-1/-1->11->10
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO Setting affinity for GPU 3 to 3fff,fff00000,03ffffff
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO Channel 00 : 9[1b000] -> 10[1d000] via P2P/IPC
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO Channel 01 : 9[1b000] -> 10[1d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO Channel 00 : 2[1d000] -> 3[1e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO Channel 01 : 2[1d000] -> 3[1e000] via P2P/IPC
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO Channel 00 : 10[1d000] -> 11[1e000] via P2P/IPC
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO Channel 01 : 10[1d000] -> 11[1e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO Channel 00 : 1[1b000] -> 2[1d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO Channel 00 : 3[1e000] -> 4[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Channel 00 : 15[41000] -> 0[1a000] [receive] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO Channel 00 : 6[40000] -> 7[41000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO Channel 00 : 4[3d000] -> 5[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO Channel 01 : 1[1b000] -> 2[1d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO Channel 00 : 5[3e000] -> 6[40000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO Channel 01 : 3[1e000] -> 4[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO Channel 01 : 6[40000] -> 7[41000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO Channel 01 : 4[3d000] -> 5[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO Channel 01 : 5[3e000] -> 6[40000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO Channel 00 : 7[41000] -> 8[1a000] [send] via NET/Socket/0
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO Channel 00 : 13[3e000] -> 14[40000] via P2P/IPC
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO Channel 00 : 14[40000] -> 15[41000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Channel 01 : 15[41000] -> 0[1a000] [receive] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Channel 00 : 7[41000] -> 8[1a000] [receive] via NET/Socket/0
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO Channel 01 : 13[3e000] -> 14[40000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO Channel 01 : 14[40000] -> 15[41000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Channel 00 : 0[1a000] -> 1[1b000] via P2P/IPC
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO Channel 00 : 15[41000] -> 0[1a000] [send] via NET/Socket/0
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO Channel 00 : 12[3d000] -> 13[3e000] via P2P/IPC
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO Channel 00 : 11[1e000] -> 12[3d000] via P2P/IPC
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO Channel 01 : 12[3d000] -> 13[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Channel 01 : 0[1a000] -> 1[1b000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO Channel 01 : 7[41000] -> 8[1a000] [send] via NET/Socket/0
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO Channel 01 : 11[1e000] -> 12[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO Channel 00 : 2[1d000] -> 1[1b000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO Channel 00 : 3[1e000] -> 2[1d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO Channel 00 : 4[3d000] -> 3[1e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO Channel 00 : 5[3e000] -> 4[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO Channel 01 : 2[1d000] -> 1[1b000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO Channel 01 : 3[1e000] -> 2[1d000] via P2P/IPC
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO Channel 01 : 4[3d000] -> 3[1e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO Channel 01 : 5[3e000] -> 4[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Channel 01 : 7[41000] -> 8[1a000] [receive] via NET/Socket/0
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO Channel 01 : 15[41000] -> 0[1a000] [send] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1498:1613 [3] NCCL INFO comm 0x7f5b5c4023d0 rank 3 nranks 16 cudaDev 3 busId 1e000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1499:1614 [4] NCCL INFO comm 0x7ff03c4023d0 rank 4 nranks 16 cudaDev 4 busId 3d000 - Init COMPLETE
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Channel 00 : 8[1a000] -> 9[1b000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO Channel 00 : 6[40000] -> 5[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO Channel 00 : 1[1b000] -> 0[1a000] via P2P/IPC
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Channel 01 : 8[1a000] -> 9[1b000] via P2P/IPC
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO Channel 00 : 13[3e000] -> 12[3d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO Channel 01 : 6[40000] -> 5[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO Channel 01 : 1[1b000] -> 0[1a000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO Channel 00 : 10[1d000] -> 9[1b000] via P2P/IPC
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO Channel 00 : 15[41000] -> 14[40000] via P2P/IPC
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO Channel 00 : 7[41000] -> 6[40000] via P2P/IPC
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO Channel 00 : 12[3d000] -> 11[1e000] via P2P/IPC
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO Channel 00 : 11[1e000] -> 10[1d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO Channel 01 : 7[41000] -> 6[40000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1500:1615 [5] NCCL INFO comm 0x7f2d444037b0 rank 5 nranks 16 cudaDev 5 busId 3e000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1497:1612 [2] NCCL INFO comm 0x7f1fcc4023d0 rank 2 nranks 16 cudaDev 2 busId 1d000 - Init COMPLETE
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO Channel 01 : 13[3e000] -> 12[3d000] via P2P/IPC
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Connected all rings
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO Channel 01 : 10[1d000] -> 9[1b000] via P2P/IPC
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO Channel 01 : 15[41000] -> 14[40000] via P2P/IPC
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO Channel 01 : 12[3d000] -> 11[1e000] via P2P/IPC
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO Channel 01 : 11[1e000] -> 10[1d000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Channel 00 : 8[1a000] -> 0[1a000] [receive] via NET/Socket/0
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO Connected all rings
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1502:1617 [7] NCCL INFO comm 0x7f9330404140 rank 7 nranks 16 cudaDev 7 busId 41000 - Init COMPLETE
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO Channel 00 : 14[40000] -> 13[3e000] via P2P/IPC
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1501:1616 [6] NCCL INFO comm 0x7fcbb04023d0 rank 6 nranks 16 cudaDev 6 busId 40000 - Init COMPLETE
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO Channel 01 : 14[40000] -> 13[3e000] via P2P/IPC
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:889:1000 [4] NCCL INFO comm 0x7fe23c402f00 rank 12 nranks 16 cudaDev 4 busId 3d000 - Init COMPLETE
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:888:1001 [3] NCCL INFO comm 0x7ff12c402150 rank 11 nranks 16 cudaDev 3 busId 1e000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Channel 01 : 8[1a000] -> 0[1a000] [receive] via NET/Socket/0
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Channel 00 : 0[1a000] -> 8[1a000] [receive] via NET/Socket/0
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO Channel 00 : 9[1b000] -> 8[1a000] via P2P/IPC
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:893:998 [7] NCCL INFO comm 0x7f67b0404140 rank 15 nranks 16 cudaDev 7 busId 41000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Channel 00 : 0[1a000] -> 8[1a000] [send] via NET/Socket/0
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO Channel 01 : 9[1b000] -> 8[1a000] via P2P/IPC
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:890:1002 [5] NCCL INFO comm 0x7f188c403a30 rank 13 nranks 16 cudaDev 5 busId 3e000 - Init COMPLETE
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:891:1003 [6] NCCL INFO comm 0x7f72c44037b0 rank 14 nranks 16 cudaDev 6 busId 40000 - Init COMPLETE
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Channel 01 : 0[1a000] -> 8[1a000] [receive] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Channel 01 : 0[1a000] -> 8[1a000] [send] via NET/Socket/0
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:887:1004 [2] NCCL INFO comm 0x7f673c4023d0 rank 10 nranks 16 cudaDev 2 busId 1d000 - Init COMPLETE
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Channel 00 : 8[1a000] -> 0[1a000] [send] via NET/Socket/0
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Channel 01 : 8[1a000] -> 0[1a000] [send] via NET/Socket/0
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1495:1610 [0] NCCL INFO comm 0x7efaf4008e10 rank 0 nranks 16 cudaDev 0 busId 1a000 - Init COMPLETE
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1495:1495 [0] NCCL INFO Launch mode Parallel
10.0.2.17: f738527b48a8:885:999 [0] NCCL INFO comm 0x7f79a0411540 rank 8 nranks 16 cudaDev 0 busId 1a000 - Init COMPLETE
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO Connected all trees
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.18: d3cbd79f2fa3:1496:1611 [1] NCCL INFO comm 0x7f40044023d0 rank 1 nranks 16 cudaDev 1 busId 1b000 - Init COMPLETE
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO Connected all trees
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/64
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
10.0.2.17: f738527b48a8:886:997 [1] NCCL INFO comm 0x7ff9544023d0 rank 9 nranks 16 cudaDev 1 busId 1b000 - Init COMPLETE
10.0.2.18: Pretrain GPT2 model
10.0.2.18: arguments:
10.0.2.18:   transformer_xl ............... False
10.0.2.18:   pretrained_bert .............. False
10.0.2.18:   encoder_decoder .............. False
10.0.2.18:   attention_dropout ............ 0.1
10.0.2.18:   num_attention_heads .......... 12
10.0.2.18:   hidden_size .................. 768
10.0.2.18:   intermediate_size ............ None
10.0.2.18:   num_layers ................... 12
10.0.2.18:   layernorm_epsilon ............ 1e-05
10.0.2.18:   hidden_dropout ............... 0.1
10.0.2.18:   output_dropout ............... 0.1
10.0.2.18:   max_position_embeddings ...... 512
10.0.2.18:   vocab_size ................... 30592
10.0.2.18:   deep_init .................... False
10.0.2.18:   make_vocab_size_divisible_by . 128
10.0.2.18:   cpu_optimizer ................ False
10.0.2.18:   cpu_torch_adam ............... False
10.0.2.18:   fp16 ......................... True
10.0.2.18:   fp32_embedding ............... False
10.0.2.18:   fp32_layernorm ............... False
10.0.2.18:   fp32_tokentypes .............. False
10.0.2.18:   fp32_allreduce ............... False
10.0.2.18:   hysteresis ................... 2
10.0.2.18:   loss_scale ................... None
10.0.2.18:   loss_scale_window ............ 1000
10.0.2.18:   min_scale .................... 1
10.0.2.18:   attention_scale .............. 1.0
10.0.2.18:   experiment_name .............. blocklm-blank12-31-12-39
10.0.2.18:   batch_size ................... 16
10.0.2.18:   gradient_accumulation_steps .. 1
10.0.2.18:   weight_decay ................. 0.01
10.0.2.18:   checkpoint_activations ....... False
10.0.2.18:   checkpoint_num_layers ........ 1
10.0.2.18:   deepspeed_activation_checkpointing  False
10.0.2.18:   epochs ....................... None
10.0.2.18:   clip_grad .................... 1.0
10.0.2.18:   train_iters .................. 9375
10.0.2.18:   label_smoothing .............. 0.0
10.0.2.18:   log_interval ................. 1
10.0.2.18:   summary_dir .................. 
10.0.2.18:   seed ......................... 1234
10.0.2.18:   reset_position_ids ........... False
10.0.2.18:   reset_attention_mask ......... False
10.0.2.18:   lr_decay_iters ............... 120000
10.0.2.18:   lr_decay_style ............... cosine
10.0.2.18:   lr_decay_ratio ............... 0.05
10.0.2.18:   lr ........................... 0.0001
10.0.2.18:   warmup ....................... 0.05
10.0.2.18:   switch_linear ................ False
10.0.2.18:   save ......................... /home/kongxiyu/GLM2/blocklm-blank12-31-12-39
10.0.2.18:   new_save_directory ........... False
10.0.2.18:   save_epoch ................... 1
10.0.2.18:   save_interval ................ 5000
10.0.2.18:   no_save_optim ................ False
10.0.2.18:   no_save_rng .................. False
10.0.2.18:   load ......................... None
10.0.2.18:   no_load_optim ................ False
10.0.2.18:   no_load_rng .................. False
10.0.2.18:   no_load_lr_scheduler ......... False
10.0.2.18:   no_deepspeed_load ............ False
10.0.2.18:   finetune ..................... False
10.0.2.18:   resume_dataloader ............ True
10.0.2.18:   distributed_backend .......... nccl
10.0.2.18:   DDP_impl ..................... torch
10.0.2.18:   local_rank ................... 0
10.0.2.18:   block_lm ..................... True
10.0.2.18:   masked_lm .................... False
10.0.2.18:   bert_prob .................... 1.0
10.0.2.18:   gpt_infill_prob .............. 0.5
10.0.2.18:   gpt_min_ratio ................ 0.5
10.0.2.18:   gap_sentence_prob ............ 0.0
10.0.2.18:   gap_sentence_ratio ........... 0.15
10.0.2.18:   avg_block_length ............. 3
10.0.2.18:   short_seq_prob ............... 0.0
10.0.2.18:   single_span_prob ............. 0.0
10.0.2.18:   task_mask .................... False
10.0.2.18:   no_shuffle_block ............. False
10.0.2.18:   no_block_position ............ False
10.0.2.18:   sentinel_token ............... False
10.0.2.18:   block_mask_prob .............. 0.0
10.0.2.18:   context_mask_ratio ........... 0.0
10.0.2.18:   random_position .............. False
10.0.2.18:   eval_batch_size .............. None
10.0.2.18:   eval_iters ................... 100
10.0.2.18:   eval_interval ................ 1000
10.0.2.18:   eval_epoch ................... 1
10.0.2.18:   eval_seq_length .............. None
10.0.2.18:   eval_max_preds_per_seq ....... None
10.0.2.18:   overlapping_eval ............. 32
10.0.2.18:   temperature .................. 1.0
10.0.2.18:   top_p ........................ 0.0
10.0.2.18:   top_k ........................ 0
10.0.2.18:   out_seq_length ............... 256
10.0.2.18:   num_beams .................... 1
10.0.2.18:   length_penalty ............... 0.0
10.0.2.18:   no_repeat_ngram_size ......... 0
10.0.2.18:   min_tgt_length ............... 0
10.0.2.18:   select_topk .................. False
10.0.2.18:   blank_maskratio .............. 0.1
10.0.2.18:   model_parallel_size .......... 1
10.0.2.18:   shuffle ...................... False
10.0.2.18:   filter_english ............... False
10.0.2.18:   train_data ................... ['bert-base']
10.0.2.18:   valid_data ................... None
10.0.2.18:   test_data .................... None
10.0.2.18:   data_dir ..................... None
10.0.2.18:   input_data_sizes_file ........ sizes.txt
10.0.2.18:   delim ........................ ,
10.0.2.18:   text_key ..................... sentence
10.0.2.18:   eval_text_key ................ None
10.0.2.18:   split ........................ 949,50,1
10.0.2.18:   no_lazy_loader ............... False
10.0.2.18:   half_lazy_loader ............. False
10.0.2.18:   loader_scatter ............... None
10.0.2.18:   loose_json ................... False
10.0.2.18:   presplit_sentences ........... False
10.0.2.18:   num_workers .................. 2
10.0.2.18:   tokenizer_model_type ......... bert-base-uncased
10.0.2.18:   tokenizer_path ............... tokenizer.model
10.0.2.18:   tokenizer_type ............... BertWordPieceTokenizer
10.0.2.18:   no_pre_tokenize .............. False
10.0.2.18:   cache_dir .................... None
10.0.2.18:   use_tfrecords ................ False
10.0.2.18:   seq_length ................... 512
10.0.2.18:   mem_length ................... 0
10.0.2.18:   max_preds_per_seq ............ None
10.0.2.18:   non_sentence_start ........... 0.0
10.0.2.18:   sample_one_document .......... False
10.0.2.18:   load_splits .................. None
10.0.2.18:   save_splits .................. None
10.0.2.18:   save_test_data ............... None
10.0.2.18:   multi_task_data .............. None
10.0.2.18:   multi_task_ratio ............. 0.0
10.0.2.18:   multi_seq_length ............. None
10.0.2.18:   multi_batch_size ............. None
10.0.2.18:   task ......................... None
10.0.2.18:   load_pretrained .............. None
10.0.2.18:   pool_token ................... cls
10.0.2.18:   cloze_eval ................... False
10.0.2.18:   multi_token .................. False
10.0.2.18:   segment_length ............... 0
10.0.2.18:   loss_func .................... cross_entropy
10.0.2.18:   block_lm_ratio ............... 0.0
10.0.2.18:   adapet ....................... False
10.0.2.18:   pattern_id ................... 0
10.0.2.18:   fast_decode .................. False
10.0.2.18:   few_superglue ................ False
10.0.2.18:   eval_valid ................... False
10.0.2.18:   validation_metric ............ None
10.0.2.18:   unidirectional ............... False
10.0.2.18:   src_seq_length ............... None
10.0.2.18:   tgt_seq_length ............... None
10.0.2.18:   adam_beta1 ................... 0.9
10.0.2.18:   adam_beta2 ................... 0.999
10.0.2.18:   adam_eps ..................... 1e-08
10.0.2.18:   optimizer .................... adam
10.0.2.18:   wsc_negative ................. False
10.0.2.18:   overwrite .................... False
10.0.2.18:   no_validation ................ False
10.0.2.18:   continuous_prompt ............ False
10.0.2.18:   num_prompt_tokens ............ 0
10.0.2.18:   prompt_func .................. lstm
10.0.2.18:   freeze_transformer ........... False
10.0.2.18:   tune_prefix_layers ........... None
10.0.2.18:   prefix_prompt ................ 0
10.0.2.18:   prompt_init .................. False
10.0.2.18:   deepspeed .................... False
10.0.2.18:   deepspeed_config ............. None
10.0.2.18:   deepscale .................... False
10.0.2.18:   deepscale_config ............. None
10.0.2.18:   deepspeed_mpi ................ False
10.0.2.18:   cuda ......................... True
10.0.2.18:   rank ......................... 0
10.0.2.18:   world_size ................... 16
10.0.2.18:   dynamic_loss_scale ........... True
10.0.2.18:   master_ip .................... 10.0.2.18
10.0.2.18:   master_port .................. 10738
10.0.2.18:   eod_token .................... 0
10.0.2.18:   persist_state ................ 0
10.0.2.18:   lazy ......................... False
10.0.2.18:   transpose .................... False
10.0.2.18:   data_set_type ................ Block
10.0.2.18:   samples_per_shard ............ 100
10.0.2.18:   do_train ..................... 1
10.0.2.18:   do_valid ..................... 1
10.0.2.18:   do_test ...................... 1
10.0.2.18:   iteration .................... 0
10.0.2.18:   log_dir ...................... runs/blocklm-blank12-31-12-39
10.0.2.18: Resume dataloader
10.0.2.17: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.17:   warnings.warn(
10.0.2.17: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.17:   warnings.warn(
10.0.2.17: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.17:   warnings.warn(
10.0.2.17: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.17:   warnings.warn(
10.0.2.17: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.17:   warnings.warn(
10.0.2.17: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.17:   warnings.warn(
10.0.2.17: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.17:   warnings.warn(
10.0.2.17: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.17:   warnings.warn(
10.0.2.18:  iteration        1/    9375 | elapsed time per iteration (ms): 2300.8 | learning rate 0.000E+00 | lm loss 1.046708E+01 | loss scale 4294967296.0 |
10.0.2.18: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.18:   warnings.warn(
10.0.2.18: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.18:   warnings.warn(
10.0.2.18: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.18:   warnings.warn(
10.0.2.18: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.18:   warnings.warn(
10.0.2.18: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.18:   warnings.warn(
10.0.2.18: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.18:   warnings.warn(
10.0.2.18: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.18:   warnings.warn(
10.0.2.18: /opt/conda/lib/python3.8/site-packages/torch/cuda/memory.py:373: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
10.0.2.18:   warnings.warn(
10.0.2.18: after 1 iterations memory (MB) | allocated: 1062.1025390625 | max allocated: 15343.48779296875 | cached: 16188.0 | max cached: 16188.0
10.0.2.18: time (ms) | forward: 1298.35 | backward: 530.17 | optimizer: 0.05 | batch generator: 38.42 | data loader: 35.60
10.0.2.18:  iteration        2/    9375 | elapsed time per iteration (ms): 872.6 | learning rate 0.000E+00 | lm loss 1.046709E+01 | loss scale 2147483648.0 |
10.0.2.18: time (ms) | forward: 309.25 | backward: 539.52 | optimizer: 0.03 | batch generator: 1.45 | data loader: 0.60
10.0.2.18:  iteration        3/    9375 | elapsed time per iteration (ms): 825.5 | learning rate 0.000E+00 | lm loss 1.046951E+01 | loss scale 1073741824.0 |
10.0.2.18: time (ms) | forward: 268.68 | backward: 526.16 | optimizer: 0.03 | batch generator: 1.30 | data loader: 0.30
10.0.2.18:  iteration        4/    9375 | elapsed time per iteration (ms): 819.7 | learning rate 0.000E+00 | lm loss 1.047514E+01 | loss scale 536870912.0 |
10.0.2.18: time (ms) | forward: 238.57 | backward: 524.83 | optimizer: 0.03 | batch generator: 1.32 | data loader: 0.35
10.0.2.18:  iteration        5/    9375 | elapsed time per iteration (ms): 806.0 | learning rate 0.000E+00 | lm loss 1.046653E+01 | loss scale 268435456.0 |
10.0.2.18: time (ms) | forward: 261.25 | backward: 488.91 | optimizer: 0.07 | batch generator: 1.39 | data loader: 0.44
10.0.2.18:  iteration        6/    9375 | elapsed time per iteration (ms): 775.2 | learning rate 0.000E+00 | lm loss 1.047115E+01 | loss scale 134217728.0 |
10.0.2.18: time (ms) | forward: 89.52 | backward: 471.25 | optimizer: 0.03 | batch generator: 1.45 | data loader: 0.41
10.0.2.18:  iteration        7/    9375 | elapsed time per iteration (ms): 752.3 | learning rate 0.000E+00 | lm loss 1.047367E+01 | loss scale 67108864.0 |
10.0.2.18: time (ms) | forward: 90.06 | backward: 463.63 | optimizer: 0.03 | batch generator: 1.41 | data loader: 0.49
10.0.2.18:  iteration        8/    9375 | elapsed time per iteration (ms): 828.9 | learning rate 0.000E+00 | lm loss 1.046805E+01 | loss scale 33554432.0 |
10.0.2.18: time (ms) | forward: 125.17 | backward: 525.84 | optimizer: 0.06 | batch generator: 1.17 | data loader: 0.43
10.0.2.18:  iteration        9/    9375 | elapsed time per iteration (ms): 797.0 | learning rate 0.000E+00 | lm loss 1.046939E+01 | loss scale 16777216.0 |
10.0.2.18: time (ms) | forward: 269.41 | backward: 505.03 | optimizer: 0.03 | batch generator: 1.44 | data loader: 0.47
10.0.2.18:  iteration       10/    9375 | elapsed time per iteration (ms): 767.6 | learning rate 0.000E+00 | lm loss 1.046611E+01 | loss scale 8388608.0 |
10.0.2.18: time (ms) | forward: 239.59 | backward: 468.61 | optimizer: 0.03 | batch generator: 1.24 | data loader: 0.35
10.0.2.18:  iteration       11/    9375 | elapsed time per iteration (ms): 796.2 | learning rate 0.000E+00 | lm loss 1.046757E+01 | loss scale 4194304.0 |
10.0.2.18: time (ms) | forward: 89.72 | backward: 495.92 | optimizer: 0.03 | batch generator: 1.18 | data loader: 0.43
10.0.2.18:  iteration       12/    9375 | elapsed time per iteration (ms): 768.6 | learning rate 0.000E+00 | lm loss 1.046832E+01 | loss scale 2097152.0 |
10.0.2.18: time (ms) | forward: 89.02 | backward: 471.83 | optimizer: 0.03 | batch generator: 1.18 | data loader: 0.45
10.0.2.18:  iteration       13/    9375 | elapsed time per iteration (ms): 764.9 | learning rate 0.000E+00 | lm loss 1.047277E+01 | loss scale 1048576.0 |
10.0.2.18: time (ms) | forward: 270.60 | backward: 468.06 | optimizer: 0.03 | batch generator: 1.26 | data loader: 0.40
10.0.2.18:  iteration       14/    9375 | elapsed time per iteration (ms): 784.0 | learning rate 0.000E+00 | lm loss 1.046594E+01 | loss scale 524288.0 |
10.0.2.18: time (ms) | forward: 242.94 | backward: 491.87 | optimizer: 0.04 | batch generator: 1.14 | data loader: 0.32
10.0.2.18:  iteration       15/    9375 | elapsed time per iteration (ms): 778.8 | learning rate 0.000E+00 | lm loss 1.046794E+01 | loss scale 262144.0 |
10.0.2.18: time (ms) | forward: 89.78 | backward: 492.24 | optimizer: 0.03 | batch generator: 1.30 | data loader: 0.57
10.0.2.18:  iteration       16/    9375 | elapsed time per iteration (ms): 797.0 | learning rate 0.000E+00 | lm loss 1.047085E+01 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 88.84 | backward: 502.16 | optimizer: 0.03 | batch generator: 1.12 | data loader: 0.33
10.0.2.18:  iteration       17/    9375 | elapsed time per iteration (ms): 749.7 | learning rate 0.000E+00 | lm loss 1.047269E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.02 | backward: 460.15 | optimizer: 0.03 | batch generator: 1.24 | data loader: 0.51
10.0.2.18:  iteration       18/    9375 | elapsed time per iteration (ms): 693.0 | learning rate 1.667E-08 | lm loss 1.046935E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.97 | backward: 444.69 | optimizer: 6.70 | batch generator: 1.23 | data loader: 0.43
10.0.2.18:  iteration       19/    9375 | elapsed time per iteration (ms): 803.4 | learning rate 3.333E-08 | lm loss 1.046829E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 122.83 | backward: 499.20 | optimizer: 5.22 | batch generator: 1.19 | data loader: 0.40
10.0.2.18:  iteration       20/    9375 | elapsed time per iteration (ms): 754.1 | learning rate 5.000E-08 | lm loss 1.046441E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 234.32 | backward: 472.41 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.42
10.0.2.18:  iteration       21/    9375 | elapsed time per iteration (ms): 791.9 | learning rate 6.667E-08 | lm loss 1.046381E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.67 | backward: 482.89 | optimizer: 5.18 | batch generator: 1.09 | data loader: 0.39
10.0.2.18:  iteration       22/    9375 | elapsed time per iteration (ms): 768.0 | learning rate 8.333E-08 | lm loss 1.046441E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 124.87 | backward: 479.04 | optimizer: 5.22 | batch generator: 1.19 | data loader: 0.42
10.0.2.18:  iteration       23/    9375 | elapsed time per iteration (ms): 794.5 | learning rate 1.000E-07 | lm loss 1.046199E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 285.17 | backward: 486.38 | optimizer: 5.26 | batch generator: 1.14 | data loader: 0.32
10.0.2.18:  iteration       24/    9375 | elapsed time per iteration (ms): 823.6 | learning rate 1.167E-07 | lm loss 1.045368E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.71 | backward: 516.51 | optimizer: 5.21 | batch generator: 1.26 | data loader: 0.37
10.0.2.18:  iteration       25/    9375 | elapsed time per iteration (ms): 800.5 | learning rate 1.333E-07 | lm loss 1.045378E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.46 | backward: 490.51 | optimizer: 5.21 | batch generator: 1.05 | data loader: 0.27
10.0.2.18:  iteration       26/    9375 | elapsed time per iteration (ms): 811.5 | learning rate 1.500E-07 | lm loss 1.044761E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.91 | backward: 504.57 | optimizer: 5.18 | batch generator: 1.07 | data loader: 0.37
10.0.2.18:  iteration       27/    9375 | elapsed time per iteration (ms): 965.5 | learning rate 1.667E-07 | lm loss 1.042707E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.41 | backward: 485.81 | optimizer: 5.25 | batch generator: 1.16 | data loader: 0.47
10.0.2.18:  iteration       28/    9375 | elapsed time per iteration (ms): 746.6 | learning rate 1.833E-07 | lm loss 1.041871E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.41 | backward: 485.13 | optimizer: 5.23 | batch generator: 1.14 | data loader: 0.30
10.0.2.18:  iteration       29/    9375 | elapsed time per iteration (ms): 734.1 | learning rate 2.000E-07 | lm loss 1.041300E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.65 | backward: 451.77 | optimizer: 5.22 | batch generator: 1.18 | data loader: 0.33
10.0.2.18:  iteration       30/    9375 | elapsed time per iteration (ms): 703.8 | learning rate 2.167E-07 | lm loss 1.032429E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.75 | backward: 456.83 | optimizer: 5.20 | batch generator: 1.16 | data loader: 0.35
10.0.2.18:  iteration       31/    9375 | elapsed time per iteration (ms): 766.2 | learning rate 2.333E-07 | lm loss 1.031115E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 272.60 | backward: 485.08 | optimizer: 5.17 | batch generator: 1.18 | data loader: 0.48
10.0.2.18:  iteration       32/    9375 | elapsed time per iteration (ms): 780.2 | learning rate 2.500E-07 | lm loss 1.028601E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.39 | backward: 477.75 | optimizer: 5.20 | batch generator: 1.10 | data loader: 0.41
10.0.2.18:  iteration       33/    9375 | elapsed time per iteration (ms): 745.8 | learning rate 2.667E-07 | lm loss 1.027308E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 124.85 | backward: 471.78 | optimizer: 5.29 | batch generator: 1.19 | data loader: 0.41
10.0.2.18:  iteration       34/    9375 | elapsed time per iteration (ms): 733.2 | learning rate 2.833E-07 | lm loss 1.009364E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.25 | backward: 464.91 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.29
10.0.2.18:  iteration       35/    9375 | elapsed time per iteration (ms): 744.5 | learning rate 3.000E-07 | lm loss 1.008681E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.79 | backward: 469.76 | optimizer: 5.26 | batch generator: 1.14 | data loader: 0.38
10.0.2.18:  iteration       36/    9375 | elapsed time per iteration (ms): 839.3 | learning rate 3.167E-07 | lm loss 1.006217E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.19 | backward: 522.33 | optimizer: 5.19 | batch generator: 1.28 | data loader: 0.40
10.0.2.18:  iteration       37/    9375 | elapsed time per iteration (ms): 789.6 | learning rate 3.333E-07 | lm loss 1.001264E+01 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 124.79 | backward: 479.49 | optimizer: 5.16 | batch generator: 1.20 | data loader: 0.40
10.0.2.18:  iteration       38/    9375 | elapsed time per iteration (ms): 792.9 | learning rate 3.500E-07 | lm loss 9.955534E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.73 | backward: 487.62 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.45
10.0.2.18:  iteration       39/    9375 | elapsed time per iteration (ms): 796.3 | learning rate 3.667E-07 | lm loss 9.921782E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.53 | backward: 480.04 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.41
10.0.2.18:  iteration       40/    9375 | elapsed time per iteration (ms): 848.8 | learning rate 3.833E-07 | lm loss 9.821833E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.37 | backward: 493.11 | optimizer: 5.18 | batch generator: 1.22 | data loader: 0.51
10.0.2.18:  iteration       41/    9375 | elapsed time per iteration (ms): 777.5 | learning rate 4.000E-07 | lm loss 9.786737E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.11 | backward: 487.13 | optimizer: 5.20 | batch generator: 1.23 | data loader: 0.51
10.0.2.18:  iteration       42/    9375 | elapsed time per iteration (ms): 784.8 | learning rate 4.167E-07 | lm loss 9.744159E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.72 | backward: 478.43 | optimizer: 5.21 | batch generator: 1.22 | data loader: 0.41
10.0.2.18:  iteration       43/    9375 | elapsed time per iteration (ms): 746.6 | learning rate 4.333E-07 | lm loss 9.668692E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.71 | backward: 485.57 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.47
10.0.2.18:  iteration       44/    9375 | elapsed time per iteration (ms): 775.5 | learning rate 4.500E-07 | lm loss 9.616385E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.42 | backward: 474.16 | optimizer: 5.18 | batch generator: 1.21 | data loader: 0.43
10.0.2.18:  iteration       45/    9375 | elapsed time per iteration (ms): 931.4 | learning rate 4.667E-07 | lm loss 9.491812E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.08 | backward: 533.23 | optimizer: 5.28 | batch generator: 1.13 | data loader: 0.45
10.0.2.18:  iteration       46/    9375 | elapsed time per iteration (ms): 523.8 | learning rate 4.833E-07 | lm loss 9.433603E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.30 | backward: 375.53 | optimizer: 5.18 | batch generator: 1.25 | data loader: 0.42
10.0.2.18:  iteration       47/    9375 | elapsed time per iteration (ms): 784.9 | learning rate 5.000E-07 | lm loss 9.379915E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.54 | backward: 488.07 | optimizer: 5.27 | batch generator: 1.21 | data loader: 0.42
10.0.2.18:  iteration       48/    9375 | elapsed time per iteration (ms): 923.9 | learning rate 5.167E-07 | lm loss 9.313871E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.38 | backward: 577.01 | optimizer: 5.17 | batch generator: 1.39 | data loader: 0.65
10.0.2.18:  iteration       49/    9375 | elapsed time per iteration (ms): 746.3 | learning rate 5.333E-07 | lm loss 9.236917E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.61 | backward: 502.12 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration       50/    9375 | elapsed time per iteration (ms): 973.4 | learning rate 5.500E-07 | lm loss 9.164486E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.19 | backward: 551.34 | optimizer: 5.22 | batch generator: 1.19 | data loader: 0.42
10.0.2.18:  iteration       51/    9375 | elapsed time per iteration (ms): 789.4 | learning rate 5.667E-07 | lm loss 9.083665E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.51 | backward: 483.26 | optimizer: 5.17 | batch generator: 1.18 | data loader: 0.49
10.0.2.18:  iteration       52/    9375 | elapsed time per iteration (ms): 727.7 | learning rate 5.833E-07 | lm loss 8.997360E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.30 | backward: 455.76 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.46
10.0.2.18:  iteration       53/    9375 | elapsed time per iteration (ms): 550.5 | learning rate 6.000E-07 | lm loss 8.929956E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.73 | backward: 403.57 | optimizer: 5.18 | batch generator: 1.21 | data loader: 0.52
10.0.2.18:  iteration       54/    9375 | elapsed time per iteration (ms): 767.0 | learning rate 6.167E-07 | lm loss 8.861410E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.62 | backward: 468.21 | optimizer: 5.22 | batch generator: 1.15 | data loader: 0.46
10.0.2.18:  iteration       55/    9375 | elapsed time per iteration (ms): 821.2 | learning rate 6.333E-07 | lm loss 8.798743E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.13 | backward: 512.42 | optimizer: 5.20 | batch generator: 1.24 | data loader: 0.43
10.0.2.18:  iteration       56/    9375 | elapsed time per iteration (ms): 782.2 | learning rate 6.500E-07 | lm loss 8.711555E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.78 | backward: 469.70 | optimizer: 5.23 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration       57/    9375 | elapsed time per iteration (ms): 742.3 | learning rate 6.667E-07 | lm loss 8.653576E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.18 | backward: 484.56 | optimizer: 5.20 | batch generator: 1.32 | data loader: 0.60
10.0.2.18:  iteration       58/    9375 | elapsed time per iteration (ms): 754.5 | learning rate 6.833E-07 | lm loss 8.620046E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 240.65 | backward: 489.36 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.40
10.0.2.18:  iteration       59/    9375 | elapsed time per iteration (ms): 509.7 | learning rate 7.000E-07 | lm loss 8.523432E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.10 | backward: 361.79 | optimizer: 5.20 | batch generator: 1.09 | data loader: 0.39
10.0.2.18:  iteration       60/    9375 | elapsed time per iteration (ms): 527.0 | learning rate 7.167E-07 | lm loss 8.475277E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.68 | backward: 379.81 | optimizer: 5.19 | batch generator: 1.06 | data loader: 0.38
10.0.2.18:  iteration       61/    9375 | elapsed time per iteration (ms): 555.4 | learning rate 7.333E-07 | lm loss 8.424923E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.59 | backward: 403.54 | optimizer: 5.16 | batch generator: 1.07 | data loader: 0.38
10.0.2.18:  iteration       62/    9375 | elapsed time per iteration (ms): 865.5 | learning rate 7.500E-07 | lm loss 8.366270E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.21 | backward: 560.18 | optimizer: 5.18 | batch generator: 1.08 | data loader: 0.34
10.0.2.18:  iteration       63/    9375 | elapsed time per iteration (ms): 577.5 | learning rate 7.667E-07 | lm loss 8.350143E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.22 | backward: 423.45 | optimizer: 5.17 | batch generator: 1.12 | data loader: 0.43
10.0.2.18:  iteration       64/    9375 | elapsed time per iteration (ms): 746.7 | learning rate 7.833E-07 | lm loss 8.308942E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.73 | backward: 501.03 | optimizer: 5.18 | batch generator: 1.02 | data loader: 0.35
10.0.2.18:  iteration       65/    9375 | elapsed time per iteration (ms): 558.7 | learning rate 8.000E-07 | lm loss 8.248251E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.72 | backward: 401.75 | optimizer: 5.21 | batch generator: 1.05 | data loader: 0.30
10.0.2.18:  iteration       66/    9375 | elapsed time per iteration (ms): 789.7 | learning rate 8.167E-07 | lm loss 8.207702E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.70 | backward: 482.92 | optimizer: 5.17 | batch generator: 1.12 | data loader: 0.41
10.0.2.18:  iteration       67/    9375 | elapsed time per iteration (ms): 774.4 | learning rate 8.333E-07 | lm loss 8.202999E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 236.30 | backward: 529.69 | optimizer: 5.17 | batch generator: 1.14 | data loader: 0.41
10.0.2.18:  iteration       68/    9375 | elapsed time per iteration (ms): 530.6 | learning rate 8.500E-07 | lm loss 8.157701E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.90 | backward: 374.80 | optimizer: 5.17 | batch generator: 1.04 | data loader: 0.31
10.0.2.18:  iteration       69/    9375 | elapsed time per iteration (ms): 803.9 | learning rate 8.667E-07 | lm loss 8.120729E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.48 | backward: 499.96 | optimizer: 5.20 | batch generator: 1.04 | data loader: 0.29
10.0.2.18:  iteration       70/    9375 | elapsed time per iteration (ms): 510.2 | learning rate 8.833E-07 | lm loss 8.115782E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.94 | backward: 363.85 | optimizer: 5.15 | batch generator: 1.08 | data loader: 0.30
10.0.2.18:  iteration       71/    9375 | elapsed time per iteration (ms): 766.3 | learning rate 9.000E-07 | lm loss 8.046570E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 273.73 | backward: 484.06 | optimizer: 5.18 | batch generator: 1.02 | data loader: 0.27
10.0.2.18:  iteration       72/    9375 | elapsed time per iteration (ms): 812.4 | learning rate 9.167E-07 | lm loss 8.067688E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.25 | backward: 511.42 | optimizer: 5.25 | batch generator: 1.06 | data loader: 0.38
10.0.2.18:  iteration       73/    9375 | elapsed time per iteration (ms): 777.3 | learning rate 9.333E-07 | lm loss 8.002800E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.56 | backward: 488.85 | optimizer: 5.17 | batch generator: 1.20 | data loader: 0.34
10.0.2.18:  iteration       74/    9375 | elapsed time per iteration (ms): 740.1 | learning rate 9.500E-07 | lm loss 7.993505E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.48 | backward: 465.63 | optimizer: 5.20 | batch generator: 1.11 | data loader: 0.40
10.0.2.18:  iteration       75/    9375 | elapsed time per iteration (ms): 529.9 | learning rate 9.667E-07 | lm loss 7.983837E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.62 | backward: 370.85 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.43
10.0.2.18:  iteration       76/    9375 | elapsed time per iteration (ms): 829.7 | learning rate 9.833E-07 | lm loss 7.972323E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.84 | backward: 529.11 | optimizer: 5.19 | batch generator: 1.23 | data loader: 0.40
10.0.2.18:  iteration       77/    9375 | elapsed time per iteration (ms): 504.6 | learning rate 1.000E-06 | lm loss 7.939511E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.65 | backward: 348.71 | optimizer: 5.19 | batch generator: 1.03 | data loader: 0.30
10.0.2.18:  iteration       78/    9375 | elapsed time per iteration (ms): 838.1 | learning rate 1.017E-06 | lm loss 7.922328E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.17 | backward: 532.15 | optimizer: 5.18 | batch generator: 1.17 | data loader: 0.49
10.0.2.18:  iteration       79/    9375 | elapsed time per iteration (ms): 749.7 | learning rate 1.033E-06 | lm loss 7.914879E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.55 | backward: 478.10 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.45
10.0.2.18:  iteration       80/    9375 | elapsed time per iteration (ms): 557.8 | learning rate 1.050E-06 | lm loss 7.887025E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.62 | backward: 410.41 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration       81/    9375 | elapsed time per iteration (ms): 821.6 | learning rate 1.067E-06 | lm loss 7.860423E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.37 | backward: 537.99 | optimizer: 5.20 | batch generator: 1.00 | data loader: 0.33
10.0.2.18:  iteration       82/    9375 | elapsed time per iteration (ms): 540.9 | learning rate 1.083E-06 | lm loss 7.841207E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.65 | backward: 389.48 | optimizer: 5.20 | batch generator: 1.11 | data loader: 0.35
10.0.2.18:  iteration       83/    9375 | elapsed time per iteration (ms): 779.6 | learning rate 1.100E-06 | lm loss 7.827082E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 124.96 | backward: 533.06 | optimizer: 5.17 | batch generator: 1.31 | data loader: 0.56
10.0.2.18:  iteration       84/    9375 | elapsed time per iteration (ms): 740.3 | learning rate 1.117E-06 | lm loss 7.794786E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.74 | backward: 472.02 | optimizer: 5.17 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration       85/    9375 | elapsed time per iteration (ms): 799.3 | learning rate 1.133E-06 | lm loss 7.796776E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.88 | backward: 516.93 | optimizer: 5.19 | batch generator: 1.12 | data loader: 0.45
10.0.2.18:  iteration       86/    9375 | elapsed time per iteration (ms): 524.5 | learning rate 1.150E-06 | lm loss 7.737048E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.04 | backward: 373.23 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.51
10.0.2.18:  iteration       87/    9375 | elapsed time per iteration (ms): 767.1 | learning rate 1.167E-06 | lm loss 7.745223E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.10 | backward: 503.87 | optimizer: 5.19 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration       88/    9375 | elapsed time per iteration (ms): 497.3 | learning rate 1.183E-06 | lm loss 7.759325E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.07 | backward: 350.63 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration       89/    9375 | elapsed time per iteration (ms): 522.9 | learning rate 1.200E-06 | lm loss 7.748223E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.28 | backward: 364.55 | optimizer: 5.22 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration       90/    9375 | elapsed time per iteration (ms): 772.2 | learning rate 1.217E-06 | lm loss 7.730433E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 269.04 | backward: 494.57 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.46
10.0.2.18:  iteration       91/    9375 | elapsed time per iteration (ms): 807.4 | learning rate 1.233E-06 | lm loss 7.720147E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 124.93 | backward: 534.93 | optimizer: 5.18 | batch generator: 1.10 | data loader: 0.40
10.0.2.18:  iteration       92/    9375 | elapsed time per iteration (ms): 510.8 | learning rate 1.250E-06 | lm loss 7.691488E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.92 | backward: 362.20 | optimizer: 5.22 | batch generator: 1.08 | data loader: 0.40
10.0.2.18:  iteration       93/    9375 | elapsed time per iteration (ms): 779.2 | learning rate 1.267E-06 | lm loss 7.672942E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.01 | backward: 533.46 | optimizer: 5.20 | batch generator: 1.13 | data loader: 0.41
10.0.2.18:  iteration       94/    9375 | elapsed time per iteration (ms): 892.9 | learning rate 1.283E-06 | lm loss 7.649899E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.16 | backward: 579.21 | optimizer: 5.29 | batch generator: 1.13 | data loader: 0.43
10.0.2.18:  iteration       95/    9375 | elapsed time per iteration (ms): 552.9 | learning rate 1.300E-06 | lm loss 7.671380E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.77 | backward: 402.18 | optimizer: 5.17 | batch generator: 1.27 | data loader: 0.44
10.0.2.18:  iteration       96/    9375 | elapsed time per iteration (ms): 575.9 | learning rate 1.317E-06 | lm loss 7.637407E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.72 | backward: 420.64 | optimizer: 5.17 | batch generator: 1.16 | data loader: 0.40
10.0.2.18:  iteration       97/    9375 | elapsed time per iteration (ms): 727.0 | learning rate 1.333E-06 | lm loss 7.646872E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 240.46 | backward: 477.57 | optimizer: 5.28 | batch generator: 1.20 | data loader: 0.41
10.0.2.18:  iteration       98/    9375 | elapsed time per iteration (ms): 713.1 | learning rate 1.350E-06 | lm loss 7.608919E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.99 | backward: 469.74 | optimizer: 5.21 | batch generator: 1.50 | data loader: 0.41
10.0.2.18:  iteration       99/    9375 | elapsed time per iteration (ms): 605.4 | learning rate 1.367E-06 | lm loss 7.632524E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.55 | backward: 440.11 | optimizer: 5.25 | batch generator: 1.49 | data loader: 0.57
10.0.2.18:  iteration      100/    9375 | elapsed time per iteration (ms): 570.7 | learning rate 1.383E-06 | lm loss 7.617739E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.88 | backward: 419.12 | optimizer: 5.21 | batch generator: 1.50 | data loader: 0.53
10.0.2.18:  iteration      101/    9375 | elapsed time per iteration (ms): 836.3 | learning rate 1.400E-06 | lm loss 7.611677E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.51 | backward: 527.22 | optimizer: 5.20 | batch generator: 1.49 | data loader: 0.58
10.0.2.18:  iteration      102/    9375 | elapsed time per iteration (ms): 576.2 | learning rate 1.417E-06 | lm loss 7.618913E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.77 | backward: 427.70 | optimizer: 5.22 | batch generator: 1.39 | data loader: 0.45
10.0.2.18:  iteration      103/    9375 | elapsed time per iteration (ms): 545.2 | learning rate 1.433E-06 | lm loss 7.577031E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.93 | backward: 397.44 | optimizer: 5.19 | batch generator: 1.48 | data loader: 0.59
10.0.2.18:  iteration      104/    9375 | elapsed time per iteration (ms): 741.1 | learning rate 1.450E-06 | lm loss 7.569201E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.69 | backward: 476.13 | optimizer: 5.28 | batch generator: 1.24 | data loader: 0.34
10.0.2.18:  iteration      105/    9375 | elapsed time per iteration (ms): 525.4 | learning rate 1.467E-06 | lm loss 7.553812E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.36 | backward: 371.43 | optimizer: 5.21 | batch generator: 1.55 | data loader: 0.51
10.0.2.18:  iteration      106/    9375 | elapsed time per iteration (ms): 753.2 | learning rate 1.483E-06 | lm loss 7.534311E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.80 | backward: 487.34 | optimizer: 5.27 | batch generator: 1.42 | data loader: 0.46
10.0.2.18:  iteration      107/    9375 | elapsed time per iteration (ms): 526.9 | learning rate 1.500E-06 | lm loss 7.558752E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.81 | backward: 375.40 | optimizer: 5.23 | batch generator: 1.57 | data loader: 0.55
10.0.2.18:  iteration      108/    9375 | elapsed time per iteration (ms): 497.7 | learning rate 1.517E-06 | lm loss 7.544168E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.31 | backward: 344.69 | optimizer: 5.24 | batch generator: 1.43 | data loader: 0.54
10.0.2.18:  iteration      109/    9375 | elapsed time per iteration (ms): 562.1 | learning rate 1.533E-06 | lm loss 7.553690E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.69 | backward: 400.94 | optimizer: 5.22 | batch generator: 1.55 | data loader: 0.53
10.0.2.18:  iteration      110/    9375 | elapsed time per iteration (ms): 531.4 | learning rate 1.550E-06 | lm loss 7.524068E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.29 | backward: 378.52 | optimizer: 5.23 | batch generator: 1.42 | data loader: 0.52
10.0.2.18:  iteration      111/    9375 | elapsed time per iteration (ms): 692.7 | learning rate 1.567E-06 | lm loss 7.527530E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.07 | backward: 450.02 | optimizer: 5.22 | batch generator: 1.53 | data loader: 0.52
10.0.2.18:  iteration      112/    9375 | elapsed time per iteration (ms): 797.2 | learning rate 1.583E-06 | lm loss 7.527113E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.39 | backward: 488.89 | optimizer: 5.20 | batch generator: 1.39 | data loader: 0.52
10.0.2.18:  iteration      113/    9375 | elapsed time per iteration (ms): 779.9 | learning rate 1.600E-06 | lm loss 7.503584E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 271.63 | backward: 498.41 | optimizer: 5.19 | batch generator: 1.37 | data loader: 0.44
10.0.2.18:  iteration      114/    9375 | elapsed time per iteration (ms): 528.6 | learning rate 1.617E-06 | lm loss 7.511677E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.45 | backward: 379.87 | optimizer: 5.26 | batch generator: 1.26 | data loader: 0.34
10.0.2.18:  iteration      115/    9375 | elapsed time per iteration (ms): 505.8 | learning rate 1.633E-06 | lm loss 7.485580E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.98 | backward: 351.83 | optimizer: 5.24 | batch generator: 1.45 | data loader: 0.34
10.0.2.18:  iteration      116/    9375 | elapsed time per iteration (ms): 537.4 | learning rate 1.650E-06 | lm loss 7.503521E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.07 | backward: 383.47 | optimizer: 5.25 | batch generator: 1.37 | data loader: 0.38
10.0.2.18:  iteration      117/    9375 | elapsed time per iteration (ms): 515.9 | learning rate 1.667E-06 | lm loss 7.468713E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.38 | backward: 361.65 | optimizer: 5.19 | batch generator: 1.59 | data loader: 0.55
10.0.2.18:  iteration      118/    9375 | elapsed time per iteration (ms): 515.7 | learning rate 1.683E-06 | lm loss 7.489559E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.34 | backward: 361.26 | optimizer: 5.18 | batch generator: 1.31 | data loader: 0.37
10.0.2.18:  iteration      119/    9375 | elapsed time per iteration (ms): 509.7 | learning rate 1.700E-06 | lm loss 7.489618E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.91 | backward: 361.44 | optimizer: 5.25 | batch generator: 1.30 | data loader: 0.42
10.0.2.18:  iteration      120/    9375 | elapsed time per iteration (ms): 731.0 | learning rate 1.717E-06 | lm loss 7.503354E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.06 | backward: 456.54 | optimizer: 5.20 | batch generator: 1.43 | data loader: 0.48
10.0.2.18:  iteration      121/    9375 | elapsed time per iteration (ms): 504.5 | learning rate 1.733E-06 | lm loss 7.492947E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.99 | backward: 349.36 | optimizer: 5.22 | batch generator: 1.49 | data loader: 0.50
10.0.2.18:  iteration      122/    9375 | elapsed time per iteration (ms): 759.6 | learning rate 1.750E-06 | lm loss 7.483111E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.00 | backward: 485.59 | optimizer: 5.22 | batch generator: 1.39 | data loader: 0.47
10.0.2.18:  iteration      123/    9375 | elapsed time per iteration (ms): 532.2 | learning rate 1.767E-06 | lm loss 7.467422E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.73 | backward: 382.08 | optimizer: 5.19 | batch generator: 1.40 | data loader: 0.38
10.0.2.18:  iteration      124/    9375 | elapsed time per iteration (ms): 521.2 | learning rate 1.783E-06 | lm loss 7.495942E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.93 | backward: 373.65 | optimizer: 5.23 | batch generator: 1.36 | data loader: 0.49
10.0.2.18:  iteration      125/    9375 | elapsed time per iteration (ms): 807.7 | learning rate 1.800E-06 | lm loss 7.453167E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.77 | backward: 510.89 | optimizer: 5.22 | batch generator: 1.45 | data loader: 0.54
10.0.2.18:  iteration      126/    9375 | elapsed time per iteration (ms): 717.4 | learning rate 1.817E-06 | lm loss 7.447849E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.99 | backward: 476.04 | optimizer: 5.20 | batch generator: 1.26 | data loader: 0.34
10.0.2.18:  iteration      127/    9375 | elapsed time per iteration (ms): 527.3 | learning rate 1.833E-06 | lm loss 7.457214E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.09 | backward: 377.53 | optimizer: 5.20 | batch generator: 1.48 | data loader: 0.58
10.0.2.18:  iteration      128/    9375 | elapsed time per iteration (ms): 469.5 | learning rate 1.850E-06 | lm loss 7.491492E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.12 | backward: 341.47 | optimizer: 5.23 | batch generator: 1.32 | data loader: 0.42
10.0.2.18:  iteration      129/    9375 | elapsed time per iteration (ms): 709.4 | learning rate 1.867E-06 | lm loss 7.448729E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.89 | backward: 464.98 | optimizer: 5.20 | batch generator: 1.40 | data loader: 0.45
10.0.2.18:  iteration      130/    9375 | elapsed time per iteration (ms): 754.0 | learning rate 1.883E-06 | lm loss 7.420517E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.10 | backward: 483.05 | optimizer: 5.19 | batch generator: 1.41 | data loader: 0.53
10.0.2.18:  iteration      131/    9375 | elapsed time per iteration (ms): 473.8 | learning rate 1.900E-06 | lm loss 7.435883E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.96 | backward: 343.59 | optimizer: 5.21 | batch generator: 1.43 | data loader: 0.55
10.0.2.18:  iteration      132/    9375 | elapsed time per iteration (ms): 514.3 | learning rate 1.917E-06 | lm loss 7.414283E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.29 | backward: 367.37 | optimizer: 5.21 | batch generator: 1.41 | data loader: 0.47
10.0.2.18:  iteration      133/    9375 | elapsed time per iteration (ms): 536.0 | learning rate 1.933E-06 | lm loss 7.434310E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.25 | backward: 382.90 | optimizer: 5.23 | batch generator: 1.46 | data loader: 0.51
10.0.2.18:  iteration      134/    9375 | elapsed time per iteration (ms): 806.6 | learning rate 1.950E-06 | lm loss 7.423147E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.48 | backward: 513.84 | optimizer: 5.20 | batch generator: 1.37 | data loader: 0.45
10.0.2.18:  iteration      135/    9375 | elapsed time per iteration (ms): 527.7 | learning rate 1.967E-06 | lm loss 7.428000E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.71 | backward: 380.08 | optimizer: 5.24 | batch generator: 1.47 | data loader: 0.49
10.0.2.18:  iteration      136/    9375 | elapsed time per iteration (ms): 520.4 | learning rate 1.983E-06 | lm loss 7.419296E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.31 | backward: 373.03 | optimizer: 5.19 | batch generator: 1.59 | data loader: 0.53
10.0.2.18:  iteration      137/    9375 | elapsed time per iteration (ms): 822.5 | learning rate 2.000E-06 | lm loss 7.412329E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.68 | backward: 527.47 | optimizer: 5.20 | batch generator: 1.32 | data loader: 0.36
10.0.2.18:  iteration      138/    9375 | elapsed time per iteration (ms): 527.3 | learning rate 2.017E-06 | lm loss 7.427059E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.60 | backward: 381.57 | optimizer: 5.22 | batch generator: 1.34 | data loader: 0.44
10.0.2.18:  iteration      139/    9375 | elapsed time per iteration (ms): 541.4 | learning rate 2.033E-06 | lm loss 7.425710E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.48 | backward: 396.17 | optimizer: 5.25 | batch generator: 1.43 | data loader: 0.48
10.0.2.18:  iteration      140/    9375 | elapsed time per iteration (ms): 512.6 | learning rate 2.050E-06 | lm loss 7.431734E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.23 | backward: 371.03 | optimizer: 6.69 | batch generator: 1.58 | data loader: 0.55
10.0.2.18:  iteration      141/    9375 | elapsed time per iteration (ms): 561.1 | learning rate 2.067E-06 | lm loss 7.408044E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.17 | backward: 417.75 | optimizer: 5.24 | batch generator: 1.51 | data loader: 0.70
10.0.2.18:  iteration      142/    9375 | elapsed time per iteration (ms): 512.4 | learning rate 2.083E-06 | lm loss 7.390260E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.45 | backward: 360.54 | optimizer: 5.19 | batch generator: 1.15 | data loader: 0.38
10.0.2.18:  iteration      143/    9375 | elapsed time per iteration (ms): 566.7 | learning rate 2.100E-06 | lm loss 7.391269E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.39 | backward: 420.83 | optimizer: 5.19 | batch generator: 1.21 | data loader: 0.45
10.0.2.18:  iteration      144/    9375 | elapsed time per iteration (ms): 567.2 | learning rate 2.117E-06 | lm loss 7.398541E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.42 | backward: 411.94 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.38
10.0.2.18:  iteration      145/    9375 | elapsed time per iteration (ms): 582.4 | learning rate 2.133E-06 | lm loss 7.396492E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.25 | backward: 427.79 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.45
10.0.2.18:  iteration      146/    9375 | elapsed time per iteration (ms): 561.9 | learning rate 2.150E-06 | lm loss 7.424845E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.32 | backward: 409.11 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.45
10.0.2.18:  iteration      147/    9375 | elapsed time per iteration (ms): 565.7 | learning rate 2.167E-06 | lm loss 7.358871E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.70 | backward: 410.73 | optimizer: 5.23 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration      148/    9375 | elapsed time per iteration (ms): 508.8 | learning rate 2.183E-06 | lm loss 7.396526E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.01 | backward: 356.84 | optimizer: 5.21 | batch generator: 1.38 | data loader: 0.48
10.0.2.18:  iteration      149/    9375 | elapsed time per iteration (ms): 528.6 | learning rate 2.200E-06 | lm loss 7.397278E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.40 | backward: 381.53 | optimizer: 5.21 | batch generator: 1.18 | data loader: 0.43
10.0.2.18:  iteration      150/    9375 | elapsed time per iteration (ms): 520.9 | learning rate 2.217E-06 | lm loss 7.361158E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.79 | backward: 366.35 | optimizer: 5.20 | batch generator: 1.31 | data loader: 0.47
10.0.2.18:  iteration      151/    9375 | elapsed time per iteration (ms): 520.2 | learning rate 2.233E-06 | lm loss 7.426375E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.84 | backward: 368.66 | optimizer: 5.18 | batch generator: 1.21 | data loader: 0.43
10.0.2.18:  iteration      152/    9375 | elapsed time per iteration (ms): 509.7 | learning rate 2.250E-06 | lm loss 7.378088E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.61 | backward: 352.11 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.45
10.0.2.18:  iteration      153/    9375 | elapsed time per iteration (ms): 516.3 | learning rate 2.267E-06 | lm loss 7.371243E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 124.75 | backward: 362.45 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.39
10.0.2.18:  iteration      154/    9375 | elapsed time per iteration (ms): 511.1 | learning rate 2.283E-06 | lm loss 7.374669E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.11 | backward: 353.40 | optimizer: 5.22 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      155/    9375 | elapsed time per iteration (ms): 499.8 | learning rate 2.300E-06 | lm loss 7.374745E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.50 | backward: 341.58 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      156/    9375 | elapsed time per iteration (ms): 496.3 | learning rate 2.317E-06 | lm loss 7.359353E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.99 | backward: 337.16 | optimizer: 5.23 | batch generator: 1.17 | data loader: 0.47
10.0.2.18:  iteration      157/    9375 | elapsed time per iteration (ms): 527.3 | learning rate 2.333E-06 | lm loss 7.360094E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.23 | backward: 368.08 | optimizer: 5.21 | batch generator: 1.32 | data loader: 0.58
10.0.2.18:  iteration      158/    9375 | elapsed time per iteration (ms): 739.0 | learning rate 2.350E-06 | lm loss 7.379292E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.89 | backward: 464.00 | optimizer: 5.18 | batch generator: 1.20 | data loader: 0.50
10.0.2.18:  iteration      159/    9375 | elapsed time per iteration (ms): 526.0 | learning rate 2.367E-06 | lm loss 7.358721E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.73 | backward: 366.63 | optimizer: 5.17 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      160/    9375 | elapsed time per iteration (ms): 506.8 | learning rate 2.383E-06 | lm loss 7.337261E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.90 | backward: 347.71 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      161/    9375 | elapsed time per iteration (ms): 740.0 | learning rate 2.400E-06 | lm loss 7.355931E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.45 | backward: 465.66 | optimizer: 5.20 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration      162/    9375 | elapsed time per iteration (ms): 501.0 | learning rate 2.417E-06 | lm loss 7.339824E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.34 | backward: 350.57 | optimizer: 5.16 | batch generator: 1.20 | data loader: 0.42
10.0.2.18:  iteration      163/    9375 | elapsed time per iteration (ms): 558.9 | learning rate 2.433E-06 | lm loss 7.371231E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.92 | backward: 400.18 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      164/    9375 | elapsed time per iteration (ms): 587.0 | learning rate 2.450E-06 | lm loss 7.368630E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.66 | backward: 440.67 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.37
10.0.2.18:  iteration      165/    9375 | elapsed time per iteration (ms): 513.5 | learning rate 2.467E-06 | lm loss 7.345593E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.41 | backward: 362.83 | optimizer: 5.17 | batch generator: 1.13 | data loader: 0.45
10.0.2.18:  iteration      166/    9375 | elapsed time per iteration (ms): 511.4 | learning rate 2.483E-06 | lm loss 7.326975E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.27 | backward: 361.61 | optimizer: 5.20 | batch generator: 1.16 | data loader: 0.40
10.0.2.18:  iteration      167/    9375 | elapsed time per iteration (ms): 513.8 | learning rate 2.500E-06 | lm loss 7.320685E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.90 | backward: 358.39 | optimizer: 5.19 | batch generator: 1.23 | data loader: 0.51
10.0.2.18:  iteration      168/    9375 | elapsed time per iteration (ms): 545.7 | learning rate 2.517E-06 | lm loss 7.353330E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.09 | backward: 373.45 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.41
10.0.2.18:  iteration      169/    9375 | elapsed time per iteration (ms): 495.4 | learning rate 2.533E-06 | lm loss 7.351452E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.55 | backward: 346.86 | optimizer: 5.20 | batch generator: 1.20 | data loader: 0.50
10.0.2.18:  iteration      170/    9375 | elapsed time per iteration (ms): 528.3 | learning rate 2.550E-06 | lm loss 7.348202E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.85 | backward: 370.89 | optimizer: 5.21 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      171/    9375 | elapsed time per iteration (ms): 781.8 | learning rate 2.567E-06 | lm loss 7.331383E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.03 | backward: 475.64 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.50
10.0.2.18:  iteration      172/    9375 | elapsed time per iteration (ms): 527.6 | learning rate 2.583E-06 | lm loss 7.322598E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.53 | backward: 370.05 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.40
10.0.2.18:  iteration      173/    9375 | elapsed time per iteration (ms): 506.0 | learning rate 2.600E-06 | lm loss 7.324018E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.36 | backward: 357.75 | optimizer: 5.17 | batch generator: 1.29 | data loader: 0.49
10.0.2.18:  iteration      174/    9375 | elapsed time per iteration (ms): 740.1 | learning rate 2.617E-06 | lm loss 7.341515E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.32 | backward: 476.36 | optimizer: 5.17 | batch generator: 1.18 | data loader: 0.49
10.0.2.18:  iteration      175/    9375 | elapsed time per iteration (ms): 526.0 | learning rate 2.633E-06 | lm loss 7.293780E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.51 | backward: 369.42 | optimizer: 5.22 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      176/    9375 | elapsed time per iteration (ms): 497.3 | learning rate 2.650E-06 | lm loss 7.297997E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.23 | backward: 335.43 | optimizer: 5.20 | batch generator: 1.25 | data loader: 0.42
10.0.2.18:  iteration      177/    9375 | elapsed time per iteration (ms): 541.8 | learning rate 2.667E-06 | lm loss 7.335947E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.19 | backward: 387.44 | optimizer: 5.20 | batch generator: 1.13 | data loader: 0.38
10.0.2.18:  iteration      178/    9375 | elapsed time per iteration (ms): 517.7 | learning rate 2.683E-06 | lm loss 7.306882E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.97 | backward: 365.70 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration      179/    9375 | elapsed time per iteration (ms): 516.7 | learning rate 2.700E-06 | lm loss 7.284252E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.91 | backward: 359.37 | optimizer: 5.28 | batch generator: 1.20 | data loader: 0.50
10.0.2.18:  iteration      180/    9375 | elapsed time per iteration (ms): 571.2 | learning rate 2.717E-06 | lm loss 7.304471E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.20 | backward: 414.27 | optimizer: 5.22 | batch generator: 1.40 | data loader: 0.68
10.0.2.18:  iteration      181/    9375 | elapsed time per iteration (ms): 543.5 | learning rate 2.733E-06 | lm loss 7.296894E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.33 | backward: 388.15 | optimizer: 5.22 | batch generator: 1.21 | data loader: 0.50
10.0.2.18:  iteration      182/    9375 | elapsed time per iteration (ms): 606.5 | learning rate 2.750E-06 | lm loss 7.299791E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.42 | backward: 459.87 | optimizer: 5.19 | batch generator: 1.27 | data loader: 0.56
10.0.2.18:  iteration      183/    9375 | elapsed time per iteration (ms): 602.2 | learning rate 2.767E-06 | lm loss 7.285890E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.66 | backward: 450.21 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.45
10.0.2.18:  iteration      184/    9375 | elapsed time per iteration (ms): 592.6 | learning rate 2.783E-06 | lm loss 7.291930E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.98 | backward: 438.01 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.42
10.0.2.18:  iteration      185/    9375 | elapsed time per iteration (ms): 591.5 | learning rate 2.800E-06 | lm loss 7.277573E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.23 | backward: 441.65 | optimizer: 5.20 | batch generator: 1.10 | data loader: 0.43
10.0.2.18:  iteration      186/    9375 | elapsed time per iteration (ms): 565.2 | learning rate 2.817E-06 | lm loss 7.258843E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.77 | backward: 413.19 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.47
10.0.2.18:  iteration      187/    9375 | elapsed time per iteration (ms): 525.2 | learning rate 2.833E-06 | lm loss 7.270526E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.18 | backward: 374.31 | optimizer: 5.24 | batch generator: 1.24 | data loader: 0.50
10.0.2.18:  iteration      188/    9375 | elapsed time per iteration (ms): 531.2 | learning rate 2.850E-06 | lm loss 7.312170E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.41 | backward: 379.01 | optimizer: 5.17 | batch generator: 1.26 | data loader: 0.47
10.0.2.18:  iteration      189/    9375 | elapsed time per iteration (ms): 527.1 | learning rate 2.867E-06 | lm loss 7.317403E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.40 | backward: 374.68 | optimizer: 5.17 | batch generator: 1.13 | data loader: 0.45
10.0.2.18:  iteration      190/    9375 | elapsed time per iteration (ms): 504.7 | learning rate 2.883E-06 | lm loss 7.258699E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.85 | backward: 356.29 | optimizer: 5.23 | batch generator: 1.11 | data loader: 0.37
10.0.2.18:  iteration      191/    9375 | elapsed time per iteration (ms): 513.7 | learning rate 2.900E-06 | lm loss 7.287910E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.89 | backward: 356.24 | optimizer: 5.27 | batch generator: 2.26 | data loader: 0.91
10.0.2.18:  iteration      192/    9375 | elapsed time per iteration (ms): 534.8 | learning rate 2.917E-06 | lm loss 7.285600E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.48 | backward: 378.68 | optimizer: 5.36 | batch generator: 1.49 | data loader: 0.49
10.0.2.18:  iteration      193/    9375 | elapsed time per iteration (ms): 540.8 | learning rate 2.933E-06 | lm loss 7.254718E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.37 | backward: 388.43 | optimizer: 5.24 | batch generator: 1.80 | data loader: 0.61
10.0.2.18:  iteration      194/    9375 | elapsed time per iteration (ms): 501.5 | learning rate 2.950E-06 | lm loss 7.263632E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.43 | backward: 350.59 | optimizer: 5.21 | batch generator: 1.49 | data loader: 0.50
10.0.2.18:  iteration      195/    9375 | elapsed time per iteration (ms): 741.4 | learning rate 2.967E-06 | lm loss 7.251760E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.47 | backward: 471.20 | optimizer: 5.23 | batch generator: 1.51 | data loader: 0.60
10.0.2.18:  iteration      196/    9375 | elapsed time per iteration (ms): 565.8 | learning rate 2.983E-06 | lm loss 7.253347E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.62 | backward: 401.87 | optimizer: 5.31 | batch generator: 1.49 | data loader: 0.60
10.0.2.18:  iteration      197/    9375 | elapsed time per iteration (ms): 576.9 | learning rate 3.000E-06 | lm loss 7.251130E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.99 | backward: 429.71 | optimizer: 5.19 | batch generator: 1.49 | data loader: 0.46
10.0.2.18:  iteration      198/    9375 | elapsed time per iteration (ms): 575.1 | learning rate 3.017E-06 | lm loss 7.286646E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.72 | backward: 420.31 | optimizer: 5.18 | batch generator: 1.36 | data loader: 0.43
10.0.2.18:  iteration      199/    9375 | elapsed time per iteration (ms): 542.2 | learning rate 3.033E-06 | lm loss 7.249933E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.86 | backward: 395.52 | optimizer: 5.27 | batch generator: 1.35 | data loader: 0.43
10.0.2.18:  iteration      200/    9375 | elapsed time per iteration (ms): 531.6 | learning rate 3.050E-06 | lm loss 7.282296E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.03 | backward: 385.57 | optimizer: 5.24 | batch generator: 1.54 | data loader: 0.53
10.0.2.18:  iteration      201/    9375 | elapsed time per iteration (ms): 518.8 | learning rate 3.067E-06 | lm loss 7.252852E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.28 | backward: 368.16 | optimizer: 5.27 | batch generator: 1.63 | data loader: 0.66
10.0.2.18:  iteration      202/    9375 | elapsed time per iteration (ms): 517.8 | learning rate 3.083E-06 | lm loss 7.234043E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.01 | backward: 370.39 | optimizer: 5.20 | batch generator: 1.40 | data loader: 0.51
10.0.2.18:  iteration      203/    9375 | elapsed time per iteration (ms): 510.2 | learning rate 3.100E-06 | lm loss 7.243269E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.94 | backward: 362.31 | optimizer: 5.22 | batch generator: 1.15 | data loader: 0.48
10.0.2.18:  iteration      204/    9375 | elapsed time per iteration (ms): 494.2 | learning rate 3.117E-06 | lm loss 7.268476E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.76 | backward: 342.28 | optimizer: 5.18 | batch generator: 1.25 | data loader: 0.45
10.0.2.18:  iteration      205/    9375 | elapsed time per iteration (ms): 587.8 | learning rate 3.133E-06 | lm loss 7.244476E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.33 | backward: 410.55 | optimizer: 5.17 | batch generator: 1.12 | data loader: 0.37
10.0.2.18:  iteration      206/    9375 | elapsed time per iteration (ms): 525.9 | learning rate 3.150E-06 | lm loss 7.224600E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.12 | backward: 370.10 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.41
10.0.2.18:  iteration      207/    9375 | elapsed time per iteration (ms): 520.3 | learning rate 3.167E-06 | lm loss 7.226335E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.77 | backward: 362.02 | optimizer: 5.20 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      208/    9375 | elapsed time per iteration (ms): 517.5 | learning rate 3.183E-06 | lm loss 7.207382E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.05 | backward: 357.96 | optimizer: 5.18 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      209/    9375 | elapsed time per iteration (ms): 490.6 | learning rate 3.200E-06 | lm loss 7.218709E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.28 | backward: 343.85 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.38
10.0.2.18:  iteration      210/    9375 | elapsed time per iteration (ms): 492.6 | learning rate 3.217E-06 | lm loss 7.191185E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.95 | backward: 339.54 | optimizer: 5.24 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      211/    9375 | elapsed time per iteration (ms): 550.0 | learning rate 3.233E-06 | lm loss 7.221991E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.43 | backward: 402.18 | optimizer: 5.28 | batch generator: 1.35 | data loader: 0.49
10.0.2.18:  iteration      212/    9375 | elapsed time per iteration (ms): 554.5 | learning rate 3.250E-06 | lm loss 7.247377E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.05 | backward: 401.90 | optimizer: 5.19 | batch generator: 1.41 | data loader: 0.52
10.0.2.18:  iteration      213/    9375 | elapsed time per iteration (ms): 537.1 | learning rate 3.267E-06 | lm loss 7.222795E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.37 | backward: 387.11 | optimizer: 5.22 | batch generator: 1.22 | data loader: 0.43
10.0.2.18:  iteration      214/    9375 | elapsed time per iteration (ms): 536.7 | learning rate 3.283E-06 | lm loss 7.204928E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.70 | backward: 389.82 | optimizer: 5.19 | batch generator: 1.36 | data loader: 0.62
10.0.2.18:  iteration      215/    9375 | elapsed time per iteration (ms): 519.4 | learning rate 3.300E-06 | lm loss 7.204883E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.54 | backward: 367.90 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.45
10.0.2.18:  iteration      216/    9375 | elapsed time per iteration (ms): 508.8 | learning rate 3.317E-06 | lm loss 7.220780E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.78 | backward: 362.36 | optimizer: 5.20 | batch generator: 1.19 | data loader: 0.50
10.0.2.18:  iteration      217/    9375 | elapsed time per iteration (ms): 544.8 | learning rate 3.333E-06 | lm loss 7.207788E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.80 | backward: 394.91 | optimizer: 5.20 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      218/    9375 | elapsed time per iteration (ms): 515.1 | learning rate 3.350E-06 | lm loss 7.194736E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.65 | backward: 360.58 | optimizer: 5.20 | batch generator: 1.21 | data loader: 0.50
10.0.2.18:  iteration      219/    9375 | elapsed time per iteration (ms): 510.6 | learning rate 3.367E-06 | lm loss 7.207469E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.81 | backward: 364.12 | optimizer: 5.24 | batch generator: 1.15 | data loader: 0.41
10.0.2.18:  iteration      220/    9375 | elapsed time per iteration (ms): 566.0 | learning rate 3.383E-06 | lm loss 7.217765E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.49 | backward: 409.73 | optimizer: 5.20 | batch generator: 1.24 | data loader: 0.41
10.0.2.18:  iteration      221/    9375 | elapsed time per iteration (ms): 613.6 | learning rate 3.400E-06 | lm loss 7.187113E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.96 | backward: 459.11 | optimizer: 5.21 | batch generator: 1.22 | data loader: 0.44
10.0.2.18:  iteration      222/    9375 | elapsed time per iteration (ms): 586.9 | learning rate 3.417E-06 | lm loss 7.154606E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.08 | backward: 432.50 | optimizer: 5.17 | batch generator: 1.20 | data loader: 0.50
10.0.2.18:  iteration      223/    9375 | elapsed time per iteration (ms): 587.5 | learning rate 3.433E-06 | lm loss 7.181917E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.51 | backward: 433.79 | optimizer: 5.25 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      224/    9375 | elapsed time per iteration (ms): 578.4 | learning rate 3.450E-06 | lm loss 7.188127E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.94 | backward: 423.48 | optimizer: 5.18 | batch generator: 1.38 | data loader: 0.51
10.0.2.18:  iteration      225/    9375 | elapsed time per iteration (ms): 521.4 | learning rate 3.467E-06 | lm loss 7.158723E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.94 | backward: 367.34 | optimizer: 5.20 | batch generator: 1.22 | data loader: 0.51
10.0.2.18:  iteration      226/    9375 | elapsed time per iteration (ms): 510.2 | learning rate 3.483E-06 | lm loss 7.172857E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.26 | backward: 349.70 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.40
10.0.2.18:  iteration      227/    9375 | elapsed time per iteration (ms): 765.1 | learning rate 3.500E-06 | lm loss 7.174860E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.78 | backward: 349.05 | optimizer: 5.17 | batch generator: 1.23 | data loader: 0.51
10.0.2.18:  iteration      228/    9375 | elapsed time per iteration (ms): 516.6 | learning rate 3.517E-06 | lm loss 7.190874E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.00 | backward: 362.11 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.45
10.0.2.18:  iteration      229/    9375 | elapsed time per iteration (ms): 518.5 | learning rate 3.533E-06 | lm loss 7.173475E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.04 | backward: 360.60 | optimizer: 5.20 | batch generator: 1.15 | data loader: 0.39
10.0.2.18:  iteration      230/    9375 | elapsed time per iteration (ms): 693.4 | learning rate 3.550E-06 | lm loss 7.149623E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 240.96 | backward: 444.03 | optimizer: 5.20 | batch generator: 1.18 | data loader: 0.41
10.0.2.18:  iteration      231/    9375 | elapsed time per iteration (ms): 491.8 | learning rate 3.567E-06 | lm loss 7.166343E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.64 | backward: 336.49 | optimizer: 5.24 | batch generator: 1.05 | data loader: 0.30
10.0.2.18:  iteration      232/    9375 | elapsed time per iteration (ms): 534.3 | learning rate 3.583E-06 | lm loss 7.141647E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.75 | backward: 373.72 | optimizer: 5.21 | batch generator: 1.21 | data loader: 0.47
10.0.2.18:  iteration      233/    9375 | elapsed time per iteration (ms): 595.7 | learning rate 3.600E-06 | lm loss 7.176969E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.01 | backward: 421.20 | optimizer: 5.21 | batch generator: 1.19 | data loader: 0.49
10.0.2.18:  iteration      234/    9375 | elapsed time per iteration (ms): 536.6 | learning rate 3.617E-06 | lm loss 7.163797E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.84 | backward: 381.18 | optimizer: 5.21 | batch generator: 1.12 | data loader: 0.37
10.0.2.18:  iteration      235/    9375 | elapsed time per iteration (ms): 536.0 | learning rate 3.633E-06 | lm loss 7.143977E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.97 | backward: 369.18 | optimizer: 5.18 | batch generator: 1.20 | data loader: 0.40
10.0.2.18:  iteration      236/    9375 | elapsed time per iteration (ms): 539.9 | learning rate 3.650E-06 | lm loss 7.142589E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.66 | backward: 382.39 | optimizer: 5.16 | batch generator: 1.16 | data loader: 0.38
10.0.2.18:  iteration      237/    9375 | elapsed time per iteration (ms): 537.7 | learning rate 3.667E-06 | lm loss 7.138198E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.74 | backward: 385.92 | optimizer: 5.35 | batch generator: 1.10 | data loader: 0.37
10.0.2.18:  iteration      238/    9375 | elapsed time per iteration (ms): 513.4 | learning rate 3.683E-06 | lm loss 7.141484E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.94 | backward: 357.20 | optimizer: 5.18 | batch generator: 1.69 | data loader: 0.66
10.0.2.18:  iteration      239/    9375 | elapsed time per iteration (ms): 522.8 | learning rate 3.700E-06 | lm loss 7.123321E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.52 | backward: 364.16 | optimizer: 5.23 | batch generator: 1.21 | data loader: 0.52
10.0.2.18:  iteration      240/    9375 | elapsed time per iteration (ms): 737.6 | learning rate 3.717E-06 | lm loss 7.131087E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.22 | backward: 460.85 | optimizer: 5.20 | batch generator: 1.22 | data loader: 0.51
10.0.2.18:  iteration      241/    9375 | elapsed time per iteration (ms): 515.8 | learning rate 3.733E-06 | lm loss 7.134385E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.50 | backward: 357.64 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.38
10.0.2.18:  iteration      242/    9375 | elapsed time per iteration (ms): 516.5 | learning rate 3.750E-06 | lm loss 7.119476E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.57 | backward: 359.16 | optimizer: 5.25 | batch generator: 1.23 | data loader: 0.50
10.0.2.18:  iteration      243/    9375 | elapsed time per iteration (ms): 560.0 | learning rate 3.767E-06 | lm loss 7.117846E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.41 | backward: 393.90 | optimizer: 5.20 | batch generator: 1.29 | data loader: 0.43
10.0.2.18:  iteration      244/    9375 | elapsed time per iteration (ms): 528.0 | learning rate 3.783E-06 | lm loss 7.142180E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.64 | backward: 379.23 | optimizer: 5.18 | batch generator: 1.17 | data loader: 0.40
10.0.2.18:  iteration      245/    9375 | elapsed time per iteration (ms): 542.1 | learning rate 3.800E-06 | lm loss 7.141741E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.27 | backward: 387.74 | optimizer: 5.20 | batch generator: 1.13 | data loader: 0.38
10.0.2.18:  iteration      246/    9375 | elapsed time per iteration (ms): 493.8 | learning rate 3.817E-06 | lm loss 7.117144E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.69 | backward: 342.95 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.44
10.0.2.18:  iteration      247/    9375 | elapsed time per iteration (ms): 540.5 | learning rate 3.833E-06 | lm loss 7.136891E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.65 | backward: 369.94 | optimizer: 5.24 | batch generator: 1.15 | data loader: 0.45
10.0.2.18:  iteration      248/    9375 | elapsed time per iteration (ms): 521.2 | learning rate 3.850E-06 | lm loss 7.090693E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.06 | backward: 362.62 | optimizer: 5.23 | batch generator: 1.36 | data loader: 0.51
10.0.2.18:  iteration      249/    9375 | elapsed time per iteration (ms): 593.3 | learning rate 3.867E-06 | lm loss 7.097563E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.04 | backward: 445.98 | optimizer: 5.22 | batch generator: 1.27 | data loader: 0.43
10.0.2.18:  iteration      250/    9375 | elapsed time per iteration (ms): 595.2 | learning rate 3.883E-06 | lm loss 7.096425E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.63 | backward: 441.90 | optimizer: 5.19 | batch generator: 1.34 | data loader: 0.49
10.0.2.18:  iteration      251/    9375 | elapsed time per iteration (ms): 554.2 | learning rate 3.900E-06 | lm loss 7.111515E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.99 | backward: 402.68 | optimizer: 5.22 | batch generator: 1.22 | data loader: 0.44
10.0.2.18:  iteration      252/    9375 | elapsed time per iteration (ms): 585.5 | learning rate 3.917E-06 | lm loss 7.116349E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.90 | backward: 428.98 | optimizer: 5.20 | batch generator: 1.27 | data loader: 0.45
10.0.2.18:  iteration      253/    9375 | elapsed time per iteration (ms): 552.5 | learning rate 3.933E-06 | lm loss 7.107878E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.91 | backward: 397.33 | optimizer: 5.21 | batch generator: 1.21 | data loader: 0.43
10.0.2.18:  iteration      254/    9375 | elapsed time per iteration (ms): 497.4 | learning rate 3.950E-06 | lm loss 7.114173E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.31 | backward: 345.30 | optimizer: 5.21 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      255/    9375 | elapsed time per iteration (ms): 534.4 | learning rate 3.967E-06 | lm loss 7.089581E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.52 | backward: 358.46 | optimizer: 5.21 | batch generator: 1.19 | data loader: 0.48
10.0.2.18:  iteration      256/    9375 | elapsed time per iteration (ms): 532.4 | learning rate 3.983E-06 | lm loss 7.068394E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.26 | backward: 373.49 | optimizer: 5.19 | batch generator: 1.22 | data loader: 0.44
10.0.2.18:  iteration      257/    9375 | elapsed time per iteration (ms): 536.5 | learning rate 4.000E-06 | lm loss 7.069542E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.39 | backward: 388.76 | optimizer: 5.19 | batch generator: 1.18 | data loader: 0.44
10.0.2.18:  iteration      258/    9375 | elapsed time per iteration (ms): 570.7 | learning rate 4.017E-06 | lm loss 7.059405E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.67 | backward: 412.22 | optimizer: 5.18 | batch generator: 1.23 | data loader: 0.52
10.0.2.18:  iteration      259/    9375 | elapsed time per iteration (ms): 564.3 | learning rate 4.033E-06 | lm loss 7.069448E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.00 | backward: 406.21 | optimizer: 5.21 | batch generator: 1.20 | data loader: 0.43
10.0.2.18:  iteration      260/    9375 | elapsed time per iteration (ms): 512.2 | learning rate 4.050E-06 | lm loss 7.077657E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.41 | backward: 347.62 | optimizer: 5.50 | batch generator: 1.23 | data loader: 0.52
10.0.2.18:  iteration      261/    9375 | elapsed time per iteration (ms): 519.7 | learning rate 4.067E-06 | lm loss 7.024467E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.69 | backward: 365.27 | optimizer: 5.21 | batch generator: 1.79 | data loader: 0.60
10.0.2.18:  iteration      262/    9375 | elapsed time per iteration (ms): 561.2 | learning rate 4.083E-06 | lm loss 7.025867E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.45 | backward: 402.14 | optimizer: 5.29 | batch generator: 1.41 | data loader: 0.50
10.0.2.18:  iteration      263/    9375 | elapsed time per iteration (ms): 525.6 | learning rate 4.100E-06 | lm loss 7.057351E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.82 | backward: 369.84 | optimizer: 5.31 | batch generator: 1.54 | data loader: 0.50
10.0.2.18:  iteration      264/    9375 | elapsed time per iteration (ms): 532.9 | learning rate 4.117E-06 | lm loss 7.052959E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.25 | backward: 378.82 | optimizer: 5.20 | batch generator: 1.62 | data loader: 0.54
10.0.2.18:  iteration      265/    9375 | elapsed time per iteration (ms): 501.3 | learning rate 4.133E-06 | lm loss 7.062404E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.20 | backward: 369.86 | optimizer: 5.26 | batch generator: 1.37 | data loader: 0.45
10.0.2.18:  iteration      266/    9375 | elapsed time per iteration (ms): 527.2 | learning rate 4.150E-06 | lm loss 7.020861E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.45 | backward: 381.24 | optimizer: 5.22 | batch generator: 1.62 | data loader: 0.65
10.0.2.18:  iteration      267/    9375 | elapsed time per iteration (ms): 518.4 | learning rate 4.167E-06 | lm loss 7.039503E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.22 | backward: 375.75 | optimizer: 5.21 | batch generator: 1.38 | data loader: 0.45
10.0.2.18:  iteration      268/    9375 | elapsed time per iteration (ms): 572.2 | learning rate 4.183E-06 | lm loss 7.014338E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.82 | backward: 426.75 | optimizer: 5.21 | batch generator: 1.41 | data loader: 0.54
10.0.2.18:  iteration      269/    9375 | elapsed time per iteration (ms): 542.5 | learning rate 4.200E-06 | lm loss 7.024821E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.54 | backward: 386.48 | optimizer: 5.19 | batch generator: 1.18 | data loader: 0.43
10.0.2.18:  iteration      270/    9375 | elapsed time per iteration (ms): 568.8 | learning rate 4.217E-06 | lm loss 7.013416E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.94 | backward: 414.76 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.38
10.0.2.18:  iteration      271/    9375 | elapsed time per iteration (ms): 560.9 | learning rate 4.233E-06 | lm loss 7.010496E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.94 | backward: 406.63 | optimizer: 5.17 | batch generator: 1.17 | data loader: 0.41
10.0.2.18:  iteration      272/    9375 | elapsed time per iteration (ms): 561.2 | learning rate 4.250E-06 | lm loss 7.023921E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.46 | backward: 406.26 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.49
10.0.2.18:  iteration      273/    9375 | elapsed time per iteration (ms): 587.1 | learning rate 4.267E-06 | lm loss 7.020160E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.52 | backward: 416.42 | optimizer: 5.21 | batch generator: 1.23 | data loader: 0.52
10.0.2.18:  iteration      274/    9375 | elapsed time per iteration (ms): 531.7 | learning rate 4.283E-06 | lm loss 7.000858E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.57 | backward: 380.44 | optimizer: 5.18 | batch generator: 1.21 | data loader: 0.44
10.0.2.18:  iteration      275/    9375 | elapsed time per iteration (ms): 550.3 | learning rate 4.300E-06 | lm loss 7.038729E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.72 | backward: 397.92 | optimizer: 5.21 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      276/    9375 | elapsed time per iteration (ms): 540.7 | learning rate 4.317E-06 | lm loss 6.998191E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.03 | backward: 387.05 | optimizer: 5.17 | batch generator: 1.41 | data loader: 0.50
10.0.2.18:  iteration      277/    9375 | elapsed time per iteration (ms): 517.2 | learning rate 4.333E-06 | lm loss 6.978253E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.61 | backward: 362.13 | optimizer: 5.19 | batch generator: 1.15 | data loader: 0.38
10.0.2.18:  iteration      278/    9375 | elapsed time per iteration (ms): 466.8 | learning rate 4.350E-06 | lm loss 6.954709E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.57 | backward: 322.70 | optimizer: 5.16 | batch generator: 1.19 | data loader: 0.50
10.0.2.18:  iteration      279/    9375 | elapsed time per iteration (ms): 544.6 | learning rate 4.367E-06 | lm loss 6.978016E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.28 | backward: 385.44 | optimizer: 5.23 | batch generator: 1.14 | data loader: 0.38
10.0.2.18:  iteration      280/    9375 | elapsed time per iteration (ms): 514.1 | learning rate 4.383E-06 | lm loss 6.969416E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.28 | backward: 361.58 | optimizer: 5.20 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      281/    9375 | elapsed time per iteration (ms): 503.8 | learning rate 4.400E-06 | lm loss 7.012938E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.89 | backward: 344.78 | optimizer: 5.20 | batch generator: 1.68 | data loader: 0.51
10.0.2.18:  iteration      282/    9375 | elapsed time per iteration (ms): 494.3 | learning rate 4.417E-06 | lm loss 6.999038E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.26 | backward: 338.04 | optimizer: 5.17 | batch generator: 1.20 | data loader: 0.51
10.0.2.18:  iteration      283/    9375 | elapsed time per iteration (ms): 691.8 | learning rate 4.433E-06 | lm loss 6.949945E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.68 | backward: 378.90 | optimizer: 5.23 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      284/    9375 | elapsed time per iteration (ms): 530.5 | learning rate 4.450E-06 | lm loss 6.987412E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.08 | backward: 377.76 | optimizer: 5.22 | batch generator: 1.29 | data loader: 0.60
10.0.2.18:  iteration      285/    9375 | elapsed time per iteration (ms): 506.3 | learning rate 4.467E-06 | lm loss 6.990418E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.21 | backward: 352.22 | optimizer: 5.24 | batch generator: 1.18 | data loader: 0.38
10.0.2.18:  iteration      286/    9375 | elapsed time per iteration (ms): 520.6 | learning rate 4.483E-06 | lm loss 6.948661E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.81 | backward: 366.72 | optimizer: 5.20 | batch generator: 1.25 | data loader: 0.47
10.0.2.18:  iteration      287/    9375 | elapsed time per iteration (ms): 495.2 | learning rate 4.500E-06 | lm loss 6.926008E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.78 | backward: 348.71 | optimizer: 5.15 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      288/    9375 | elapsed time per iteration (ms): 508.3 | learning rate 4.517E-06 | lm loss 6.947106E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.58 | backward: 350.20 | optimizer: 5.19 | batch generator: 1.10 | data loader: 0.37
10.0.2.18:  iteration      289/    9375 | elapsed time per iteration (ms): 520.5 | learning rate 4.533E-06 | lm loss 6.991755E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.59 | backward: 365.96 | optimizer: 5.20 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      290/    9375 | elapsed time per iteration (ms): 541.2 | learning rate 4.550E-06 | lm loss 6.934850E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.06 | backward: 370.16 | optimizer: 5.20 | batch generator: 1.17 | data loader: 0.41
10.0.2.18:  iteration      291/    9375 | elapsed time per iteration (ms): 538.7 | learning rate 4.567E-06 | lm loss 6.946551E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.52 | backward: 369.43 | optimizer: 5.17 | batch generator: 1.11 | data loader: 0.37
10.0.2.18:  iteration      292/    9375 | elapsed time per iteration (ms): 510.7 | learning rate 4.583E-06 | lm loss 6.924340E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.74 | backward: 364.74 | optimizer: 5.18 | batch generator: 1.10 | data loader: 0.37
10.0.2.18:  iteration      293/    9375 | elapsed time per iteration (ms): 558.7 | learning rate 4.600E-06 | lm loss 6.930934E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.04 | backward: 412.58 | optimizer: 5.20 | batch generator: 1.16 | data loader: 0.46
10.0.2.18:  iteration      294/    9375 | elapsed time per iteration (ms): 534.6 | learning rate 4.617E-06 | lm loss 6.930060E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.92 | backward: 379.95 | optimizer: 5.19 | batch generator: 1.20 | data loader: 0.49
10.0.2.18:  iteration      295/    9375 | elapsed time per iteration (ms): 512.9 | learning rate 4.633E-06 | lm loss 6.946416E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.15 | backward: 361.73 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.45
10.0.2.18:  iteration      296/    9375 | elapsed time per iteration (ms): 519.8 | learning rate 4.650E-06 | lm loss 6.888100E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.80 | backward: 369.53 | optimizer: 5.20 | batch generator: 1.20 | data loader: 0.51
10.0.2.18:  iteration      297/    9375 | elapsed time per iteration (ms): 518.5 | learning rate 4.667E-06 | lm loss 6.896614E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.50 | backward: 369.08 | optimizer: 5.24 | batch generator: 1.19 | data loader: 0.44
10.0.2.18:  iteration      298/    9375 | elapsed time per iteration (ms): 533.7 | learning rate 4.683E-06 | lm loss 6.927757E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.33 | backward: 383.62 | optimizer: 5.28 | batch generator: 1.25 | data loader: 0.48
10.0.2.18:  iteration      299/    9375 | elapsed time per iteration (ms): 536.9 | learning rate 4.700E-06 | lm loss 6.932386E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.93 | backward: 385.88 | optimizer: 5.19 | batch generator: 1.28 | data loader: 0.45
10.0.2.18:  iteration      300/    9375 | elapsed time per iteration (ms): 571.8 | learning rate 4.717E-06 | lm loss 6.894915E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.26 | backward: 408.00 | optimizer: 5.18 | batch generator: 1.24 | data loader: 0.47
10.0.2.18:  iteration      301/    9375 | elapsed time per iteration (ms): 536.2 | learning rate 4.733E-06 | lm loss 6.899322E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.09 | backward: 381.40 | optimizer: 5.20 | batch generator: 1.14 | data loader: 0.40
10.0.2.18:  iteration      302/    9375 | elapsed time per iteration (ms): 564.0 | learning rate 4.750E-06 | lm loss 6.929180E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.30 | backward: 413.05 | optimizer: 5.25 | batch generator: 1.17 | data loader: 0.43
10.0.2.18:  iteration      303/    9375 | elapsed time per iteration (ms): 587.0 | learning rate 4.767E-06 | lm loss 6.906824E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.95 | backward: 425.93 | optimizer: 5.21 | batch generator: 1.31 | data loader: 0.60
10.0.2.18:  iteration      304/    9375 | elapsed time per iteration (ms): 484.7 | learning rate 4.783E-06 | lm loss 6.878670E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.84 | backward: 333.31 | optimizer: 5.19 | batch generator: 1.41 | data loader: 0.52
10.0.2.18:  iteration      305/    9375 | elapsed time per iteration (ms): 556.1 | learning rate 4.800E-06 | lm loss 6.886514E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.50 | backward: 383.55 | optimizer: 5.21 | batch generator: 1.17 | data loader: 0.41
10.0.2.18:  iteration      306/    9375 | elapsed time per iteration (ms): 553.0 | learning rate 4.817E-06 | lm loss 6.898319E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.22 | backward: 397.34 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.40
10.0.2.18:  iteration      307/    9375 | elapsed time per iteration (ms): 522.8 | learning rate 4.833E-06 | lm loss 6.883608E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.71 | backward: 388.34 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.38
10.0.2.18:  iteration      308/    9375 | elapsed time per iteration (ms): 525.4 | learning rate 4.850E-06 | lm loss 6.911693E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.40 | backward: 368.91 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.48
10.0.2.18:  iteration      309/    9375 | elapsed time per iteration (ms): 585.9 | learning rate 4.867E-06 | lm loss 6.890162E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.44 | backward: 434.71 | optimizer: 5.21 | batch generator: 1.17 | data loader: 0.49
10.0.2.18:  iteration      310/    9375 | elapsed time per iteration (ms): 576.4 | learning rate 4.883E-06 | lm loss 6.886492E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.28 | backward: 421.96 | optimizer: 5.16 | batch generator: 1.26 | data loader: 0.53
10.0.2.18:  iteration      311/    9375 | elapsed time per iteration (ms): 582.2 | learning rate 4.900E-06 | lm loss 6.871307E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.65 | backward: 412.32 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration      312/    9375 | elapsed time per iteration (ms): 511.9 | learning rate 4.917E-06 | lm loss 6.876210E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.32 | backward: 361.25 | optimizer: 5.18 | batch generator: 1.30 | data loader: 0.49
10.0.2.18:  iteration      313/    9375 | elapsed time per iteration (ms): 566.8 | learning rate 4.933E-06 | lm loss 6.916133E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.61 | backward: 415.03 | optimizer: 5.20 | batch generator: 1.16 | data loader: 0.41
10.0.2.18:  iteration      314/    9375 | elapsed time per iteration (ms): 518.9 | learning rate 4.950E-06 | lm loss 6.841998E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.81 | backward: 364.59 | optimizer: 5.18 | batch generator: 1.24 | data loader: 0.53
10.0.2.18:  iteration      315/    9375 | elapsed time per iteration (ms): 530.8 | learning rate 4.967E-06 | lm loss 6.872000E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.60 | backward: 384.16 | optimizer: 5.21 | batch generator: 1.24 | data loader: 0.54
10.0.2.18:  iteration      316/    9375 | elapsed time per iteration (ms): 565.0 | learning rate 4.983E-06 | lm loss 6.868193E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.01 | backward: 411.50 | optimizer: 5.19 | batch generator: 1.24 | data loader: 0.45
10.0.2.18:  iteration      317/    9375 | elapsed time per iteration (ms): 556.5 | learning rate 5.000E-06 | lm loss 6.877712E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.55 | backward: 400.89 | optimizer: 5.27 | batch generator: 1.12 | data loader: 0.37
10.0.2.18:  iteration      318/    9375 | elapsed time per iteration (ms): 479.5 | learning rate 5.017E-06 | lm loss 6.851993E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.94 | backward: 344.48 | optimizer: 5.18 | batch generator: 1.29 | data loader: 0.44
10.0.2.18:  iteration      319/    9375 | elapsed time per iteration (ms): 569.6 | learning rate 5.033E-06 | lm loss 6.821591E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.77 | backward: 416.33 | optimizer: 5.23 | batch generator: 1.15 | data loader: 0.39
10.0.2.18:  iteration      320/    9375 | elapsed time per iteration (ms): 519.1 | learning rate 5.050E-06 | lm loss 6.811798E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.82 | backward: 364.87 | optimizer: 5.20 | batch generator: 1.27 | data loader: 0.56
10.0.2.18:  iteration      321/    9375 | elapsed time per iteration (ms): 562.8 | learning rate 5.067E-06 | lm loss 6.848391E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.02 | backward: 397.72 | optimizer: 5.21 | batch generator: 1.24 | data loader: 0.52
10.0.2.18:  iteration      322/    9375 | elapsed time per iteration (ms): 492.6 | learning rate 5.083E-06 | lm loss 6.853851E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.01 | backward: 346.90 | optimizer: 5.23 | batch generator: 1.26 | data loader: 0.46
10.0.2.18:  iteration      323/    9375 | elapsed time per iteration (ms): 491.5 | learning rate 5.100E-06 | lm loss 6.816286E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.22 | backward: 336.55 | optimizer: 5.18 | batch generator: 1.21 | data loader: 0.46
10.0.2.18:  iteration      324/    9375 | elapsed time per iteration (ms): 524.2 | learning rate 5.117E-06 | lm loss 6.785347E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.01 | backward: 363.92 | optimizer: 5.21 | batch generator: 1.22 | data loader: 0.51
10.0.2.18:  iteration      325/    9375 | elapsed time per iteration (ms): 554.6 | learning rate 5.133E-06 | lm loss 6.847082E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.35 | backward: 407.21 | optimizer: 5.18 | batch generator: 1.28 | data loader: 0.57
10.0.2.18:  iteration      326/    9375 | elapsed time per iteration (ms): 558.0 | learning rate 5.150E-06 | lm loss 6.816031E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.60 | backward: 401.46 | optimizer: 5.20 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      327/    9375 | elapsed time per iteration (ms): 553.1 | learning rate 5.167E-06 | lm loss 6.797833E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.43 | backward: 399.90 | optimizer: 5.19 | batch generator: 1.31 | data loader: 0.57
10.0.2.18:  iteration      328/    9375 | elapsed time per iteration (ms): 590.2 | learning rate 5.183E-06 | lm loss 6.830422E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.98 | backward: 420.26 | optimizer: 5.21 | batch generator: 1.18 | data loader: 0.49
10.0.2.18:  iteration      329/    9375 | elapsed time per iteration (ms): 565.2 | learning rate 5.200E-06 | lm loss 6.816834E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.30 | backward: 410.83 | optimizer: 5.21 | batch generator: 1.24 | data loader: 0.50
10.0.2.18:  iteration      330/    9375 | elapsed time per iteration (ms): 551.9 | learning rate 5.217E-06 | lm loss 6.798513E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.49 | backward: 397.08 | optimizer: 5.18 | batch generator: 1.23 | data loader: 0.44
10.0.2.18:  iteration      331/    9375 | elapsed time per iteration (ms): 559.8 | learning rate 5.233E-06 | lm loss 6.859808E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.94 | backward: 407.24 | optimizer: 5.19 | batch generator: 1.18 | data loader: 0.48
10.0.2.18:  iteration      332/    9375 | elapsed time per iteration (ms): 528.2 | learning rate 5.250E-06 | lm loss 6.829982E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.49 | backward: 365.88 | optimizer: 5.26 | batch generator: 1.23 | data loader: 0.51
10.0.2.18:  iteration      333/    9375 | elapsed time per iteration (ms): 522.5 | learning rate 5.267E-06 | lm loss 6.850510E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.83 | backward: 375.04 | optimizer: 5.22 | batch generator: 1.73 | data loader: 0.68
10.0.2.18:  iteration      334/    9375 | elapsed time per iteration (ms): 526.6 | learning rate 5.283E-06 | lm loss 6.835317E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.53 | backward: 375.15 | optimizer: 5.21 | batch generator: 1.42 | data loader: 0.48
10.0.2.18:  iteration      335/    9375 | elapsed time per iteration (ms): 541.4 | learning rate 5.300E-06 | lm loss 6.811877E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.27 | backward: 384.91 | optimizer: 5.19 | batch generator: 1.39 | data loader: 0.45
10.0.2.18:  iteration      336/    9375 | elapsed time per iteration (ms): 518.0 | learning rate 5.317E-06 | lm loss 6.806692E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.42 | backward: 368.22 | optimizer: 5.25 | batch generator: 1.37 | data loader: 0.45
10.0.2.18:  iteration      337/    9375 | elapsed time per iteration (ms): 580.9 | learning rate 5.333E-06 | lm loss 6.804648E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.72 | backward: 438.23 | optimizer: 5.26 | batch generator: 1.88 | data loader: 0.65
10.0.2.18:  iteration      338/    9375 | elapsed time per iteration (ms): 585.1 | learning rate 5.350E-06 | lm loss 6.825221E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.28 | backward: 438.00 | optimizer: 5.23 | batch generator: 1.45 | data loader: 0.49
10.0.2.18:  iteration      339/    9375 | elapsed time per iteration (ms): 575.6 | learning rate 5.367E-06 | lm loss 6.823180E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.29 | backward: 425.18 | optimizer: 5.22 | batch generator: 1.46 | data loader: 0.49
10.0.2.18:  iteration      340/    9375 | elapsed time per iteration (ms): 572.7 | learning rate 5.383E-06 | lm loss 6.779527E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.74 | backward: 422.50 | optimizer: 5.22 | batch generator: 1.41 | data loader: 0.47
10.0.2.18:  iteration      341/    9375 | elapsed time per iteration (ms): 568.6 | learning rate 5.400E-06 | lm loss 6.789324E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.36 | backward: 418.90 | optimizer: 5.26 | batch generator: 1.47 | data loader: 0.58
10.0.2.18:  iteration      342/    9375 | elapsed time per iteration (ms): 485.8 | learning rate 5.417E-06 | lm loss 6.778321E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.76 | backward: 354.19 | optimizer: 5.20 | batch generator: 1.58 | data loader: 0.50
10.0.2.18:  iteration      343/    9375 | elapsed time per iteration (ms): 514.5 | learning rate 5.433E-06 | lm loss 6.846819E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.62 | backward: 367.93 | optimizer: 5.24 | batch generator: 1.21 | data loader: 0.45
10.0.2.18:  iteration      344/    9375 | elapsed time per iteration (ms): 565.7 | learning rate 5.450E-06 | lm loss 6.824957E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.87 | backward: 400.04 | optimizer: 5.16 | batch generator: 1.31 | data loader: 0.47
10.0.2.18:  iteration      345/    9375 | elapsed time per iteration (ms): 552.5 | learning rate 5.467E-06 | lm loss 6.757207E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.48 | backward: 398.32 | optimizer: 5.19 | batch generator: 1.12 | data loader: 0.38
10.0.2.18:  iteration      346/    9375 | elapsed time per iteration (ms): 584.0 | learning rate 5.483E-06 | lm loss 6.788458E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.42 | backward: 423.51 | optimizer: 5.19 | batch generator: 1.23 | data loader: 0.42
10.0.2.18:  iteration      347/    9375 | elapsed time per iteration (ms): 570.0 | learning rate 5.500E-06 | lm loss 6.810378E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.59 | backward: 418.35 | optimizer: 5.20 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      348/    9375 | elapsed time per iteration (ms): 583.6 | learning rate 5.517E-06 | lm loss 6.751837E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.61 | backward: 422.34 | optimizer: 5.18 | batch generator: 1.17 | data loader: 0.48
10.0.2.18:  iteration      349/    9375 | elapsed time per iteration (ms): 516.7 | learning rate 5.533E-06 | lm loss 6.778900E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.10 | backward: 361.01 | optimizer: 5.22 | batch generator: 1.15 | data loader: 0.46
10.0.2.18:  iteration      350/    9375 | elapsed time per iteration (ms): 514.8 | learning rate 5.550E-06 | lm loss 6.746268E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.15 | backward: 369.08 | optimizer: 5.17 | batch generator: 1.35 | data loader: 0.61
10.0.2.18:  iteration      351/    9375 | elapsed time per iteration (ms): 784.8 | learning rate 5.567E-06 | lm loss 6.760411E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.93 | backward: 336.08 | optimizer: 5.17 | batch generator: 1.20 | data loader: 0.50
10.0.2.18:  iteration      352/    9375 | elapsed time per iteration (ms): 527.2 | learning rate 5.583E-06 | lm loss 6.725765E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.10 | backward: 379.12 | optimizer: 5.24 | batch generator: 1.13 | data loader: 0.38
10.0.2.18:  iteration      353/    9375 | elapsed time per iteration (ms): 512.0 | learning rate 5.600E-06 | lm loss 6.772482E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.23 | backward: 364.52 | optimizer: 5.20 | batch generator: 1.29 | data loader: 0.56
10.0.2.18:  iteration      354/    9375 | elapsed time per iteration (ms): 526.8 | learning rate 5.617E-06 | lm loss 6.779249E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.83 | backward: 368.96 | optimizer: 5.21 | batch generator: 1.24 | data loader: 0.44
10.0.2.18:  iteration      355/    9375 | elapsed time per iteration (ms): 520.3 | learning rate 5.633E-06 | lm loss 6.750410E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.73 | backward: 365.58 | optimizer: 5.24 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      356/    9375 | elapsed time per iteration (ms): 511.3 | learning rate 5.650E-06 | lm loss 6.764823E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.64 | backward: 365.40 | optimizer: 5.21 | batch generator: 1.33 | data loader: 0.60
10.0.2.18:  iteration      357/    9375 | elapsed time per iteration (ms): 503.5 | learning rate 5.667E-06 | lm loss 6.732364E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.29 | backward: 345.51 | optimizer: 5.23 | batch generator: 1.17 | data loader: 0.42
10.0.2.18:  iteration      358/    9375 | elapsed time per iteration (ms): 589.8 | learning rate 5.683E-06 | lm loss 6.748666E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.22 | backward: 415.06 | optimizer: 5.24 | batch generator: 1.31 | data loader: 0.47
10.0.2.18:  iteration      359/    9375 | elapsed time per iteration (ms): 491.4 | learning rate 5.700E-06 | lm loss 6.760061E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.39 | backward: 347.68 | optimizer: 5.19 | batch generator: 1.29 | data loader: 0.45
10.0.2.18:  iteration      360/    9375 | elapsed time per iteration (ms): 523.6 | learning rate 5.717E-06 | lm loss 6.768955E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.08 | backward: 364.99 | optimizer: 5.20 | batch generator: 1.27 | data loader: 0.47
10.0.2.18:  iteration      361/    9375 | elapsed time per iteration (ms): 497.7 | learning rate 5.733E-06 | lm loss 6.759017E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.64 | backward: 348.31 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      362/    9375 | elapsed time per iteration (ms): 525.7 | learning rate 5.750E-06 | lm loss 6.733393E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.07 | backward: 369.52 | optimizer: 5.19 | batch generator: 1.17 | data loader: 0.41
10.0.2.18:  iteration      363/    9375 | elapsed time per iteration (ms): 530.0 | learning rate 5.767E-06 | lm loss 6.741769E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.95 | backward: 382.60 | optimizer: 5.25 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      364/    9375 | elapsed time per iteration (ms): 554.5 | learning rate 5.783E-06 | lm loss 6.733153E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.49 | backward: 400.16 | optimizer: 5.17 | batch generator: 1.25 | data loader: 0.42
10.0.2.18:  iteration      365/    9375 | elapsed time per iteration (ms): 522.2 | learning rate 5.800E-06 | lm loss 6.728994E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.29 | backward: 368.23 | optimizer: 5.25 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      366/    9375 | elapsed time per iteration (ms): 527.5 | learning rate 5.817E-06 | lm loss 6.720964E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.22 | backward: 370.11 | optimizer: 5.23 | batch generator: 1.36 | data loader: 0.50
10.0.2.18:  iteration      367/    9375 | elapsed time per iteration (ms): 528.7 | learning rate 5.833E-06 | lm loss 6.712444E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.35 | backward: 370.59 | optimizer: 5.20 | batch generator: 1.35 | data loader: 0.52
10.0.2.18:  iteration      368/    9375 | elapsed time per iteration (ms): 508.3 | learning rate 5.850E-06 | lm loss 6.728592E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.40 | backward: 350.05 | optimizer: 5.18 | batch generator: 1.32 | data loader: 0.60
10.0.2.18:  iteration      369/    9375 | elapsed time per iteration (ms): 543.8 | learning rate 5.867E-06 | lm loss 6.725388E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.29 | backward: 397.48 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.44
10.0.2.18:  iteration      370/    9375 | elapsed time per iteration (ms): 493.6 | learning rate 5.883E-06 | lm loss 6.722445E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.42 | backward: 340.74 | optimizer: 5.18 | batch generator: 1.24 | data loader: 0.54
10.0.2.18:  iteration      371/    9375 | elapsed time per iteration (ms): 508.9 | learning rate 5.900E-06 | lm loss 6.708449E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.54 | backward: 345.43 | optimizer: 5.16 | batch generator: 1.18 | data loader: 0.47
10.0.2.18:  iteration      372/    9375 | elapsed time per iteration (ms): 525.0 | learning rate 5.917E-06 | lm loss 6.718238E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.68 | backward: 366.66 | optimizer: 5.20 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      373/    9375 | elapsed time per iteration (ms): 523.4 | learning rate 5.933E-06 | lm loss 6.712042E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.32 | backward: 359.25 | optimizer: 5.22 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      374/    9375 | elapsed time per iteration (ms): 508.7 | learning rate 5.950E-06 | lm loss 6.732721E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.14 | backward: 361.33 | optimizer: 5.23 | batch generator: 1.13 | data loader: 0.45
10.0.2.18:  iteration      375/    9375 | elapsed time per iteration (ms): 501.8 | learning rate 5.967E-06 | lm loss 6.668850E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.26 | backward: 346.72 | optimizer: 5.21 | batch generator: 1.28 | data loader: 0.47
10.0.2.18:  iteration      376/    9375 | elapsed time per iteration (ms): 523.2 | learning rate 5.983E-06 | lm loss 6.692390E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.67 | backward: 364.49 | optimizer: 5.17 | batch generator: 1.20 | data loader: 0.51
10.0.2.18:  iteration      377/    9375 | elapsed time per iteration (ms): 535.9 | learning rate 6.000E-06 | lm loss 6.703332E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 124.94 | backward: 381.04 | optimizer: 5.33 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      378/    9375 | elapsed time per iteration (ms): 528.2 | learning rate 6.017E-06 | lm loss 6.688162E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.40 | backward: 375.81 | optimizer: 5.34 | batch generator: 1.49 | data loader: 0.48
10.0.2.18:  iteration      379/    9375 | elapsed time per iteration (ms): 513.4 | learning rate 6.033E-06 | lm loss 6.695539E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.96 | backward: 369.54 | optimizer: 5.28 | batch generator: 1.58 | data loader: 0.52
10.0.2.18:  iteration      380/    9375 | elapsed time per iteration (ms): 531.2 | learning rate 6.050E-06 | lm loss 6.698887E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.33 | backward: 374.24 | optimizer: 5.19 | batch generator: 1.40 | data loader: 0.54
10.0.2.18:  iteration      381/    9375 | elapsed time per iteration (ms): 534.1 | learning rate 6.067E-06 | lm loss 6.712242E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.21 | backward: 388.43 | optimizer: 5.19 | batch generator: 1.22 | data loader: 0.41
10.0.2.18:  iteration      382/    9375 | elapsed time per iteration (ms): 491.0 | learning rate 6.083E-06 | lm loss 6.704167E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.14 | backward: 357.52 | optimizer: 5.19 | batch generator: 1.15 | data loader: 0.40
10.0.2.18:  iteration      383/    9375 | elapsed time per iteration (ms): 530.2 | learning rate 6.100E-06 | lm loss 6.685892E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.01 | backward: 371.72 | optimizer: 5.23 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      384/    9375 | elapsed time per iteration (ms): 517.4 | learning rate 6.117E-06 | lm loss 6.661255E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.33 | backward: 370.78 | optimizer: 5.21 | batch generator: 1.31 | data loader: 0.58
10.0.2.18:  iteration      385/    9375 | elapsed time per iteration (ms): 498.6 | learning rate 6.133E-06 | lm loss 6.686698E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.58 | backward: 354.77 | optimizer: 5.28 | batch generator: 1.20 | data loader: 0.41
10.0.2.18:  iteration      386/    9375 | elapsed time per iteration (ms): 525.1 | learning rate 6.150E-06 | lm loss 6.685812E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.26 | backward: 365.16 | optimizer: 5.17 | batch generator: 1.45 | data loader: 0.54
10.0.2.18:  iteration      387/    9375 | elapsed time per iteration (ms): 531.7 | learning rate 6.167E-06 | lm loss 6.671772E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.08 | backward: 367.83 | optimizer: 5.21 | batch generator: 1.23 | data loader: 0.44
10.0.2.18:  iteration      388/    9375 | elapsed time per iteration (ms): 794.6 | learning rate 6.183E-06 | lm loss 6.685951E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.61 | backward: 380.65 | optimizer: 5.17 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      389/    9375 | elapsed time per iteration (ms): 504.3 | learning rate 6.200E-06 | lm loss 6.685627E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.44 | backward: 340.01 | optimizer: 5.20 | batch generator: 1.17 | data loader: 0.47
10.0.2.18:  iteration      390/    9375 | elapsed time per iteration (ms): 505.2 | learning rate 6.217E-06 | lm loss 6.681441E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.01 | backward: 355.87 | optimizer: 5.22 | batch generator: 1.24 | data loader: 0.53
10.0.2.18:  iteration      391/    9375 | elapsed time per iteration (ms): 497.8 | learning rate 6.233E-06 | lm loss 6.650432E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.18 | backward: 339.44 | optimizer: 5.18 | batch generator: 1.29 | data loader: 0.47
10.0.2.18:  iteration      392/    9375 | elapsed time per iteration (ms): 494.1 | learning rate 6.250E-06 | lm loss 6.671878E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.46 | backward: 345.11 | optimizer: 5.18 | batch generator: 1.20 | data loader: 0.43
10.0.2.18:  iteration      393/    9375 | elapsed time per iteration (ms): 534.7 | learning rate 6.267E-06 | lm loss 6.640272E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.99 | backward: 373.15 | optimizer: 5.25 | batch generator: 1.25 | data loader: 0.54
10.0.2.18:  iteration      394/    9375 | elapsed time per iteration (ms): 535.8 | learning rate 6.283E-06 | lm loss 6.656808E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.86 | backward: 373.95 | optimizer: 5.24 | batch generator: 1.32 | data loader: 0.48
10.0.2.18:  iteration      395/    9375 | elapsed time per iteration (ms): 498.0 | learning rate 6.300E-06 | lm loss 6.637168E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.43 | backward: 337.90 | optimizer: 5.29 | batch generator: 1.19 | data loader: 0.44
10.0.2.18:  iteration      396/    9375 | elapsed time per iteration (ms): 525.5 | learning rate 6.317E-06 | lm loss 6.685071E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.52 | backward: 365.44 | optimizer: 5.21 | batch generator: 1.35 | data loader: 0.63
10.0.2.18:  iteration      397/    9375 | elapsed time per iteration (ms): 488.7 | learning rate 6.333E-06 | lm loss 6.630998E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.31 | backward: 354.82 | optimizer: 5.20 | batch generator: 1.26 | data loader: 0.46
10.0.2.18:  iteration      398/    9375 | elapsed time per iteration (ms): 537.6 | learning rate 6.350E-06 | lm loss 6.613094E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.61 | backward: 378.32 | optimizer: 5.24 | batch generator: 1.24 | data loader: 0.53
10.0.2.18:  iteration      399/    9375 | elapsed time per iteration (ms): 517.1 | learning rate 6.367E-06 | lm loss 6.633372E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.48 | backward: 375.06 | optimizer: 5.26 | batch generator: 1.66 | data loader: 0.58
10.0.2.18:  iteration      400/    9375 | elapsed time per iteration (ms): 516.3 | learning rate 6.383E-06 | lm loss 6.638892E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.55 | backward: 366.02 | optimizer: 5.28 | batch generator: 1.47 | data loader: 0.58
10.0.2.18:  iteration      401/    9375 | elapsed time per iteration (ms): 505.2 | learning rate 6.400E-06 | lm loss 6.678683E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.97 | backward: 350.38 | optimizer: 5.29 | batch generator: 1.50 | data loader: 0.49
10.0.2.18:  iteration      402/    9375 | elapsed time per iteration (ms): 514.8 | learning rate 6.417E-06 | lm loss 6.647801E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.70 | backward: 359.05 | optimizer: 5.23 | batch generator: 1.67 | data loader: 0.56
10.0.2.18:  iteration      403/    9375 | elapsed time per iteration (ms): 526.3 | learning rate 6.433E-06 | lm loss 6.629461E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.80 | backward: 375.15 | optimizer: 5.24 | batch generator: 1.44 | data loader: 0.47
10.0.2.18:  iteration      404/    9375 | elapsed time per iteration (ms): 501.8 | learning rate 6.450E-06 | lm loss 6.602847E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.24 | backward: 358.65 | optimizer: 5.20 | batch generator: 1.56 | data loader: 0.62
10.0.2.18:  iteration      405/    9375 | elapsed time per iteration (ms): 451.6 | learning rate 6.467E-06 | lm loss 6.598180E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.61 | backward: 320.66 | optimizer: 5.22 | batch generator: 1.43 | data loader: 0.48
10.0.2.18:  iteration      406/    9375 | elapsed time per iteration (ms): 524.6 | learning rate 6.483E-06 | lm loss 6.619251E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.98 | backward: 371.22 | optimizer: 5.24 | batch generator: 1.35 | data loader: 0.44
10.0.2.18:  iteration      407/    9375 | elapsed time per iteration (ms): 512.3 | learning rate 6.500E-06 | lm loss 6.631240E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.47 | backward: 362.28 | optimizer: 5.25 | batch generator: 1.53 | data loader: 0.50
10.0.2.18:  iteration      408/    9375 | elapsed time per iteration (ms): 511.1 | learning rate 6.517E-06 | lm loss 6.633205E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.22 | backward: 361.87 | optimizer: 5.27 | batch generator: 1.43 | data loader: 0.48
10.0.2.18:  iteration      409/    9375 | elapsed time per iteration (ms): 526.4 | learning rate 6.533E-06 | lm loss 6.627311E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.54 | backward: 373.29 | optimizer: 5.22 | batch generator: 1.49 | data loader: 0.51
10.0.2.18:  iteration      410/    9375 | elapsed time per iteration (ms): 533.8 | learning rate 6.550E-06 | lm loss 6.602679E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.03 | backward: 374.27 | optimizer: 5.21 | batch generator: 1.41 | data loader: 0.43
10.0.2.18:  iteration      411/    9375 | elapsed time per iteration (ms): 545.3 | learning rate 6.567E-06 | lm loss 6.605396E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.89 | backward: 392.79 | optimizer: 5.19 | batch generator: 1.40 | data loader: 0.46
10.0.2.18:  iteration      412/    9375 | elapsed time per iteration (ms): 520.6 | learning rate 6.583E-06 | lm loss 6.585422E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.24 | backward: 376.95 | optimizer: 5.19 | batch generator: 1.43 | data loader: 0.48
10.0.2.18:  iteration      413/    9375 | elapsed time per iteration (ms): 523.5 | learning rate 6.600E-06 | lm loss 6.607117E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.75 | backward: 377.76 | optimizer: 5.24 | batch generator: 1.43 | data loader: 0.48
10.0.2.18:  iteration      414/    9375 | elapsed time per iteration (ms): 543.9 | learning rate 6.617E-06 | lm loss 6.591542E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.69 | backward: 390.37 | optimizer: 5.22 | batch generator: 1.45 | data loader: 0.50
10.0.2.18:  iteration      415/    9375 | elapsed time per iteration (ms): 1269.0 | learning rate 6.633E-06 | lm loss 6.565144E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.27 | backward: 363.25 | optimizer: 769.52 | batch generator: 1.62 | data loader: 0.65
10.0.2.18:  iteration      416/    9375 | elapsed time per iteration (ms): 466.5 | learning rate 6.650E-06 | lm loss 6.621749E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.92 | backward: 365.15 | optimizer: 5.24 | batch generator: 1.77 | data loader: 0.56
10.0.2.18:  iteration      417/    9375 | elapsed time per iteration (ms): 528.7 | learning rate 6.667E-06 | lm loss 6.601336E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.31 | backward: 378.64 | optimizer: 5.26 | batch generator: 1.44 | data loader: 0.47
10.0.2.18:  iteration      418/    9375 | elapsed time per iteration (ms): 527.1 | learning rate 6.683E-06 | lm loss 6.591411E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.14 | backward: 373.43 | optimizer: 5.21 | batch generator: 1.39 | data loader: 0.65
10.0.2.18:  iteration      419/    9375 | elapsed time per iteration (ms): 575.2 | learning rate 6.700E-06 | lm loss 6.638021E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.86 | backward: 423.60 | optimizer: 5.22 | batch generator: 1.22 | data loader: 0.45
10.0.2.18:  iteration      420/    9375 | elapsed time per iteration (ms): 582.1 | learning rate 6.717E-06 | lm loss 6.605923E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.48 | backward: 427.10 | optimizer: 5.19 | batch generator: 1.24 | data loader: 0.43
10.0.2.18:  iteration      421/    9375 | elapsed time per iteration (ms): 503.2 | learning rate 6.733E-06 | lm loss 6.592631E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.41 | backward: 350.92 | optimizer: 5.26 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      422/    9375 | elapsed time per iteration (ms): 519.2 | learning rate 6.750E-06 | lm loss 6.548158E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.59 | backward: 360.39 | optimizer: 5.17 | batch generator: 1.28 | data loader: 0.49
10.0.2.18:  iteration      423/    9375 | elapsed time per iteration (ms): 536.4 | learning rate 6.767E-06 | lm loss 6.582427E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.81 | backward: 377.16 | optimizer: 5.20 | batch generator: 1.12 | data loader: 0.45
10.0.2.18:  iteration      424/    9375 | elapsed time per iteration (ms): 502.8 | learning rate 6.783E-06 | lm loss 6.594278E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.54 | backward: 349.17 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.41
10.0.2.18:  iteration      425/    9375 | elapsed time per iteration (ms): 507.1 | learning rate 6.800E-06 | lm loss 6.584680E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.16 | backward: 342.54 | optimizer: 5.27 | batch generator: 1.23 | data loader: 0.52
10.0.2.18:  iteration      426/    9375 | elapsed time per iteration (ms): 514.4 | learning rate 6.817E-06 | lm loss 6.571267E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.85 | backward: 357.20 | optimizer: 5.21 | batch generator: 1.26 | data loader: 0.42
10.0.2.18:  iteration      427/    9375 | elapsed time per iteration (ms): 526.7 | learning rate 6.833E-06 | lm loss 6.593645E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.23 | backward: 369.61 | optimizer: 5.28 | batch generator: 1.18 | data loader: 0.41
10.0.2.18:  iteration      428/    9375 | elapsed time per iteration (ms): 708.3 | learning rate 6.850E-06 | lm loss 6.573939E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 240.83 | backward: 458.36 | optimizer: 5.20 | batch generator: 1.45 | data loader: 0.56
10.0.2.18:  iteration      429/    9375 | elapsed time per iteration (ms): 521.6 | learning rate 6.867E-06 | lm loss 6.588741E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.78 | backward: 359.37 | optimizer: 5.19 | batch generator: 1.15 | data loader: 0.43
10.0.2.18:  iteration      430/    9375 | elapsed time per iteration (ms): 537.1 | learning rate 6.883E-06 | lm loss 6.588059E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.95 | backward: 378.86 | optimizer: 5.19 | batch generator: 1.15 | data loader: 0.43
10.0.2.18:  iteration      431/    9375 | elapsed time per iteration (ms): 492.8 | learning rate 6.900E-06 | lm loss 6.534272E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.93 | backward: 348.55 | optimizer: 5.22 | batch generator: 1.07 | data loader: 0.38
10.0.2.18:  iteration      432/    9375 | elapsed time per iteration (ms): 509.9 | learning rate 6.917E-06 | lm loss 6.555508E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.91 | backward: 356.87 | optimizer: 5.22 | batch generator: 1.22 | data loader: 0.38
10.0.2.18:  iteration      433/    9375 | elapsed time per iteration (ms): 517.7 | learning rate 6.933E-06 | lm loss 6.563262E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.89 | backward: 368.39 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.49
10.0.2.18:  iteration      434/    9375 | elapsed time per iteration (ms): 489.0 | learning rate 6.950E-06 | lm loss 6.572783E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.41 | backward: 340.74 | optimizer: 5.20 | batch generator: 1.22 | data loader: 0.45
10.0.2.18:  iteration      435/    9375 | elapsed time per iteration (ms): 513.2 | learning rate 6.967E-06 | lm loss 6.570185E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.70 | backward: 358.04 | optimizer: 5.20 | batch generator: 1.19 | data loader: 0.50
10.0.2.18:  iteration      436/    9375 | elapsed time per iteration (ms): 511.2 | learning rate 6.983E-06 | lm loss 6.566980E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.09 | backward: 349.71 | optimizer: 5.22 | batch generator: 1.25 | data loader: 0.53
10.0.2.18:  iteration      437/    9375 | elapsed time per iteration (ms): 534.8 | learning rate 7.000E-06 | lm loss 6.526816E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.60 | backward: 374.83 | optimizer: 5.21 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      438/    9375 | elapsed time per iteration (ms): 578.3 | learning rate 7.017E-06 | lm loss 6.556243E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.74 | backward: 426.52 | optimizer: 5.20 | batch generator: 1.16 | data loader: 0.39
10.0.2.18:  iteration      439/    9375 | elapsed time per iteration (ms): 484.0 | learning rate 7.033E-06 | lm loss 6.542771E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.02 | backward: 347.15 | optimizer: 5.20 | batch generator: 1.19 | data loader: 0.42
10.0.2.18:  iteration      440/    9375 | elapsed time per iteration (ms): 559.3 | learning rate 7.050E-06 | lm loss 6.520741E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.50 | backward: 408.37 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      441/    9375 | elapsed time per iteration (ms): 547.7 | learning rate 7.067E-06 | lm loss 6.550709E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.26 | backward: 393.36 | optimizer: 5.30 | batch generator: 1.15 | data loader: 0.39
10.0.2.18:  iteration      442/    9375 | elapsed time per iteration (ms): 506.9 | learning rate 7.083E-06 | lm loss 6.532704E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.56 | backward: 353.05 | optimizer: 5.21 | batch generator: 1.36 | data loader: 0.49
10.0.2.18:  iteration      443/    9375 | elapsed time per iteration (ms): 521.8 | learning rate 7.100E-06 | lm loss 6.554621E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.97 | backward: 363.50 | optimizer: 5.20 | batch generator: 1.17 | data loader: 0.39
10.0.2.18:  iteration      444/    9375 | elapsed time per iteration (ms): 537.1 | learning rate 7.117E-06 | lm loss 6.533728E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.25 | backward: 363.61 | optimizer: 5.19 | batch generator: 1.20 | data loader: 0.44
10.0.2.18:  iteration      445/    9375 | elapsed time per iteration (ms): 522.6 | learning rate 7.133E-06 | lm loss 6.557850E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.33 | backward: 366.46 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.40
10.0.2.18:  iteration      446/    9375 | elapsed time per iteration (ms): 537.4 | learning rate 7.150E-06 | lm loss 6.533060E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.07 | backward: 378.05 | optimizer: 5.20 | batch generator: 1.18 | data loader: 0.42
10.0.2.18:  iteration      447/    9375 | elapsed time per iteration (ms): 527.5 | learning rate 7.167E-06 | lm loss 6.515001E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.42 | backward: 369.15 | optimizer: 5.26 | batch generator: 1.23 | data loader: 0.52
10.0.2.18:  iteration      448/    9375 | elapsed time per iteration (ms): 515.1 | learning rate 7.183E-06 | lm loss 6.504589E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.14 | backward: 358.06 | optimizer: 5.18 | batch generator: 1.41 | data loader: 0.67
10.0.2.18:  iteration      449/    9375 | elapsed time per iteration (ms): 537.9 | learning rate 7.200E-06 | lm loss 6.530129E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.47 | backward: 376.55 | optimizer: 5.25 | batch generator: 1.16 | data loader: 0.39
10.0.2.18:  iteration      450/    9375 | elapsed time per iteration (ms): 492.9 | learning rate 7.217E-06 | lm loss 6.562849E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.73 | backward: 336.55 | optimizer: 5.23 | batch generator: 2.35 | data loader: 0.97
10.0.2.18:  iteration      451/    9375 | elapsed time per iteration (ms): 537.9 | learning rate 7.233E-06 | lm loss 6.535668E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.06 | backward: 378.15 | optimizer: 5.16 | batch generator: 1.17 | data loader: 0.50
10.0.2.18:  iteration      452/    9375 | elapsed time per iteration (ms): 523.8 | learning rate 7.250E-06 | lm loss 6.519147E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.06 | backward: 368.27 | optimizer: 5.23 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      453/    9375 | elapsed time per iteration (ms): 527.6 | learning rate 7.267E-06 | lm loss 6.511026E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.69 | backward: 366.54 | optimizer: 5.18 | batch generator: 1.26 | data loader: 0.48
10.0.2.18:  iteration      454/    9375 | elapsed time per iteration (ms): 543.0 | learning rate 7.283E-06 | lm loss 6.517436E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.93 | backward: 380.93 | optimizer: 5.23 | batch generator: 1.15 | data loader: 0.49
10.0.2.18:  iteration      455/    9375 | elapsed time per iteration (ms): 526.2 | learning rate 7.300E-06 | lm loss 6.514577E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.24 | backward: 369.78 | optimizer: 5.24 | batch generator: 1.36 | data loader: 0.59
10.0.2.18:  iteration      456/    9375 | elapsed time per iteration (ms): 534.3 | learning rate 7.317E-06 | lm loss 6.507711E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.90 | backward: 379.24 | optimizer: 5.21 | batch generator: 1.32 | data loader: 0.50
10.0.2.18:  iteration      457/    9375 | elapsed time per iteration (ms): 527.6 | learning rate 7.333E-06 | lm loss 6.518988E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.56 | backward: 371.66 | optimizer: 5.21 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      458/    9375 | elapsed time per iteration (ms): 499.4 | learning rate 7.350E-06 | lm loss 6.503066E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.88 | backward: 359.74 | optimizer: 5.21 | batch generator: 1.04 | data loader: 0.35
10.0.2.18:  iteration      459/    9375 | elapsed time per iteration (ms): 497.2 | learning rate 7.367E-06 | lm loss 6.513323E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.86 | backward: 339.36 | optimizer: 5.19 | batch generator: 1.23 | data loader: 0.51
10.0.2.18:  iteration      460/    9375 | elapsed time per iteration (ms): 506.8 | learning rate 7.383E-06 | lm loss 6.509066E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.91 | backward: 350.31 | optimizer: 5.16 | batch generator: 1.15 | data loader: 0.41
10.0.2.18:  iteration      461/    9375 | elapsed time per iteration (ms): 521.1 | learning rate 7.400E-06 | lm loss 6.497669E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.85 | backward: 367.84 | optimizer: 5.19 | batch generator: 1.00 | data loader: 0.26
10.0.2.18:  iteration      462/    9375 | elapsed time per iteration (ms): 519.7 | learning rate 7.417E-06 | lm loss 6.497294E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.35 | backward: 375.38 | optimizer: 5.19 | batch generator: 1.09 | data loader: 0.31
10.0.2.18:  iteration      463/    9375 | elapsed time per iteration (ms): 533.4 | learning rate 7.433E-06 | lm loss 6.500190E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.80 | backward: 379.83 | optimizer: 5.19 | batch generator: 1.02 | data loader: 0.29
10.0.2.18:  iteration      464/    9375 | elapsed time per iteration (ms): 549.3 | learning rate 7.450E-06 | lm loss 6.497043E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.01 | backward: 393.85 | optimizer: 5.20 | batch generator: 1.02 | data loader: 0.35
10.0.2.18:  iteration      465/    9375 | elapsed time per iteration (ms): 561.1 | learning rate 7.467E-06 | lm loss 6.503186E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.57 | backward: 407.04 | optimizer: 5.19 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      466/    9375 | elapsed time per iteration (ms): 499.5 | learning rate 7.483E-06 | lm loss 6.499887E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.60 | backward: 344.08 | optimizer: 5.23 | batch generator: 1.10 | data loader: 0.34
10.0.2.18:  iteration      467/    9375 | elapsed time per iteration (ms): 568.3 | learning rate 7.500E-06 | lm loss 6.474903E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.78 | backward: 402.48 | optimizer: 5.27 | batch generator: 1.30 | data loader: 0.46
10.0.2.18:  iteration      468/    9375 | elapsed time per iteration (ms): 522.0 | learning rate 7.517E-06 | lm loss 6.453363E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.50 | backward: 373.81 | optimizer: 5.23 | batch generator: 1.58 | data loader: 0.53
10.0.2.18:  iteration      469/    9375 | elapsed time per iteration (ms): 596.2 | learning rate 7.533E-06 | lm loss 6.490860E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.32 | backward: 427.15 | optimizer: 5.21 | batch generator: 1.48 | data loader: 0.48
10.0.2.18:  iteration      470/    9375 | elapsed time per iteration (ms): 494.0 | learning rate 7.550E-06 | lm loss 6.436939E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.34 | backward: 346.11 | optimizer: 5.23 | batch generator: 1.38 | data loader: 0.45
10.0.2.18:  iteration      471/    9375 | elapsed time per iteration (ms): 522.7 | learning rate 7.567E-06 | lm loss 6.469598E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.72 | backward: 373.83 | optimizer: 5.19 | batch generator: 2.11 | data loader: 0.80
10.0.2.18:  iteration      472/    9375 | elapsed time per iteration (ms): 501.6 | learning rate 7.583E-06 | lm loss 6.447619E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.58 | backward: 340.51 | optimizer: 5.22 | batch generator: 1.19 | data loader: 0.44
10.0.2.18:  iteration      473/    9375 | elapsed time per iteration (ms): 528.7 | learning rate 7.600E-06 | lm loss 6.477085E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.80 | backward: 369.81 | optimizer: 5.26 | batch generator: 1.19 | data loader: 0.40
10.0.2.18:  iteration      474/    9375 | elapsed time per iteration (ms): 520.2 | learning rate 7.617E-06 | lm loss 6.442791E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.78 | backward: 361.92 | optimizer: 5.20 | batch generator: 1.35 | data loader: 0.49
10.0.2.18:  iteration      475/    9375 | elapsed time per iteration (ms): 531.0 | learning rate 7.633E-06 | lm loss 6.466185E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.33 | backward: 371.33 | optimizer: 5.23 | batch generator: 1.12 | data loader: 0.38
10.0.2.18:  iteration      476/    9375 | elapsed time per iteration (ms): 486.6 | learning rate 7.650E-06 | lm loss 6.467843E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.26 | backward: 327.71 | optimizer: 5.21 | batch generator: 1.29 | data loader: 0.45
10.0.2.18:  iteration      477/    9375 | elapsed time per iteration (ms): 528.9 | learning rate 7.667E-06 | lm loss 6.455617E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.87 | backward: 374.03 | optimizer: 5.23 | batch generator: 1.14 | data loader: 0.38
10.0.2.18:  iteration      478/    9375 | elapsed time per iteration (ms): 507.5 | learning rate 7.683E-06 | lm loss 6.476564E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.23 | backward: 360.49 | optimizer: 5.20 | batch generator: 1.23 | data loader: 0.45
10.0.2.18:  iteration      479/    9375 | elapsed time per iteration (ms): 514.9 | learning rate 7.700E-06 | lm loss 6.436712E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.14 | backward: 345.69 | optimizer: 5.21 | batch generator: 1.12 | data loader: 0.37
10.0.2.18:  iteration      480/    9375 | elapsed time per iteration (ms): 488.0 | learning rate 7.717E-06 | lm loss 6.455687E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.66 | backward: 321.09 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.41
10.0.2.18:  iteration      481/    9375 | elapsed time per iteration (ms): 536.2 | learning rate 7.733E-06 | lm loss 6.446695E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.12 | backward: 368.55 | optimizer: 5.19 | batch generator: 1.22 | data loader: 0.50
10.0.2.18:  iteration      482/    9375 | elapsed time per iteration (ms): 561.3 | learning rate 7.750E-06 | lm loss 6.411348E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.83 | backward: 410.27 | optimizer: 5.17 | batch generator: 1.21 | data loader: 0.44
10.0.2.18:  iteration      483/    9375 | elapsed time per iteration (ms): 564.3 | learning rate 7.767E-06 | lm loss 6.440575E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.77 | backward: 409.18 | optimizer: 5.23 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      484/    9375 | elapsed time per iteration (ms): 505.2 | learning rate 7.783E-06 | lm loss 6.395212E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.12 | backward: 350.92 | optimizer: 5.28 | batch generator: 1.35 | data loader: 0.58
10.0.2.18:  iteration      485/    9375 | elapsed time per iteration (ms): 516.6 | learning rate 7.800E-06 | lm loss 6.436004E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.91 | backward: 362.95 | optimizer: 5.19 | batch generator: 1.26 | data loader: 0.42
10.0.2.18:  iteration      486/    9375 | elapsed time per iteration (ms): 539.3 | learning rate 7.817E-06 | lm loss 6.437798E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 144.47 | backward: 381.30 | optimizer: 5.24 | batch generator: 1.17 | data loader: 0.39
10.0.2.18:  iteration      487/    9375 | elapsed time per iteration (ms): 547.8 | learning rate 7.833E-06 | lm loss 6.448786E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.19 | backward: 391.68 | optimizer: 5.25 | batch generator: 1.36 | data loader: 0.65
10.0.2.18:  iteration      488/    9375 | elapsed time per iteration (ms): 590.0 | learning rate 7.850E-06 | lm loss 6.388635E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.78 | backward: 437.27 | optimizer: 5.18 | batch generator: 1.44 | data loader: 0.54
10.0.2.18:  iteration      489/    9375 | elapsed time per iteration (ms): 566.0 | learning rate 7.867E-06 | lm loss 6.435575E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.59 | backward: 411.20 | optimizer: 5.19 | batch generator: 1.20 | data loader: 0.49
10.0.2.18:  iteration      490/    9375 | elapsed time per iteration (ms): 511.0 | learning rate 7.883E-06 | lm loss 6.407511E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.71 | backward: 360.09 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.49
10.0.2.18:  iteration      491/    9375 | elapsed time per iteration (ms): 508.4 | learning rate 7.900E-06 | lm loss 6.412163E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.23 | backward: 361.83 | optimizer: 5.36 | batch generator: 1.18 | data loader: 0.48
10.0.2.18:  iteration      492/    9375 | elapsed time per iteration (ms): 544.6 | learning rate 7.917E-06 | lm loss 6.420197E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.45 | backward: 406.11 | optimizer: 5.27 | batch generator: 1.57 | data loader: 0.52
10.0.2.18:  iteration      493/    9375 | elapsed time per iteration (ms): 526.8 | learning rate 7.933E-06 | lm loss 6.401948E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.47 | backward: 375.81 | optimizer: 5.23 | batch generator: 1.55 | data loader: 0.50
10.0.2.18:  iteration      494/    9375 | elapsed time per iteration (ms): 537.2 | learning rate 7.950E-06 | lm loss 6.398739E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.11 | backward: 396.14 | optimizer: 5.19 | batch generator: 1.43 | data loader: 0.47
10.0.2.18:  iteration      495/    9375 | elapsed time per iteration (ms): 553.2 | learning rate 7.967E-06 | lm loss 6.401670E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.99 | backward: 404.36 | optimizer: 5.21 | batch generator: 1.36 | data loader: 0.44
10.0.2.18:  iteration      496/    9375 | elapsed time per iteration (ms): 581.4 | learning rate 7.983E-06 | lm loss 6.410128E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.78 | backward: 424.90 | optimizer: 5.18 | batch generator: 1.44 | data loader: 0.57
10.0.2.18:  iteration      497/    9375 | elapsed time per iteration (ms): 567.9 | learning rate 8.000E-06 | lm loss 6.424745E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.37 | backward: 417.58 | optimizer: 5.19 | batch generator: 1.35 | data loader: 0.49
10.0.2.18:  iteration      498/    9375 | elapsed time per iteration (ms): 571.5 | learning rate 8.017E-06 | lm loss 6.395588E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.26 | backward: 425.30 | optimizer: 5.22 | batch generator: 1.38 | data loader: 0.52
10.0.2.18:  iteration      499/    9375 | elapsed time per iteration (ms): 549.7 | learning rate 8.033E-06 | lm loss 6.402924E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.11 | backward: 391.08 | optimizer: 5.23 | batch generator: 1.40 | data loader: 0.46
10.0.2.18:  iteration      500/    9375 | elapsed time per iteration (ms): 564.2 | learning rate 8.050E-06 | lm loss 6.411687E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.48 | backward: 415.66 | optimizer: 5.21 | batch generator: 1.47 | data loader: 0.45
10.0.2.18:  iteration      501/    9375 | elapsed time per iteration (ms): 533.5 | learning rate 8.067E-06 | lm loss 6.361493E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.86 | backward: 383.63 | optimizer: 5.19 | batch generator: 1.44 | data loader: 0.48
10.0.2.18:  iteration      502/    9375 | elapsed time per iteration (ms): 530.4 | learning rate 8.083E-06 | lm loss 6.386371E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.81 | backward: 384.13 | optimizer: 5.17 | batch generator: 1.95 | data loader: 0.71
10.0.2.18:  iteration      503/    9375 | elapsed time per iteration (ms): 529.6 | learning rate 8.100E-06 | lm loss 6.421034E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.03 | backward: 379.03 | optimizer: 5.27 | batch generator: 1.14 | data loader: 0.40
10.0.2.18:  iteration      504/    9375 | elapsed time per iteration (ms): 550.3 | learning rate 8.117E-06 | lm loss 6.421332E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 124.49 | backward: 400.29 | optimizer: 5.19 | batch generator: 1.48 | data loader: 0.72
10.0.2.18:  iteration      505/    9375 | elapsed time per iteration (ms): 585.3 | learning rate 8.133E-06 | lm loss 6.354910E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.84 | backward: 430.41 | optimizer: 5.21 | batch generator: 1.20 | data loader: 0.50
10.0.2.18:  iteration      506/    9375 | elapsed time per iteration (ms): 575.7 | learning rate 8.150E-06 | lm loss 6.384276E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.37 | backward: 423.36 | optimizer: 5.21 | batch generator: 1.21 | data loader: 0.45
10.0.2.18:  iteration      507/    9375 | elapsed time per iteration (ms): 529.9 | learning rate 8.167E-06 | lm loss 6.383856E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.38 | backward: 375.47 | optimizer: 5.21 | batch generator: 1.31 | data loader: 0.57
10.0.2.18:  iteration      508/    9375 | elapsed time per iteration (ms): 551.8 | learning rate 8.183E-06 | lm loss 6.353047E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.71 | backward: 399.81 | optimizer: 5.19 | batch generator: 1.20 | data loader: 0.45
10.0.2.18:  iteration      509/    9375 | elapsed time per iteration (ms): 557.0 | learning rate 8.200E-06 | lm loss 6.380282E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.33 | backward: 394.01 | optimizer: 5.23 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      510/    9375 | elapsed time per iteration (ms): 533.0 | learning rate 8.217E-06 | lm loss 6.305013E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.31 | backward: 372.15 | optimizer: 5.21 | batch generator: 1.27 | data loader: 0.50
10.0.2.18:  iteration      511/    9375 | elapsed time per iteration (ms): 496.7 | learning rate 8.233E-06 | lm loss 6.319252E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.02 | backward: 341.38 | optimizer: 5.18 | batch generator: 1.25 | data loader: 0.54
10.0.2.18:  iteration      512/    9375 | elapsed time per iteration (ms): 511.9 | learning rate 8.250E-06 | lm loss 6.340693E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.59 | backward: 354.26 | optimizer: 5.20 | batch generator: 1.20 | data loader: 0.45
10.0.2.18:  iteration      513/    9375 | elapsed time per iteration (ms): 505.1 | learning rate 8.267E-06 | lm loss 6.356441E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.58 | backward: 346.03 | optimizer: 5.25 | batch generator: 1.17 | data loader: 0.49
10.0.2.18:  iteration      514/    9375 | elapsed time per iteration (ms): 526.3 | learning rate 8.283E-06 | lm loss 6.342155E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.72 | backward: 368.28 | optimizer: 5.20 | batch generator: 1.28 | data loader: 0.57
10.0.2.18:  iteration      515/    9375 | elapsed time per iteration (ms): 569.3 | learning rate 8.300E-06 | lm loss 6.339868E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.71 | backward: 407.86 | optimizer: 5.19 | batch generator: 1.20 | data loader: 0.53
10.0.2.18:  iteration      516/    9375 | elapsed time per iteration (ms): 501.1 | learning rate 8.317E-06 | lm loss 6.352293E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.03 | backward: 356.48 | optimizer: 5.17 | batch generator: 2.75 | data loader: 0.39
10.0.2.18:  iteration      517/    9375 | elapsed time per iteration (ms): 510.7 | learning rate 8.333E-06 | lm loss 6.370203E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.19 | backward: 350.69 | optimizer: 5.21 | batch generator: 1.10 | data loader: 0.38
10.0.2.18:  iteration      518/    9375 | elapsed time per iteration (ms): 493.8 | learning rate 8.350E-06 | lm loss 6.341285E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.64 | backward: 337.33 | optimizer: 5.28 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      519/    9375 | elapsed time per iteration (ms): 528.3 | learning rate 8.367E-06 | lm loss 6.343561E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.60 | backward: 370.64 | optimizer: 5.17 | batch generator: 1.20 | data loader: 0.40
10.0.2.18:  iteration      520/    9375 | elapsed time per iteration (ms): 535.1 | learning rate 8.383E-06 | lm loss 6.330231E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.91 | backward: 375.79 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.40
10.0.2.18:  iteration      521/    9375 | elapsed time per iteration (ms): 515.1 | learning rate 8.400E-06 | lm loss 6.362738E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.01 | backward: 369.57 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.40
10.0.2.18:  iteration      522/    9375 | elapsed time per iteration (ms): 505.0 | learning rate 8.417E-06 | lm loss 6.320725E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.74 | backward: 332.30 | optimizer: 5.24 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      523/    9375 | elapsed time per iteration (ms): 534.3 | learning rate 8.433E-06 | lm loss 6.346072E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.10 | backward: 377.24 | optimizer: 5.17 | batch generator: 1.40 | data loader: 0.67
10.0.2.18:  iteration      524/    9375 | elapsed time per iteration (ms): 487.0 | learning rate 8.450E-06 | lm loss 6.364996E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.91 | backward: 343.97 | optimizer: 5.21 | batch generator: 1.17 | data loader: 0.46
10.0.2.18:  iteration      525/    9375 | elapsed time per iteration (ms): 535.1 | learning rate 8.467E-06 | lm loss 6.327268E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.50 | backward: 375.13 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.52
10.0.2.18:  iteration      526/    9375 | elapsed time per iteration (ms): 513.3 | learning rate 8.483E-06 | lm loss 6.293354E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.97 | backward: 365.61 | optimizer: 5.17 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      527/    9375 | elapsed time per iteration (ms): 554.9 | learning rate 8.500E-06 | lm loss 6.327654E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.92 | backward: 400.11 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      528/    9375 | elapsed time per iteration (ms): 559.2 | learning rate 8.517E-06 | lm loss 6.324987E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.69 | backward: 404.92 | optimizer: 5.19 | batch generator: 1.17 | data loader: 0.42
10.0.2.18:  iteration      529/    9375 | elapsed time per iteration (ms): 522.3 | learning rate 8.533E-06 | lm loss 6.281006E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.14 | backward: 367.71 | optimizer: 5.19 | batch generator: 1.18 | data loader: 0.42
10.0.2.18:  iteration      530/    9375 | elapsed time per iteration (ms): 747.7 | learning rate 8.550E-06 | lm loss 6.315699E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.96 | backward: 387.54 | optimizer: 5.19 | batch generator: 1.12 | data loader: 0.38
10.0.2.18:  iteration      531/    9375 | elapsed time per iteration (ms): 565.3 | learning rate 8.567E-06 | lm loss 6.339192E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.09 | backward: 413.61 | optimizer: 5.22 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      532/    9375 | elapsed time per iteration (ms): 563.2 | learning rate 8.583E-06 | lm loss 6.290821E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.53 | backward: 411.62 | optimizer: 5.27 | batch generator: 1.29 | data loader: 0.49
10.0.2.18:  iteration      533/    9375 | elapsed time per iteration (ms): 574.4 | learning rate 8.600E-06 | lm loss 6.276857E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.36 | backward: 423.25 | optimizer: 5.20 | batch generator: 1.22 | data loader: 0.40
10.0.2.18:  iteration      534/    9375 | elapsed time per iteration (ms): 596.2 | learning rate 8.617E-06 | lm loss 6.315724E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.41 | backward: 429.30 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.41
10.0.2.18:  iteration      535/    9375 | elapsed time per iteration (ms): 519.9 | learning rate 8.633E-06 | lm loss 6.307436E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.67 | backward: 365.73 | optimizer: 5.22 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration      536/    9375 | elapsed time per iteration (ms): 577.9 | learning rate 8.650E-06 | lm loss 6.337023E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.11 | backward: 434.45 | optimizer: 5.20 | batch generator: 1.29 | data loader: 0.51
10.0.2.18:  iteration      537/    9375 | elapsed time per iteration (ms): 533.6 | learning rate 8.667E-06 | lm loss 6.334232E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.75 | backward: 381.59 | optimizer: 5.29 | batch generator: 1.30 | data loader: 0.48
10.0.2.18:  iteration      538/    9375 | elapsed time per iteration (ms): 587.6 | learning rate 8.683E-06 | lm loss 6.261363E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.23 | backward: 445.68 | optimizer: 5.22 | batch generator: 1.53 | data loader: 0.55
10.0.2.18:  iteration      539/    9375 | elapsed time per iteration (ms): 577.2 | learning rate 8.700E-06 | lm loss 6.299753E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.45 | backward: 427.24 | optimizer: 5.34 | batch generator: 1.41 | data loader: 0.46
10.0.2.18:  iteration      540/    9375 | elapsed time per iteration (ms): 541.1 | learning rate 8.717E-06 | lm loss 6.245572E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.69 | backward: 392.38 | optimizer: 5.28 | batch generator: 1.61 | data loader: 0.54
10.0.2.18:  iteration      541/    9375 | elapsed time per iteration (ms): 562.9 | learning rate 8.733E-06 | lm loss 6.287306E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.23 | backward: 401.19 | optimizer: 5.21 | batch generator: 1.64 | data loader: 0.56
10.0.2.18:  iteration      542/    9375 | elapsed time per iteration (ms): 576.2 | learning rate 8.750E-06 | lm loss 6.261126E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.51 | backward: 427.02 | optimizer: 5.21 | batch generator: 1.45 | data loader: 0.49
10.0.2.18:  iteration      543/    9375 | elapsed time per iteration (ms): 582.7 | learning rate 8.767E-06 | lm loss 6.303072E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.15 | backward: 432.28 | optimizer: 5.20 | batch generator: 1.45 | data loader: 0.55
10.0.2.18:  iteration      544/    9375 | elapsed time per iteration (ms): 547.3 | learning rate 8.783E-06 | lm loss 6.298088E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.29 | backward: 398.36 | optimizer: 5.21 | batch generator: 1.38 | data loader: 0.52
10.0.2.18:  iteration      545/    9375 | elapsed time per iteration (ms): 575.1 | learning rate 8.800E-06 | lm loss 6.276821E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.03 | backward: 418.53 | optimizer: 5.36 | batch generator: 1.44 | data loader: 0.56
10.0.2.18:  iteration      546/    9375 | elapsed time per iteration (ms): 538.4 | learning rate 8.817E-06 | lm loss 6.275125E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.10 | backward: 382.90 | optimizer: 5.22 | batch generator: 1.55 | data loader: 0.50
10.0.2.18:  iteration      547/    9375 | elapsed time per iteration (ms): 524.1 | learning rate 8.833E-06 | lm loss 6.317779E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.73 | backward: 379.63 | optimizer: 5.19 | batch generator: 1.49 | data loader: 0.50
10.0.2.18:  iteration      548/    9375 | elapsed time per iteration (ms): 594.7 | learning rate 8.850E-06 | lm loss 6.255548E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.79 | backward: 433.30 | optimizer: 5.21 | batch generator: 1.41 | data loader: 0.54
10.0.2.18:  iteration      549/    9375 | elapsed time per iteration (ms): 539.7 | learning rate 8.867E-06 | lm loss 6.269812E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.44 | backward: 392.73 | optimizer: 5.24 | batch generator: 1.40 | data loader: 0.45
10.0.2.18:  iteration      550/    9375 | elapsed time per iteration (ms): 564.3 | learning rate 8.883E-06 | lm loss 6.300869E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.28 | backward: 415.22 | optimizer: 5.19 | batch generator: 1.38 | data loader: 0.52
10.0.2.18:  iteration      551/    9375 | elapsed time per iteration (ms): 567.3 | learning rate 8.900E-06 | lm loss 6.249687E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.79 | backward: 419.73 | optimizer: 5.18 | batch generator: 1.97 | data loader: 0.71
10.0.2.18:  iteration      552/    9375 | elapsed time per iteration (ms): 545.6 | learning rate 8.917E-06 | lm loss 6.268216E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.69 | backward: 390.56 | optimizer: 5.20 | batch generator: 1.21 | data loader: 0.44
10.0.2.18:  iteration      553/    9375 | elapsed time per iteration (ms): 545.1 | learning rate 8.933E-06 | lm loss 6.241838E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.46 | backward: 392.71 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.45
10.0.2.18:  iteration      554/    9375 | elapsed time per iteration (ms): 500.8 | learning rate 8.950E-06 | lm loss 6.293180E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.47 | backward: 348.49 | optimizer: 5.27 | batch generator: 1.17 | data loader: 0.46
10.0.2.18:  iteration      555/    9375 | elapsed time per iteration (ms): 484.3 | learning rate 8.967E-06 | lm loss 6.258090E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.83 | backward: 350.43 | optimizer: 5.16 | batch generator: 1.43 | data loader: 0.56
10.0.2.18:  iteration      556/    9375 | elapsed time per iteration (ms): 521.5 | learning rate 8.983E-06 | lm loss 6.226186E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.20 | backward: 376.38 | optimizer: 5.20 | batch generator: 1.15 | data loader: 0.38
10.0.2.18:  iteration      557/    9375 | elapsed time per iteration (ms): 537.3 | learning rate 9.000E-06 | lm loss 6.243773E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.95 | backward: 381.65 | optimizer: 5.21 | batch generator: 1.17 | data loader: 0.40
10.0.2.18:  iteration      558/    9375 | elapsed time per iteration (ms): 502.8 | learning rate 9.017E-06 | lm loss 6.231318E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.96 | backward: 357.52 | optimizer: 5.19 | batch generator: 1.28 | data loader: 0.57
10.0.2.18:  iteration      559/    9375 | elapsed time per iteration (ms): 514.7 | learning rate 9.033E-06 | lm loss 6.252127E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.64 | backward: 370.22 | optimizer: 5.20 | batch generator: 1.20 | data loader: 0.51
10.0.2.18:  iteration      560/    9375 | elapsed time per iteration (ms): 567.8 | learning rate 9.050E-06 | lm loss 6.279195E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.87 | backward: 418.47 | optimizer: 5.17 | batch generator: 1.21 | data loader: 0.52
10.0.2.18:  iteration      561/    9375 | elapsed time per iteration (ms): 560.3 | learning rate 9.067E-06 | lm loss 6.240487E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.08 | backward: 399.34 | optimizer: 5.24 | batch generator: 1.11 | data loader: 0.39
10.0.2.18:  iteration      562/    9375 | elapsed time per iteration (ms): 525.0 | learning rate 9.083E-06 | lm loss 6.231376E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.93 | backward: 377.28 | optimizer: 5.19 | batch generator: 1.20 | data loader: 0.46
10.0.2.18:  iteration      563/    9375 | elapsed time per iteration (ms): 512.3 | learning rate 9.100E-06 | lm loss 6.227158E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.15 | backward: 365.42 | optimizer: 5.17 | batch generator: 1.19 | data loader: 0.44
10.0.2.18:  iteration      564/    9375 | elapsed time per iteration (ms): 515.7 | learning rate 9.117E-06 | lm loss 6.205383E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.32 | backward: 371.22 | optimizer: 5.21 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      565/    9375 | elapsed time per iteration (ms): 1023.7 | learning rate 9.133E-06 | lm loss 6.224702E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.19 | backward: 408.39 | optimizer: 5.26 | batch generator: 1.28 | data loader: 0.55
10.0.2.18:  iteration      566/    9375 | elapsed time per iteration (ms): 1099.1 | learning rate 9.150E-06 | lm loss 6.213785E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.64 | backward: 419.09 | optimizer: 5.17 | batch generator: 1.29 | data loader: 0.46
10.0.2.18:  iteration      567/    9375 | elapsed time per iteration (ms): 536.1 | learning rate 9.167E-06 | lm loss 6.204122E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 133.39 | backward: 373.44 | optimizer: 5.26 | batch generator: 1.15 | data loader: 0.40
10.0.2.18:  iteration      568/    9375 | elapsed time per iteration (ms): 530.1 | learning rate 9.183E-06 | lm loss 6.197597E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.23 | backward: 369.09 | optimizer: 5.17 | batch generator: 1.41 | data loader: 0.69
10.0.2.18:  iteration      569/    9375 | elapsed time per iteration (ms): 541.5 | learning rate 9.200E-06 | lm loss 6.146487E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.24 | backward: 386.75 | optimizer: 5.17 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      570/    9375 | elapsed time per iteration (ms): 522.7 | learning rate 9.217E-06 | lm loss 6.218720E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.25 | backward: 366.31 | optimizer: 5.19 | batch generator: 1.12 | data loader: 0.38
10.0.2.18:  iteration      571/    9375 | elapsed time per iteration (ms): 566.4 | learning rate 9.233E-06 | lm loss 6.233682E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.90 | backward: 407.78 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      572/    9375 | elapsed time per iteration (ms): 521.7 | learning rate 9.250E-06 | lm loss 6.221864E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.78 | backward: 367.14 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.47
10.0.2.18:  iteration      573/    9375 | elapsed time per iteration (ms): 1230.8 | learning rate 9.267E-06 | lm loss 6.197741E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.85 | backward: 396.22 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.46
10.0.2.18:  iteration      574/    9375 | elapsed time per iteration (ms): 1121.0 | learning rate 9.283E-06 | lm loss 6.195119E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.58 | backward: 386.96 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      575/    9375 | elapsed time per iteration (ms): 536.7 | learning rate 9.300E-06 | lm loss 6.189614E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.70 | backward: 383.47 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      576/    9375 | elapsed time per iteration (ms): 560.0 | learning rate 9.317E-06 | lm loss 6.246542E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.39 | backward: 410.00 | optimizer: 5.20 | batch generator: 1.21 | data loader: 0.50
10.0.2.18:  iteration      577/    9375 | elapsed time per iteration (ms): 529.4 | learning rate 9.333E-06 | lm loss 6.216833E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.67 | backward: 377.79 | optimizer: 5.19 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      578/    9375 | elapsed time per iteration (ms): 528.1 | learning rate 9.350E-06 | lm loss 6.180717E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.62 | backward: 379.59 | optimizer: 5.21 | batch generator: 1.24 | data loader: 0.46
10.0.2.18:  iteration      579/    9375 | elapsed time per iteration (ms): 587.6 | learning rate 9.367E-06 | lm loss 6.159869E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.50 | backward: 435.76 | optimizer: 5.20 | batch generator: 1.26 | data loader: 0.55
10.0.2.18:  iteration      580/    9375 | elapsed time per iteration (ms): 1222.3 | learning rate 9.383E-06 | lm loss 6.180999E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.84 | backward: 402.07 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.40
10.0.2.18:  iteration      581/    9375 | elapsed time per iteration (ms): 1373.6 | learning rate 9.400E-06 | lm loss 6.234369E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.85 | backward: 359.96 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      582/    9375 | elapsed time per iteration (ms): 544.4 | learning rate 9.417E-06 | lm loss 6.189931E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.57 | backward: 397.35 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      583/    9375 | elapsed time per iteration (ms): 565.0 | learning rate 9.433E-06 | lm loss 6.149443E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.58 | backward: 410.73 | optimizer: 5.20 | batch generator: 1.13 | data loader: 0.45
10.0.2.18:  iteration      584/    9375 | elapsed time per iteration (ms): 574.2 | learning rate 9.450E-06 | lm loss 6.232354E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.35 | backward: 417.24 | optimizer: 5.20 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      585/    9375 | elapsed time per iteration (ms): 1027.5 | learning rate 9.467E-06 | lm loss 6.218595E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.21 | backward: 369.02 | optimizer: 5.17 | batch generator: 1.18 | data loader: 0.39
10.0.2.18:  iteration      586/    9375 | elapsed time per iteration (ms): 1217.7 | learning rate 9.483E-06 | lm loss 6.148643E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.06 | backward: 398.99 | optimizer: 5.19 | batch generator: 1.17 | data loader: 0.40
10.0.2.18:  iteration      587/    9375 | elapsed time per iteration (ms): 492.5 | learning rate 9.500E-06 | lm loss 6.205982E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.82 | backward: 338.32 | optimizer: 5.26 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      588/    9375 | elapsed time per iteration (ms): 535.4 | learning rate 9.517E-06 | lm loss 6.164349E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.19 | backward: 374.70 | optimizer: 5.20 | batch generator: 1.30 | data loader: 0.47
10.0.2.18:  iteration      589/    9375 | elapsed time per iteration (ms): 576.2 | learning rate 9.533E-06 | lm loss 6.149667E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.03 | backward: 411.98 | optimizer: 5.17 | batch generator: 1.24 | data loader: 0.52
10.0.2.18:  iteration      590/    9375 | elapsed time per iteration (ms): 1153.9 | learning rate 9.550E-06 | lm loss 6.121264E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.83 | backward: 396.41 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.41
10.0.2.18:  iteration      591/    9375 | elapsed time per iteration (ms): 567.8 | learning rate 9.567E-06 | lm loss 6.175546E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.99 | backward: 396.82 | optimizer: 5.20 | batch generator: 1.24 | data loader: 0.53
10.0.2.18:  iteration      592/    9375 | elapsed time per iteration (ms): 564.5 | learning rate 9.583E-06 | lm loss 6.158561E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.96 | backward: 410.75 | optimizer: 5.20 | batch generator: 1.28 | data loader: 0.47
10.0.2.18:  iteration      593/    9375 | elapsed time per iteration (ms): 540.6 | learning rate 9.600E-06 | lm loss 6.203950E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.07 | backward: 386.73 | optimizer: 5.26 | batch generator: 1.17 | data loader: 0.42
10.0.2.18:  iteration      594/    9375 | elapsed time per iteration (ms): 1000.7 | learning rate 9.617E-06 | lm loss 6.144561E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.47 | backward: 370.11 | optimizer: 5.28 | batch generator: 1.43 | data loader: 0.47
10.0.2.18:  iteration      595/    9375 | elapsed time per iteration (ms): 516.9 | learning rate 9.633E-06 | lm loss 6.128748E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.31 | backward: 362.74 | optimizer: 5.21 | batch generator: 1.73 | data loader: 0.58
10.0.2.18:  iteration      596/    9375 | elapsed time per iteration (ms): 526.5 | learning rate 9.650E-06 | lm loss 6.195723E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.19 | backward: 384.06 | optimizer: 5.22 | batch generator: 1.40 | data loader: 0.45
10.0.2.18:  iteration      597/    9375 | elapsed time per iteration (ms): 545.3 | learning rate 9.667E-06 | lm loss 6.143641E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.93 | backward: 398.31 | optimizer: 5.20 | batch generator: 1.39 | data loader: 0.47
10.0.2.18:  iteration      598/    9375 | elapsed time per iteration (ms): 567.1 | learning rate 9.683E-06 | lm loss 6.174881E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.72 | backward: 417.34 | optimizer: 5.21 | batch generator: 1.39 | data loader: 0.46
10.0.2.18:  iteration      599/    9375 | elapsed time per iteration (ms): 1031.3 | learning rate 9.700E-06 | lm loss 6.141919E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.17 | backward: 361.22 | optimizer: 5.18 | batch generator: 1.41 | data loader: 0.54
10.0.2.18:  iteration      600/    9375 | elapsed time per iteration (ms): 564.5 | learning rate 9.717E-06 | lm loss 6.173568E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.28 | backward: 411.48 | optimizer: 5.16 | batch generator: 1.14 | data loader: 0.40
10.0.2.18:  iteration      601/    9375 | elapsed time per iteration (ms): 541.6 | learning rate 9.733E-06 | lm loss 6.167747E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.55 | backward: 380.36 | optimizer: 5.23 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      602/    9375 | elapsed time per iteration (ms): 520.3 | learning rate 9.750E-06 | lm loss 6.152816E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.80 | backward: 379.51 | optimizer: 5.23 | batch generator: 1.20 | data loader: 0.41
10.0.2.18:  iteration      603/    9375 | elapsed time per iteration (ms): 561.0 | learning rate 9.767E-06 | lm loss 6.148858E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.27 | backward: 416.34 | optimizer: 5.24 | batch generator: 1.21 | data loader: 0.52
10.0.2.18:  iteration      604/    9375 | elapsed time per iteration (ms): 574.6 | learning rate 9.783E-06 | lm loss 6.179124E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.02 | backward: 418.17 | optimizer: 5.18 | batch generator: 1.30 | data loader: 0.55
10.0.2.18:  iteration      605/    9375 | elapsed time per iteration (ms): 580.4 | learning rate 9.800E-06 | lm loss 6.178384E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.18 | backward: 423.14 | optimizer: 5.30 | batch generator: 1.13 | data loader: 0.40
10.0.2.18:  iteration      606/    9375 | elapsed time per iteration (ms): 1041.6 | learning rate 9.817E-06 | lm loss 6.129932E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.16 | backward: 435.96 | optimizer: 5.24 | batch generator: 1.33 | data loader: 0.47
10.0.2.18:  iteration      607/    9375 | elapsed time per iteration (ms): 1120.2 | learning rate 9.833E-06 | lm loss 6.143177E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.65 | backward: 424.95 | optimizer: 5.20 | batch generator: 1.34 | data loader: 0.48
10.0.2.18:  iteration      608/    9375 | elapsed time per iteration (ms): 569.9 | learning rate 9.850E-06 | lm loss 6.142904E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.68 | backward: 416.02 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.41
10.0.2.18:  iteration      609/    9375 | elapsed time per iteration (ms): 532.2 | learning rate 9.867E-06 | lm loss 6.135151E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.39 | backward: 379.83 | optimizer: 5.17 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      610/    9375 | elapsed time per iteration (ms): 565.0 | learning rate 9.883E-06 | lm loss 6.133790E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.53 | backward: 420.51 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.40
10.0.2.18:  iteration      611/    9375 | elapsed time per iteration (ms): 568.8 | learning rate 9.900E-06 | lm loss 6.129159E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.02 | backward: 414.55 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.40
10.0.2.18:  iteration      612/    9375 | elapsed time per iteration (ms): 1171.5 | learning rate 9.917E-06 | lm loss 6.114482E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.27 | backward: 442.30 | optimizer: 5.25 | batch generator: 1.14 | data loader: 0.40
10.0.2.18:  iteration      613/    9375 | elapsed time per iteration (ms): 583.5 | learning rate 9.933E-06 | lm loss 6.091652E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.22 | backward: 432.67 | optimizer: 5.20 | batch generator: 1.23 | data loader: 0.40
10.0.2.18:  iteration      614/    9375 | elapsed time per iteration (ms): 577.7 | learning rate 9.950E-06 | lm loss 6.124688E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.03 | backward: 425.89 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.43
10.0.2.18:  iteration      615/    9375 | elapsed time per iteration (ms): 584.9 | learning rate 9.967E-06 | lm loss 6.110799E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.31 | backward: 432.78 | optimizer: 5.24 | batch generator: 1.12 | data loader: 0.46
10.0.2.18:  iteration      616/    9375 | elapsed time per iteration (ms): 591.7 | learning rate 9.983E-06 | lm loss 6.118015E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.17 | backward: 437.81 | optimizer: 5.20 | batch generator: 1.35 | data loader: 0.63
10.0.2.18:  iteration      617/    9375 | elapsed time per iteration (ms): 582.9 | learning rate 1.000E-05 | lm loss 6.125170E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.23 | backward: 428.16 | optimizer: 5.21 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      618/    9375 | elapsed time per iteration (ms): 558.9 | learning rate 1.002E-05 | lm loss 6.118126E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.83 | backward: 405.40 | optimizer: 5.19 | batch generator: 1.25 | data loader: 0.46
10.0.2.18:  iteration      619/    9375 | elapsed time per iteration (ms): 565.6 | learning rate 1.003E-05 | lm loss 6.157460E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.71 | backward: 410.62 | optimizer: 5.24 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration      620/    9375 | elapsed time per iteration (ms): 563.2 | learning rate 1.005E-05 | lm loss 6.080744E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.48 | backward: 392.74 | optimizer: 5.20 | batch generator: 1.29 | data loader: 0.48
10.0.2.18:  iteration      621/    9375 | elapsed time per iteration (ms): 584.6 | learning rate 1.007E-05 | lm loss 6.074538E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.31 | backward: 431.04 | optimizer: 5.33 | batch generator: 1.21 | data loader: 0.52
10.0.2.18:  iteration      622/    9375 | elapsed time per iteration (ms): 570.9 | learning rate 1.008E-05 | lm loss 6.105755E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.56 | backward: 429.37 | optimizer: 5.19 | batch generator: 1.61 | data loader: 0.53
10.0.2.18:  iteration      623/    9375 | elapsed time per iteration (ms): 593.9 | learning rate 1.010E-05 | lm loss 6.112989E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.85 | backward: 443.07 | optimizer: 5.34 | batch generator: 1.46 | data loader: 0.48
10.0.2.18:  iteration      624/    9375 | elapsed time per iteration (ms): 586.4 | learning rate 1.012E-05 | lm loss 6.098313E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.43 | backward: 437.38 | optimizer: 5.30 | batch generator: 1.60 | data loader: 0.51
10.0.2.18:  iteration      625/    9375 | elapsed time per iteration (ms): 589.6 | learning rate 1.013E-05 | lm loss 6.089307E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.99 | backward: 440.52 | optimizer: 5.17 | batch generator: 1.65 | data loader: 0.55
10.0.2.18:  iteration      626/    9375 | elapsed time per iteration (ms): 596.1 | learning rate 1.015E-05 | lm loss 6.089467E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.13 | backward: 446.16 | optimizer: 5.20 | batch generator: 1.33 | data loader: 0.41
10.0.2.18:  iteration      627/    9375 | elapsed time per iteration (ms): 574.6 | learning rate 1.017E-05 | lm loss 6.076078E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.52 | backward: 424.68 | optimizer: 5.20 | batch generator: 1.49 | data loader: 0.51
10.0.2.18:  iteration      628/    9375 | elapsed time per iteration (ms): 566.8 | learning rate 1.018E-05 | lm loss 6.077544E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.87 | backward: 419.59 | optimizer: 5.20 | batch generator: 1.37 | data loader: 0.51
10.0.2.18:  iteration      629/    9375 | elapsed time per iteration (ms): 577.6 | learning rate 1.020E-05 | lm loss 6.065641E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.68 | backward: 423.25 | optimizer: 5.23 | batch generator: 1.15 | data loader: 0.46
10.0.2.18:  iteration      630/    9375 | elapsed time per iteration (ms): 595.6 | learning rate 1.022E-05 | lm loss 6.016489E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.63 | backward: 440.09 | optimizer: 5.19 | batch generator: 1.36 | data loader: 0.60
10.0.2.18:  iteration      631/    9375 | elapsed time per iteration (ms): 581.9 | learning rate 1.023E-05 | lm loss 6.074485E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.93 | backward: 427.52 | optimizer: 5.19 | batch generator: 1.17 | data loader: 0.43
10.0.2.18:  iteration      632/    9375 | elapsed time per iteration (ms): 488.8 | learning rate 1.025E-05 | lm loss 6.061277E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.41 | backward: 336.24 | optimizer: 5.21 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      633/    9375 | elapsed time per iteration (ms): 714.5 | learning rate 1.027E-05 | lm loss 6.090826E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.81 | backward: 560.73 | optimizer: 5.20 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      634/    9375 | elapsed time per iteration (ms): 583.6 | learning rate 1.028E-05 | lm loss 6.062825E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.33 | backward: 437.07 | optimizer: 5.18 | batch generator: 1.22 | data loader: 0.45
10.0.2.18:  iteration      635/    9375 | elapsed time per iteration (ms): 576.4 | learning rate 1.030E-05 | lm loss 6.087847E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.17 | backward: 421.98 | optimizer: 5.22 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      636/    9375 | elapsed time per iteration (ms): 597.6 | learning rate 1.032E-05 | lm loss 6.076248E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.50 | backward: 443.99 | optimizer: 5.23 | batch generator: 1.29 | data loader: 0.45
10.0.2.18:  iteration      637/    9375 | elapsed time per iteration (ms): 613.4 | learning rate 1.033E-05 | lm loss 6.073285E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.27 | backward: 459.02 | optimizer: 5.17 | batch generator: 1.33 | data loader: 0.46
10.0.2.18:  iteration      638/    9375 | elapsed time per iteration (ms): 593.5 | learning rate 1.035E-05 | lm loss 6.070498E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.61 | backward: 439.15 | optimizer: 5.18 | batch generator: 1.25 | data loader: 0.54
10.0.2.18:  iteration      639/    9375 | elapsed time per iteration (ms): 604.3 | learning rate 1.037E-05 | lm loss 6.044257E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.30 | backward: 443.01 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.50
10.0.2.18:  iteration      640/    9375 | elapsed time per iteration (ms): 585.5 | learning rate 1.038E-05 | lm loss 6.083873E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.38 | backward: 431.44 | optimizer: 5.20 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      641/    9375 | elapsed time per iteration (ms): 597.3 | learning rate 1.040E-05 | lm loss 6.023787E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.20 | backward: 441.14 | optimizer: 5.18 | batch generator: 1.20 | data loader: 0.43
10.0.2.18:  iteration      642/    9375 | elapsed time per iteration (ms): 562.2 | learning rate 1.042E-05 | lm loss 6.028873E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.77 | backward: 407.07 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.41
10.0.2.18:  iteration      643/    9375 | elapsed time per iteration (ms): 536.3 | learning rate 1.043E-05 | lm loss 6.074865E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.70 | backward: 385.04 | optimizer: 5.16 | batch generator: 1.15 | data loader: 0.46
10.0.2.18:  iteration      644/    9375 | elapsed time per iteration (ms): 521.4 | learning rate 1.045E-05 | lm loss 6.005147E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.91 | backward: 367.84 | optimizer: 5.20 | batch generator: 1.18 | data loader: 0.49
10.0.2.18:  iteration      645/    9375 | elapsed time per iteration (ms): 563.1 | learning rate 1.047E-05 | lm loss 6.021344E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.88 | backward: 403.32 | optimizer: 5.21 | batch generator: 1.20 | data loader: 0.42
10.0.2.18:  iteration      646/    9375 | elapsed time per iteration (ms): 525.7 | learning rate 1.048E-05 | lm loss 6.037457E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.15 | backward: 370.84 | optimizer: 5.18 | batch generator: 1.22 | data loader: 0.53
10.0.2.18:  iteration      647/    9375 | elapsed time per iteration (ms): 527.7 | learning rate 1.050E-05 | lm loss 6.069401E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.85 | backward: 371.89 | optimizer: 5.19 | batch generator: 2.00 | data loader: 0.75
10.0.2.18:  iteration      648/    9375 | elapsed time per iteration (ms): 530.4 | learning rate 1.052E-05 | lm loss 6.019546E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.42 | backward: 378.31 | optimizer: 5.20 | batch generator: 1.19 | data loader: 0.42
10.0.2.18:  iteration      649/    9375 | elapsed time per iteration (ms): 504.3 | learning rate 1.053E-05 | lm loss 6.048482E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.83 | backward: 356.02 | optimizer: 5.26 | batch generator: 1.23 | data loader: 0.53
10.0.2.18:  iteration      650/    9375 | elapsed time per iteration (ms): 505.6 | learning rate 1.055E-05 | lm loss 6.042675E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.28 | backward: 364.13 | optimizer: 5.27 | batch generator: 1.57 | data loader: 0.62
10.0.2.18:  iteration      651/    9375 | elapsed time per iteration (ms): 528.5 | learning rate 1.057E-05 | lm loss 6.013496E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.58 | backward: 378.69 | optimizer: 5.24 | batch generator: 1.51 | data loader: 0.50
10.0.2.18:  iteration      652/    9375 | elapsed time per iteration (ms): 519.6 | learning rate 1.058E-05 | lm loss 6.038089E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.19 | backward: 377.70 | optimizer: 5.22 | batch generator: 1.45 | data loader: 0.47
10.0.2.18:  iteration      653/    9375 | elapsed time per iteration (ms): 598.0 | learning rate 1.060E-05 | lm loss 6.003270E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.42 | backward: 437.78 | optimizer: 5.20 | batch generator: 1.59 | data loader: 0.64
10.0.2.18:  iteration      654/    9375 | elapsed time per iteration (ms): 558.7 | learning rate 1.062E-05 | lm loss 6.027087E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.70 | backward: 411.64 | optimizer: 5.19 | batch generator: 1.45 | data loader: 0.51
10.0.2.18:  iteration      655/    9375 | elapsed time per iteration (ms): 578.3 | learning rate 1.063E-05 | lm loss 6.058440E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.91 | backward: 428.57 | optimizer: 5.19 | batch generator: 1.35 | data loader: 0.43
10.0.2.18:  iteration      656/    9375 | elapsed time per iteration (ms): 508.5 | learning rate 1.065E-05 | lm loss 6.032694E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.41 | backward: 359.84 | optimizer: 5.24 | batch generator: 1.35 | data loader: 0.50
10.0.2.18:  iteration      657/    9375 | elapsed time per iteration (ms): 531.9 | learning rate 1.067E-05 | lm loss 6.017859E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.84 | backward: 377.31 | optimizer: 5.23 | batch generator: 1.47 | data loader: 0.57
10.0.2.18:  iteration      658/    9375 | elapsed time per iteration (ms): 522.0 | learning rate 1.068E-05 | lm loss 6.016686E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.42 | backward: 368.99 | optimizer: 5.20 | batch generator: 1.44 | data loader: 0.55
10.0.2.18:  iteration      659/    9375 | elapsed time per iteration (ms): 524.7 | learning rate 1.070E-05 | lm loss 5.996922E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.37 | backward: 371.10 | optimizer: 5.21 | batch generator: 1.47 | data loader: 0.48
10.0.2.18:  iteration      660/    9375 | elapsed time per iteration (ms): 551.8 | learning rate 1.072E-05 | lm loss 5.998353E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.19 | backward: 409.01 | optimizer: 5.21 | batch generator: 1.37 | data loader: 0.51
10.0.2.18:  iteration      661/    9375 | elapsed time per iteration (ms): 490.0 | learning rate 1.073E-05 | lm loss 6.064146E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.30 | backward: 340.12 | optimizer: 5.22 | batch generator: 1.38 | data loader: 0.52
10.0.2.18:  iteration      662/    9375 | elapsed time per iteration (ms): 517.0 | learning rate 1.075E-05 | lm loss 6.030285E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.77 | backward: 375.04 | optimizer: 5.31 | batch generator: 1.42 | data loader: 0.48
10.0.2.18:  iteration      663/    9375 | elapsed time per iteration (ms): 518.7 | learning rate 1.077E-05 | lm loss 6.009748E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.36 | backward: 367.31 | optimizer: 5.22 | batch generator: 1.51 | data loader: 0.49
10.0.2.18:  iteration      664/    9375 | elapsed time per iteration (ms): 536.2 | learning rate 1.078E-05 | lm loss 6.014605E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.86 | backward: 386.39 | optimizer: 5.23 | batch generator: 1.45 | data loader: 0.49
10.0.2.18:  iteration      665/    9375 | elapsed time per iteration (ms): 492.5 | learning rate 1.080E-05 | lm loss 5.996275E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.02 | backward: 353.48 | optimizer: 5.19 | batch generator: 1.45 | data loader: 0.49
10.0.2.18:  iteration      666/    9375 | elapsed time per iteration (ms): 499.2 | learning rate 1.082E-05 | lm loss 6.015619E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.37 | backward: 356.41 | optimizer: 5.19 | batch generator: 1.41 | data loader: 0.48
10.0.2.18:  iteration      667/    9375 | elapsed time per iteration (ms): 534.2 | learning rate 1.083E-05 | lm loss 6.025618E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.70 | backward: 385.22 | optimizer: 5.24 | batch generator: 1.46 | data loader: 0.58
10.0.2.18:  iteration      668/    9375 | elapsed time per iteration (ms): 517.4 | learning rate 1.085E-05 | lm loss 5.991188E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.25 | backward: 373.53 | optimizer: 5.19 | batch generator: 1.46 | data loader: 0.59
10.0.2.18:  iteration      669/    9375 | elapsed time per iteration (ms): 503.8 | learning rate 1.087E-05 | lm loss 6.011106E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.19 | backward: 362.55 | optimizer: 5.24 | batch generator: 1.48 | data loader: 0.59
10.0.2.18:  iteration      670/    9375 | elapsed time per iteration (ms): 567.9 | learning rate 1.088E-05 | lm loss 5.998909E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 142.71 | backward: 415.15 | optimizer: 5.19 | batch generator: 1.44 | data loader: 0.56
10.0.2.18:  iteration      671/    9375 | elapsed time per iteration (ms): 515.9 | learning rate 1.090E-05 | lm loss 5.992937E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.91 | backward: 362.53 | optimizer: 5.19 | batch generator: 1.26 | data loader: 0.45
10.0.2.18:  iteration      672/    9375 | elapsed time per iteration (ms): 524.4 | learning rate 1.092E-05 | lm loss 5.988866E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.96 | backward: 370.61 | optimizer: 5.26 | batch generator: 1.16 | data loader: 0.49
10.0.2.18:  iteration      673/    9375 | elapsed time per iteration (ms): 555.2 | learning rate 1.093E-05 | lm loss 6.042356E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.75 | backward: 411.55 | optimizer: 5.19 | batch generator: 1.39 | data loader: 0.68
10.0.2.18:  iteration      674/    9375 | elapsed time per iteration (ms): 568.8 | learning rate 1.095E-05 | lm loss 5.986797E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.72 | backward: 414.61 | optimizer: 5.18 | batch generator: 1.20 | data loader: 0.50
10.0.2.18:  iteration      675/    9375 | elapsed time per iteration (ms): 533.0 | learning rate 1.097E-05 | lm loss 5.962531E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.00 | backward: 365.65 | optimizer: 5.18 | batch generator: 1.25 | data loader: 0.52
10.0.2.18:  iteration      676/    9375 | elapsed time per iteration (ms): 525.9 | learning rate 1.098E-05 | lm loss 6.009722E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.67 | backward: 371.69 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      677/    9375 | elapsed time per iteration (ms): 515.4 | learning rate 1.100E-05 | lm loss 5.991841E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.12 | backward: 369.28 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.43
10.0.2.18:  iteration      678/    9375 | elapsed time per iteration (ms): 494.9 | learning rate 1.102E-05 | lm loss 5.948003E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.83 | backward: 342.93 | optimizer: 5.19 | batch generator: 1.23 | data loader: 0.53
10.0.2.18:  iteration      679/    9375 | elapsed time per iteration (ms): 506.9 | learning rate 1.103E-05 | lm loss 5.981333E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.88 | backward: 349.19 | optimizer: 5.18 | batch generator: 1.20 | data loader: 0.45
10.0.2.18:  iteration      680/    9375 | elapsed time per iteration (ms): 533.0 | learning rate 1.105E-05 | lm loss 6.000640E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.20 | backward: 372.29 | optimizer: 5.18 | batch generator: 1.11 | data loader: 0.37
10.0.2.18:  iteration      681/    9375 | elapsed time per iteration (ms): 531.0 | learning rate 1.107E-05 | lm loss 5.954247E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.99 | backward: 370.04 | optimizer: 5.20 | batch generator: 1.17 | data loader: 0.50
10.0.2.18:  iteration      682/    9375 | elapsed time per iteration (ms): 508.5 | learning rate 1.108E-05 | lm loss 6.002741E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.27 | backward: 352.53 | optimizer: 5.17 | batch generator: 1.23 | data loader: 0.51
10.0.2.18:  iteration      683/    9375 | elapsed time per iteration (ms): 534.0 | learning rate 1.110E-05 | lm loss 5.958228E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.72 | backward: 374.68 | optimizer: 5.24 | batch generator: 1.90 | data loader: 0.68
10.0.2.18:  iteration      684/    9375 | elapsed time per iteration (ms): 503.2 | learning rate 1.112E-05 | lm loss 5.982438E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 124.12 | backward: 342.62 | optimizer: 5.20 | batch generator: 1.30 | data loader: 0.56
10.0.2.18:  iteration      685/    9375 | elapsed time per iteration (ms): 524.6 | learning rate 1.113E-05 | lm loss 5.936273E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.85 | backward: 365.57 | optimizer: 5.22 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      686/    9375 | elapsed time per iteration (ms): 500.2 | learning rate 1.115E-05 | lm loss 5.986147E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.22 | backward: 340.78 | optimizer: 5.16 | batch generator: 1.19 | data loader: 0.50
10.0.2.18:  iteration      687/    9375 | elapsed time per iteration (ms): 523.1 | learning rate 1.117E-05 | lm loss 5.956965E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.72 | backward: 364.52 | optimizer: 5.17 | batch generator: 1.11 | data loader: 0.44
10.0.2.18:  iteration      688/    9375 | elapsed time per iteration (ms): 507.1 | learning rate 1.118E-05 | lm loss 5.968261E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.90 | backward: 348.42 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      689/    9375 | elapsed time per iteration (ms): 507.5 | learning rate 1.120E-05 | lm loss 5.950490E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.75 | backward: 352.59 | optimizer: 5.22 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      690/    9375 | elapsed time per iteration (ms): 488.9 | learning rate 1.122E-05 | lm loss 5.968120E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.02 | backward: 333.87 | optimizer: 5.21 | batch generator: 1.28 | data loader: 0.51
10.0.2.18:  iteration      691/    9375 | elapsed time per iteration (ms): 533.1 | learning rate 1.123E-05 | lm loss 5.964284E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.25 | backward: 375.35 | optimizer: 5.29 | batch generator: 1.25 | data loader: 0.44
10.0.2.18:  iteration      692/    9375 | elapsed time per iteration (ms): 496.1 | learning rate 1.125E-05 | lm loss 5.968865E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.57 | backward: 338.49 | optimizer: 5.19 | batch generator: 1.29 | data loader: 0.45
10.0.2.18:  iteration      693/    9375 | elapsed time per iteration (ms): 529.0 | learning rate 1.127E-05 | lm loss 5.957063E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 98.71 | backward: 369.00 | optimizer: 5.23 | batch generator: 1.12 | data loader: 0.46
10.0.2.18:  iteration      694/    9375 | elapsed time per iteration (ms): 548.2 | learning rate 1.128E-05 | lm loss 5.909825E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.53 | backward: 404.40 | optimizer: 5.24 | batch generator: 1.35 | data loader: 0.52
10.0.2.18:  iteration      695/    9375 | elapsed time per iteration (ms): 505.1 | learning rate 1.130E-05 | lm loss 5.949552E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.15 | backward: 351.41 | optimizer: 5.19 | batch generator: 1.31 | data loader: 0.49
10.0.2.18:  iteration      696/    9375 | elapsed time per iteration (ms): 542.0 | learning rate 1.132E-05 | lm loss 5.941719E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.32 | backward: 384.07 | optimizer: 5.21 | batch generator: 1.22 | data loader: 0.43
10.0.2.18:  iteration      697/    9375 | elapsed time per iteration (ms): 509.1 | learning rate 1.133E-05 | lm loss 5.934890E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.15 | backward: 362.35 | optimizer: 5.23 | batch generator: 1.28 | data loader: 0.55
10.0.2.18:  iteration      698/    9375 | elapsed time per iteration (ms): 513.7 | learning rate 1.135E-05 | lm loss 5.916213E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.58 | backward: 366.71 | optimizer: 5.16 | batch generator: 1.19 | data loader: 0.52
10.0.2.18:  iteration      699/    9375 | elapsed time per iteration (ms): 561.6 | learning rate 1.137E-05 | lm loss 5.935386E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.55 | backward: 408.17 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.39
10.0.2.18:  iteration      700/    9375 | elapsed time per iteration (ms): 507.4 | learning rate 1.138E-05 | lm loss 5.918176E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.59 | backward: 352.59 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      701/    9375 | elapsed time per iteration (ms): 538.6 | learning rate 1.140E-05 | lm loss 5.971036E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 133.72 | backward: 383.06 | optimizer: 5.21 | batch generator: 1.17 | data loader: 0.50
10.0.2.18:  iteration      702/    9375 | elapsed time per iteration (ms): 521.2 | learning rate 1.142E-05 | lm loss 5.961141E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.38 | backward: 359.00 | optimizer: 5.17 | batch generator: 1.24 | data loader: 0.44
10.0.2.18:  iteration      703/    9375 | elapsed time per iteration (ms): 528.5 | learning rate 1.143E-05 | lm loss 5.944921E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.71 | backward: 369.13 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration      704/    9375 | elapsed time per iteration (ms): 533.1 | learning rate 1.145E-05 | lm loss 5.957617E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.40 | backward: 387.23 | optimizer: 5.20 | batch generator: 1.32 | data loader: 0.58
10.0.2.18:  iteration      705/    9375 | elapsed time per iteration (ms): 509.8 | learning rate 1.147E-05 | lm loss 5.938303E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.96 | backward: 356.36 | optimizer: 5.26 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      706/    9375 | elapsed time per iteration (ms): 518.4 | learning rate 1.148E-05 | lm loss 5.880791E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.30 | backward: 368.65 | optimizer: 5.17 | batch generator: 1.32 | data loader: 0.64
10.0.2.18:  iteration      707/    9375 | elapsed time per iteration (ms): 498.9 | learning rate 1.150E-05 | lm loss 5.902472E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.90 | backward: 352.69 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.47
10.0.2.18:  iteration      708/    9375 | elapsed time per iteration (ms): 497.7 | learning rate 1.152E-05 | lm loss 5.892683E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.60 | backward: 341.52 | optimizer: 5.18 | batch generator: 1.27 | data loader: 0.57
10.0.2.18:  iteration      709/    9375 | elapsed time per iteration (ms): 514.3 | learning rate 1.153E-05 | lm loss 5.885078E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.17 | backward: 358.03 | optimizer: 5.20 | batch generator: 1.12 | data loader: 0.38
10.0.2.18:  iteration      710/    9375 | elapsed time per iteration (ms): 529.0 | learning rate 1.155E-05 | lm loss 5.918341E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.07 | backward: 368.48 | optimizer: 5.19 | batch generator: 1.29 | data loader: 0.55
10.0.2.18:  iteration      711/    9375 | elapsed time per iteration (ms): 520.3 | learning rate 1.157E-05 | lm loss 5.927904E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.90 | backward: 361.06 | optimizer: 5.27 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      712/    9375 | elapsed time per iteration (ms): 535.0 | learning rate 1.158E-05 | lm loss 5.926749E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.70 | backward: 378.69 | optimizer: 5.20 | batch generator: 2.18 | data loader: 0.90
10.0.2.18:  iteration      713/    9375 | elapsed time per iteration (ms): 554.1 | learning rate 1.160E-05 | lm loss 5.889303E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.06 | backward: 398.58 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.41
10.0.2.18:  iteration      714/    9375 | elapsed time per iteration (ms): 504.4 | learning rate 1.162E-05 | lm loss 5.915820E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.20 | backward: 358.58 | optimizer: 5.20 | batch generator: 1.16 | data loader: 0.47
10.0.2.18:  iteration      715/    9375 | elapsed time per iteration (ms): 542.9 | learning rate 1.163E-05 | lm loss 5.890965E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.00 | backward: 395.54 | optimizer: 5.20 | batch generator: 1.29 | data loader: 0.49
10.0.2.18:  iteration      716/    9375 | elapsed time per iteration (ms): 535.9 | learning rate 1.165E-05 | lm loss 5.914128E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.78 | backward: 381.86 | optimizer: 5.17 | batch generator: 1.19 | data loader: 0.51
10.0.2.18:  iteration      717/    9375 | elapsed time per iteration (ms): 549.1 | learning rate 1.167E-05 | lm loss 5.935153E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.77 | backward: 396.52 | optimizer: 5.21 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      718/    9375 | elapsed time per iteration (ms): 570.6 | learning rate 1.168E-05 | lm loss 5.921189E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.74 | backward: 399.40 | optimizer: 5.17 | batch generator: 1.27 | data loader: 0.46
10.0.2.18:  iteration      719/    9375 | elapsed time per iteration (ms): 544.9 | learning rate 1.170E-05 | lm loss 5.909652E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.54 | backward: 401.34 | optimizer: 5.16 | batch generator: 1.10 | data loader: 0.38
10.0.2.18:  iteration      720/    9375 | elapsed time per iteration (ms): 568.5 | learning rate 1.172E-05 | lm loss 5.871223E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.87 | backward: 414.79 | optimizer: 5.18 | batch generator: 1.12 | data loader: 0.44
10.0.2.18:  iteration      721/    9375 | elapsed time per iteration (ms): 589.7 | learning rate 1.173E-05 | lm loss 5.914107E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.06 | backward: 421.36 | optimizer: 5.21 | batch generator: 1.15 | data loader: 0.42
10.0.2.18:  iteration      722/    9375 | elapsed time per iteration (ms): 547.9 | learning rate 1.175E-05 | lm loss 5.852027E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.60 | backward: 378.97 | optimizer: 5.26 | batch generator: 1.25 | data loader: 0.43
10.0.2.18:  iteration      723/    9375 | elapsed time per iteration (ms): 547.0 | learning rate 1.177E-05 | lm loss 5.908718E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 142.66 | backward: 395.54 | optimizer: 5.23 | batch generator: 1.28 | data loader: 0.45
10.0.2.18:  iteration      724/    9375 | elapsed time per iteration (ms): 545.7 | learning rate 1.178E-05 | lm loss 5.901233E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.08 | backward: 400.77 | optimizer: 5.22 | batch generator: 1.31 | data loader: 0.50
10.0.2.18:  iteration      725/    9375 | elapsed time per iteration (ms): 563.9 | learning rate 1.180E-05 | lm loss 5.898511E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.46 | backward: 409.18 | optimizer: 5.19 | batch generator: 1.18 | data loader: 0.49
10.0.2.18:  iteration      726/    9375 | elapsed time per iteration (ms): 508.1 | learning rate 1.182E-05 | lm loss 5.898725E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.05 | backward: 356.90 | optimizer: 5.21 | batch generator: 1.13 | data loader: 0.39
10.0.2.18:  iteration      727/    9375 | elapsed time per iteration (ms): 549.6 | learning rate 1.183E-05 | lm loss 5.901421E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.15 | backward: 397.15 | optimizer: 5.20 | batch generator: 1.21 | data loader: 0.45
10.0.2.18:  iteration      728/    9375 | elapsed time per iteration (ms): 549.4 | learning rate 1.185E-05 | lm loss 5.900696E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.21 | backward: 398.84 | optimizer: 5.25 | batch generator: 1.28 | data loader: 0.45
10.0.2.18:  iteration      729/    9375 | elapsed time per iteration (ms): 569.1 | learning rate 1.187E-05 | lm loss 5.923755E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.65 | backward: 417.69 | optimizer: 5.20 | batch generator: 1.26 | data loader: 0.43
10.0.2.18:  iteration      730/    9375 | elapsed time per iteration (ms): 522.9 | learning rate 1.188E-05 | lm loss 5.895776E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.95 | backward: 368.29 | optimizer: 5.18 | batch generator: 1.25 | data loader: 0.47
10.0.2.18:  iteration      731/    9375 | elapsed time per iteration (ms): 566.3 | learning rate 1.190E-05 | lm loss 5.861997E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.88 | backward: 414.57 | optimizer: 5.21 | batch generator: 1.24 | data loader: 0.44
10.0.2.18:  iteration      732/    9375 | elapsed time per iteration (ms): 500.3 | learning rate 1.192E-05 | lm loss 5.884724E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.35 | backward: 346.67 | optimizer: 5.22 | batch generator: 1.20 | data loader: 0.43
10.0.2.18:  iteration      733/    9375 | elapsed time per iteration (ms): 563.9 | learning rate 1.193E-05 | lm loss 5.908455E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.72 | backward: 402.49 | optimizer: 5.20 | batch generator: 1.16 | data loader: 0.49
10.0.2.18:  iteration      734/    9375 | elapsed time per iteration (ms): 507.7 | learning rate 1.195E-05 | lm loss 5.876113E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.13 | backward: 360.83 | optimizer: 5.18 | batch generator: 1.20 | data loader: 0.50
10.0.2.18:  iteration      735/    9375 | elapsed time per iteration (ms): 512.9 | learning rate 1.197E-05 | lm loss 5.851005E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.03 | backward: 364.49 | optimizer: 5.22 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      736/    9375 | elapsed time per iteration (ms): 522.4 | learning rate 1.198E-05 | lm loss 5.878318E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.94 | backward: 378.69 | optimizer: 5.18 | batch generator: 1.32 | data loader: 0.52
10.0.2.18:  iteration      737/    9375 | elapsed time per iteration (ms): 570.4 | learning rate 1.200E-05 | lm loss 5.888109E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.28 | backward: 405.43 | optimizer: 5.19 | batch generator: 1.15 | data loader: 0.43
10.0.2.18:  iteration      738/    9375 | elapsed time per iteration (ms): 549.9 | learning rate 1.202E-05 | lm loss 5.855103E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.45 | backward: 388.37 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      739/    9375 | elapsed time per iteration (ms): 524.3 | learning rate 1.203E-05 | lm loss 5.902005E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.33 | backward: 369.91 | optimizer: 5.17 | batch generator: 1.19 | data loader: 0.40
10.0.2.18:  iteration      740/    9375 | elapsed time per iteration (ms): 515.7 | learning rate 1.205E-05 | lm loss 5.850470E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.84 | backward: 370.58 | optimizer: 5.16 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      741/    9375 | elapsed time per iteration (ms): 506.7 | learning rate 1.207E-05 | lm loss 5.877769E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.05 | backward: 359.40 | optimizer: 5.19 | batch generator: 1.10 | data loader: 0.38
10.0.2.18:  iteration      742/    9375 | elapsed time per iteration (ms): 498.1 | learning rate 1.208E-05 | lm loss 5.831202E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.36 | backward: 347.53 | optimizer: 5.25 | batch generator: 1.19 | data loader: 0.50
10.0.2.18:  iteration      743/    9375 | elapsed time per iteration (ms): 572.7 | learning rate 1.210E-05 | lm loss 5.870864E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.24 | backward: 407.05 | optimizer: 5.15 | batch generator: 1.34 | data loader: 0.50
10.0.2.18:  iteration      744/    9375 | elapsed time per iteration (ms): 514.3 | learning rate 1.212E-05 | lm loss 5.822514E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.27 | backward: 367.83 | optimizer: 5.17 | batch generator: 1.11 | data loader: 0.44
10.0.2.18:  iteration      745/    9375 | elapsed time per iteration (ms): 519.4 | learning rate 1.213E-05 | lm loss 5.872675E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.68 | backward: 365.27 | optimizer: 5.18 | batch generator: 1.10 | data loader: 0.39
10.0.2.18:  iteration      746/    9375 | elapsed time per iteration (ms): 542.4 | learning rate 1.215E-05 | lm loss 5.904912E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.43 | backward: 367.33 | optimizer: 5.22 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      747/    9375 | elapsed time per iteration (ms): 516.5 | learning rate 1.217E-05 | lm loss 5.846412E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.37 | backward: 368.44 | optimizer: 5.19 | batch generator: 1.32 | data loader: 0.50
10.0.2.18:  iteration      748/    9375 | elapsed time per iteration (ms): 489.7 | learning rate 1.218E-05 | lm loss 5.872849E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.27 | backward: 344.43 | optimizer: 5.17 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      749/    9375 | elapsed time per iteration (ms): 513.6 | learning rate 1.220E-05 | lm loss 5.867505E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.06 | backward: 360.88 | optimizer: 5.17 | batch generator: 1.22 | data loader: 0.46
10.0.2.18:  iteration      750/    9375 | elapsed time per iteration (ms): 525.1 | learning rate 1.222E-05 | lm loss 5.882908E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.23 | backward: 366.97 | optimizer: 5.22 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      751/    9375 | elapsed time per iteration (ms): 516.8 | learning rate 1.223E-05 | lm loss 5.840375E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.29 | backward: 367.11 | optimizer: 5.23 | batch generator: 1.11 | data loader: 0.39
10.0.2.18:  iteration      752/    9375 | elapsed time per iteration (ms): 503.6 | learning rate 1.225E-05 | lm loss 5.869892E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.61 | backward: 357.81 | optimizer: 5.18 | batch generator: 1.17 | data loader: 0.43
10.0.2.18:  iteration      753/    9375 | elapsed time per iteration (ms): 591.7 | learning rate 1.227E-05 | lm loss 5.805722E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.39 | backward: 444.16 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      754/    9375 | elapsed time per iteration (ms): 537.8 | learning rate 1.228E-05 | lm loss 5.904686E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.93 | backward: 383.13 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      755/    9375 | elapsed time per iteration (ms): 540.2 | learning rate 1.230E-05 | lm loss 5.900053E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.42 | backward: 389.51 | optimizer: 5.21 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      756/    9375 | elapsed time per iteration (ms): 551.5 | learning rate 1.232E-05 | lm loss 5.847220E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.11 | backward: 401.77 | optimizer: 5.20 | batch generator: 1.20 | data loader: 0.44
10.0.2.18:  iteration      757/    9375 | elapsed time per iteration (ms): 505.9 | learning rate 1.233E-05 | lm loss 5.830156E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.39 | backward: 353.06 | optimizer: 5.18 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      758/    9375 | elapsed time per iteration (ms): 571.0 | learning rate 1.235E-05 | lm loss 5.852300E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.43 | backward: 419.24 | optimizer: 5.20 | batch generator: 1.13 | data loader: 0.47
10.0.2.18:  iteration      759/    9375 | elapsed time per iteration (ms): 508.2 | learning rate 1.237E-05 | lm loss 5.874459E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.72 | backward: 355.00 | optimizer: 5.18 | batch generator: 1.24 | data loader: 0.46
10.0.2.18:  iteration      760/    9375 | elapsed time per iteration (ms): 499.9 | learning rate 1.238E-05 | lm loss 5.830269E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.23 | backward: 355.48 | optimizer: 5.19 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      761/    9375 | elapsed time per iteration (ms): 524.9 | learning rate 1.240E-05 | lm loss 5.843675E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.36 | backward: 371.10 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.41
10.0.2.18:  iteration      762/    9375 | elapsed time per iteration (ms): 480.7 | learning rate 1.242E-05 | lm loss 5.839205E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.76 | backward: 333.48 | optimizer: 5.18 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      763/    9375 | elapsed time per iteration (ms): 494.9 | learning rate 1.243E-05 | lm loss 5.875174E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.66 | backward: 338.33 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.41
10.0.2.18:  iteration      764/    9375 | elapsed time per iteration (ms): 524.7 | learning rate 1.245E-05 | lm loss 5.843012E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.01 | backward: 366.63 | optimizer: 5.20 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      765/    9375 | elapsed time per iteration (ms): 523.9 | learning rate 1.247E-05 | lm loss 5.882571E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.71 | backward: 365.23 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.41
10.0.2.18:  iteration      766/    9375 | elapsed time per iteration (ms): 525.6 | learning rate 1.248E-05 | lm loss 5.856296E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.77 | backward: 379.73 | optimizer: 5.18 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      767/    9375 | elapsed time per iteration (ms): 549.5 | learning rate 1.250E-05 | lm loss 5.843219E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.50 | backward: 398.34 | optimizer: 5.24 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      768/    9375 | elapsed time per iteration (ms): 533.7 | learning rate 1.252E-05 | lm loss 5.823726E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.80 | backward: 379.81 | optimizer: 5.16 | batch generator: 1.31 | data loader: 0.60
10.0.2.18:  iteration      769/    9375 | elapsed time per iteration (ms): 585.5 | learning rate 1.253E-05 | lm loss 5.833487E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.45 | backward: 433.96 | optimizer: 5.23 | batch generator: 1.10 | data loader: 0.36
10.0.2.18:  iteration      770/    9375 | elapsed time per iteration (ms): 580.9 | learning rate 1.255E-05 | lm loss 5.800506E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.53 | backward: 426.42 | optimizer: 5.19 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      771/    9375 | elapsed time per iteration (ms): 577.9 | learning rate 1.257E-05 | lm loss 5.836112E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.70 | backward: 423.79 | optimizer: 5.20 | batch generator: 1.17 | data loader: 0.43
10.0.2.18:  iteration      772/    9375 | elapsed time per iteration (ms): 562.6 | learning rate 1.258E-05 | lm loss 5.821432E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.57 | backward: 409.54 | optimizer: 5.20 | batch generator: 1.24 | data loader: 0.44
10.0.2.18:  iteration      773/    9375 | elapsed time per iteration (ms): 525.3 | learning rate 1.260E-05 | lm loss 5.889952E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.68 | backward: 368.03 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.43
10.0.2.18:  iteration      774/    9375 | elapsed time per iteration (ms): 527.5 | learning rate 1.262E-05 | lm loss 5.805229E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.70 | backward: 369.53 | optimizer: 5.16 | batch generator: 1.10 | data loader: 0.39
10.0.2.18:  iteration      775/    9375 | elapsed time per iteration (ms): 521.0 | learning rate 1.263E-05 | lm loss 5.859556E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.80 | backward: 367.04 | optimizer: 5.21 | batch generator: 1.11 | data loader: 0.39
10.0.2.18:  iteration      776/    9375 | elapsed time per iteration (ms): 533.9 | learning rate 1.265E-05 | lm loss 5.791645E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.05 | backward: 370.32 | optimizer: 5.18 | batch generator: 1.17 | data loader: 0.41
10.0.2.18:  iteration      777/    9375 | elapsed time per iteration (ms): 537.7 | learning rate 1.267E-05 | lm loss 5.818390E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.90 | backward: 378.19 | optimizer: 5.25 | batch generator: 1.20 | data loader: 0.43
10.0.2.18:  iteration      778/    9375 | elapsed time per iteration (ms): 487.4 | learning rate 1.268E-05 | lm loss 5.840948E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.89 | backward: 332.16 | optimizer: 5.22 | batch generator: 1.25 | data loader: 0.48
10.0.2.18:  iteration      779/    9375 | elapsed time per iteration (ms): 530.2 | learning rate 1.270E-05 | lm loss 5.861640E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.37 | backward: 373.23 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      780/    9375 | elapsed time per iteration (ms): 499.9 | learning rate 1.272E-05 | lm loss 5.824073E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.55 | backward: 340.33 | optimizer: 5.21 | batch generator: 1.12 | data loader: 0.45
10.0.2.18:  iteration      781/    9375 | elapsed time per iteration (ms): 529.6 | learning rate 1.273E-05 | lm loss 5.839989E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.62 | backward: 369.43 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      782/    9375 | elapsed time per iteration (ms): 526.1 | learning rate 1.275E-05 | lm loss 5.810809E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.94 | backward: 364.84 | optimizer: 5.22 | batch generator: 1.11 | data loader: 0.44
10.0.2.18:  iteration      783/    9375 | elapsed time per iteration (ms): 496.9 | learning rate 1.277E-05 | lm loss 5.829108E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.80 | backward: 339.35 | optimizer: 5.20 | batch generator: 1.18 | data loader: 0.38
10.0.2.18:  iteration      784/    9375 | elapsed time per iteration (ms): 502.2 | learning rate 1.278E-05 | lm loss 5.808365E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.28 | backward: 345.40 | optimizer: 5.17 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      785/    9375 | elapsed time per iteration (ms): 549.4 | learning rate 1.280E-05 | lm loss 5.816764E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.38 | backward: 390.30 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.37
10.0.2.18:  iteration      786/    9375 | elapsed time per iteration (ms): 515.5 | learning rate 1.282E-05 | lm loss 5.850082E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.43 | backward: 362.36 | optimizer: 5.19 | batch generator: 1.18 | data loader: 0.42
10.0.2.18:  iteration      787/    9375 | elapsed time per iteration (ms): 540.9 | learning rate 1.283E-05 | lm loss 5.816665E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.96 | backward: 381.33 | optimizer: 5.20 | batch generator: 1.12 | data loader: 0.45
10.0.2.18:  iteration      788/    9375 | elapsed time per iteration (ms): 550.0 | learning rate 1.285E-05 | lm loss 5.861239E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.18 | backward: 393.90 | optimizer: 5.17 | batch generator: 1.28 | data loader: 0.54
10.0.2.18:  iteration      789/    9375 | elapsed time per iteration (ms): 559.7 | learning rate 1.287E-05 | lm loss 5.807556E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.91 | backward: 407.96 | optimizer: 5.21 | batch generator: 1.15 | data loader: 0.46
10.0.2.18:  iteration      790/    9375 | elapsed time per iteration (ms): 572.4 | learning rate 1.288E-05 | lm loss 5.780276E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.58 | backward: 419.18 | optimizer: 5.17 | batch generator: 1.17 | data loader: 0.41
10.0.2.18:  iteration      791/    9375 | elapsed time per iteration (ms): 561.7 | learning rate 1.290E-05 | lm loss 5.807007E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.77 | backward: 409.92 | optimizer: 5.20 | batch generator: 1.10 | data loader: 0.37
10.0.2.18:  iteration      792/    9375 | elapsed time per iteration (ms): 583.4 | learning rate 1.292E-05 | lm loss 5.831160E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.72 | backward: 429.70 | optimizer: 5.21 | batch generator: 1.33 | data loader: 0.58
10.0.2.18:  iteration      793/    9375 | elapsed time per iteration (ms): 520.2 | learning rate 1.293E-05 | lm loss 5.867098E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.61 | backward: 365.51 | optimizer: 5.18 | batch generator: 1.20 | data loader: 0.50
10.0.2.18:  iteration      794/    9375 | elapsed time per iteration (ms): 554.9 | learning rate 1.295E-05 | lm loss 5.819770E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.84 | backward: 407.29 | optimizer: 5.23 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      795/    9375 | elapsed time per iteration (ms): 517.3 | learning rate 1.297E-05 | lm loss 5.765726E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.41 | backward: 363.00 | optimizer: 5.21 | batch generator: 1.33 | data loader: 0.62
10.0.2.18:  iteration      796/    9375 | elapsed time per iteration (ms): 511.6 | learning rate 1.298E-05 | lm loss 5.836485E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.10 | backward: 366.39 | optimizer: 5.21 | batch generator: 1.30 | data loader: 0.56
10.0.2.18:  iteration      797/    9375 | elapsed time per iteration (ms): 496.8 | learning rate 1.300E-05 | lm loss 5.855582E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.90 | backward: 352.95 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      798/    9375 | elapsed time per iteration (ms): 475.4 | learning rate 1.302E-05 | lm loss 5.816052E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.25 | backward: 330.00 | optimizer: 5.20 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      799/    9375 | elapsed time per iteration (ms): 533.8 | learning rate 1.303E-05 | lm loss 5.794655E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.36 | backward: 375.43 | optimizer: 5.16 | batch generator: 1.20 | data loader: 0.51
10.0.2.18:  iteration      800/    9375 | elapsed time per iteration (ms): 523.7 | learning rate 1.305E-05 | lm loss 5.826404E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.89 | backward: 365.65 | optimizer: 5.15 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      801/    9375 | elapsed time per iteration (ms): 573.0 | learning rate 1.307E-05 | lm loss 5.795470E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.60 | backward: 421.37 | optimizer: 5.21 | batch generator: 1.12 | data loader: 0.45
10.0.2.18:  iteration      802/    9375 | elapsed time per iteration (ms): 498.3 | learning rate 1.308E-05 | lm loss 5.813427E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.86 | backward: 344.20 | optimizer: 5.18 | batch generator: 1.23 | data loader: 0.42
10.0.2.18:  iteration      803/    9375 | elapsed time per iteration (ms): 532.7 | learning rate 1.310E-05 | lm loss 5.789571E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.56 | backward: 375.55 | optimizer: 5.17 | batch generator: 1.16 | data loader: 0.42
10.0.2.18:  iteration      804/    9375 | elapsed time per iteration (ms): 488.7 | learning rate 1.312E-05 | lm loss 5.807665E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.28 | backward: 340.32 | optimizer: 5.18 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      805/    9375 | elapsed time per iteration (ms): 500.8 | learning rate 1.313E-05 | lm loss 5.804835E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.22 | backward: 341.70 | optimizer: 5.16 | batch generator: 1.13 | data loader: 0.42
10.0.2.18:  iteration      806/    9375 | elapsed time per iteration (ms): 521.0 | learning rate 1.315E-05 | lm loss 5.777920E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.78 | backward: 363.80 | optimizer: 5.21 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      807/    9375 | elapsed time per iteration (ms): 505.8 | learning rate 1.317E-05 | lm loss 5.800090E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.98 | backward: 360.78 | optimizer: 5.22 | batch generator: 1.17 | data loader: 0.43
10.0.2.18:  iteration      808/    9375 | elapsed time per iteration (ms): 514.1 | learning rate 1.318E-05 | lm loss 5.834121E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.26 | backward: 365.20 | optimizer: 5.20 | batch generator: 1.34 | data loader: 0.57
10.0.2.18:  iteration      809/    9375 | elapsed time per iteration (ms): 499.7 | learning rate 1.320E-05 | lm loss 5.795138E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.50 | backward: 356.21 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.44
10.0.2.18:  iteration      810/    9375 | elapsed time per iteration (ms): 524.2 | learning rate 1.322E-05 | lm loss 5.864212E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.80 | backward: 369.18 | optimizer: 5.21 | batch generator: 1.20 | data loader: 0.52
10.0.2.18:  iteration      811/    9375 | elapsed time per iteration (ms): 522.6 | learning rate 1.323E-05 | lm loss 5.830966E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.22 | backward: 374.88 | optimizer: 5.19 | batch generator: 1.18 | data loader: 0.50
10.0.2.18:  iteration      812/    9375 | elapsed time per iteration (ms): 513.2 | learning rate 1.325E-05 | lm loss 5.755983E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.05 | backward: 370.27 | optimizer: 5.15 | batch generator: 1.13 | data loader: 0.40
10.0.2.18:  iteration      813/    9375 | elapsed time per iteration (ms): 531.5 | learning rate 1.327E-05 | lm loss 5.796216E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 140.43 | backward: 382.53 | optimizer: 5.21 | batch generator: 1.13 | data loader: 0.39
10.0.2.18:  iteration      814/    9375 | elapsed time per iteration (ms): 495.9 | learning rate 1.328E-05 | lm loss 5.776361E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.34 | backward: 336.27 | optimizer: 5.21 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      815/    9375 | elapsed time per iteration (ms): 528.9 | learning rate 1.330E-05 | lm loss 5.765780E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.48 | backward: 367.95 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      816/    9375 | elapsed time per iteration (ms): 494.2 | learning rate 1.332E-05 | lm loss 5.812178E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.69 | backward: 346.00 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.41
10.0.2.18:  iteration      817/    9375 | elapsed time per iteration (ms): 517.1 | learning rate 1.333E-05 | lm loss 5.772741E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.82 | backward: 360.27 | optimizer: 5.21 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      818/    9375 | elapsed time per iteration (ms): 487.5 | learning rate 1.335E-05 | lm loss 5.775047E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.94 | backward: 353.11 | optimizer: 5.18 | batch generator: 1.21 | data loader: 0.53
10.0.2.18:  iteration      819/    9375 | elapsed time per iteration (ms): 828.7 | learning rate 1.337E-05 | lm loss 5.796473E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.44 | backward: 469.14 | optimizer: 5.17 | batch generator: 1.19 | data loader: 0.44
10.0.2.18:  iteration      820/    9375 | elapsed time per iteration (ms): 583.4 | learning rate 1.338E-05 | lm loss 5.762253E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.28 | backward: 427.71 | optimizer: 5.20 | batch generator: 1.17 | data loader: 0.49
10.0.2.18:  iteration      821/    9375 | elapsed time per iteration (ms): 533.6 | learning rate 1.340E-05 | lm loss 5.801565E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.61 | backward: 379.64 | optimizer: 5.17 | batch generator: 1.19 | data loader: 0.49
10.0.2.18:  iteration      822/    9375 | elapsed time per iteration (ms): 517.6 | learning rate 1.342E-05 | lm loss 5.787687E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.77 | backward: 370.36 | optimizer: 5.17 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      823/    9375 | elapsed time per iteration (ms): 521.3 | learning rate 1.343E-05 | lm loss 5.812391E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.90 | backward: 377.30 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      824/    9375 | elapsed time per iteration (ms): 517.4 | learning rate 1.345E-05 | lm loss 5.767106E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.39 | backward: 368.43 | optimizer: 5.17 | batch generator: 1.21 | data loader: 0.47
10.0.2.18:  iteration      825/    9375 | elapsed time per iteration (ms): 502.0 | learning rate 1.347E-05 | lm loss 5.771406E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.92 | backward: 354.42 | optimizer: 5.20 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      826/    9375 | elapsed time per iteration (ms): 479.8 | learning rate 1.348E-05 | lm loss 5.807461E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.47 | backward: 336.19 | optimizer: 5.23 | batch generator: 1.26 | data loader: 0.48
10.0.2.18:  iteration      827/    9375 | elapsed time per iteration (ms): 499.7 | learning rate 1.350E-05 | lm loss 5.779950E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.66 | backward: 341.07 | optimizer: 5.20 | batch generator: 1.22 | data loader: 0.40
10.0.2.18:  iteration      828/    9375 | elapsed time per iteration (ms): 529.8 | learning rate 1.352E-05 | lm loss 5.805207E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.02 | backward: 370.99 | optimizer: 5.17 | batch generator: 1.15 | data loader: 0.41
10.0.2.18:  iteration      829/    9375 | elapsed time per iteration (ms): 523.3 | learning rate 1.353E-05 | lm loss 5.766155E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.79 | backward: 378.87 | optimizer: 5.17 | batch generator: 1.16 | data loader: 0.46
10.0.2.18:  iteration      830/    9375 | elapsed time per iteration (ms): 567.0 | learning rate 1.355E-05 | lm loss 5.789579E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.87 | backward: 415.35 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      831/    9375 | elapsed time per iteration (ms): 564.0 | learning rate 1.357E-05 | lm loss 5.785761E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.09 | backward: 409.18 | optimizer: 5.19 | batch generator: 1.12 | data loader: 0.44
10.0.2.18:  iteration      832/    9375 | elapsed time per iteration (ms): 564.9 | learning rate 1.358E-05 | lm loss 5.800542E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.27 | backward: 413.33 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.45
10.0.2.18:  iteration      833/    9375 | elapsed time per iteration (ms): 584.9 | learning rate 1.360E-05 | lm loss 5.786237E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.52 | backward: 430.25 | optimizer: 5.23 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      834/    9375 | elapsed time per iteration (ms): 526.6 | learning rate 1.362E-05 | lm loss 5.750297E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.96 | backward: 371.25 | optimizer: 5.17 | batch generator: 1.29 | data loader: 0.59
10.0.2.18:  iteration      835/    9375 | elapsed time per iteration (ms): 524.3 | learning rate 1.363E-05 | lm loss 5.782096E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.52 | backward: 376.85 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      836/    9375 | elapsed time per iteration (ms): 554.9 | learning rate 1.365E-05 | lm loss 5.777736E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.88 | backward: 402.95 | optimizer: 5.16 | batch generator: 1.10 | data loader: 0.38
10.0.2.18:  iteration      837/    9375 | elapsed time per iteration (ms): 516.4 | learning rate 1.367E-05 | lm loss 5.751120E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.88 | backward: 362.62 | optimizer: 5.20 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      838/    9375 | elapsed time per iteration (ms): 547.1 | learning rate 1.368E-05 | lm loss 5.782461E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.86 | backward: 387.99 | optimizer: 5.17 | batch generator: 1.17 | data loader: 0.43
10.0.2.18:  iteration      839/    9375 | elapsed time per iteration (ms): 542.6 | learning rate 1.370E-05 | lm loss 5.781940E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.44 | backward: 390.75 | optimizer: 5.19 | batch generator: 1.11 | data loader: 0.38
10.0.2.18:  iteration      840/    9375 | elapsed time per iteration (ms): 533.9 | learning rate 1.372E-05 | lm loss 5.775695E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.78 | backward: 378.86 | optimizer: 5.20 | batch generator: 1.17 | data loader: 0.42
10.0.2.18:  iteration      841/    9375 | elapsed time per iteration (ms): 588.1 | learning rate 1.373E-05 | lm loss 5.762575E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.95 | backward: 434.44 | optimizer: 5.16 | batch generator: 1.20 | data loader: 0.50
10.0.2.18:  iteration      842/    9375 | elapsed time per iteration (ms): 536.0 | learning rate 1.375E-05 | lm loss 5.780368E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.57 | backward: 368.05 | optimizer: 5.17 | batch generator: 1.10 | data loader: 0.37
10.0.2.18:  iteration      843/    9375 | elapsed time per iteration (ms): 514.8 | learning rate 1.377E-05 | lm loss 5.719789E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.78 | backward: 366.11 | optimizer: 5.25 | batch generator: 1.12 | data loader: 0.45
10.0.2.18:  iteration      844/    9375 | elapsed time per iteration (ms): 515.0 | learning rate 1.378E-05 | lm loss 5.747621E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.85 | backward: 365.82 | optimizer: 5.19 | batch generator: 1.27 | data loader: 0.56
10.0.2.18:  iteration      845/    9375 | elapsed time per iteration (ms): 556.4 | learning rate 1.380E-05 | lm loss 5.772442E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.87 | backward: 411.90 | optimizer: 5.21 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      846/    9375 | elapsed time per iteration (ms): 558.2 | learning rate 1.382E-05 | lm loss 5.772928E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.22 | backward: 394.54 | optimizer: 5.16 | batch generator: 1.30 | data loader: 0.56
10.0.2.18:  iteration      847/    9375 | elapsed time per iteration (ms): 544.4 | learning rate 1.383E-05 | lm loss 5.821660E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 140.81 | backward: 389.67 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      848/    9375 | elapsed time per iteration (ms): 587.9 | learning rate 1.385E-05 | lm loss 5.741305E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.34 | backward: 432.53 | optimizer: 5.19 | batch generator: 1.12 | data loader: 0.37
10.0.2.18:  iteration      849/    9375 | elapsed time per iteration (ms): 552.7 | learning rate 1.387E-05 | lm loss 5.735083E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.07 | backward: 400.42 | optimizer: 5.23 | batch generator: 1.22 | data loader: 0.53
10.0.2.18:  iteration      850/    9375 | elapsed time per iteration (ms): 504.5 | learning rate 1.388E-05 | lm loss 5.745433E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.99 | backward: 369.47 | optimizer: 5.18 | batch generator: 1.57 | data loader: 0.59
10.0.2.18:  iteration      851/    9375 | elapsed time per iteration (ms): 562.0 | learning rate 1.390E-05 | lm loss 5.741660E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.98 | backward: 412.46 | optimizer: 5.19 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      852/    9375 | elapsed time per iteration (ms): 514.2 | learning rate 1.392E-05 | lm loss 5.745275E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.88 | backward: 363.55 | optimizer: 5.20 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      853/    9375 | elapsed time per iteration (ms): 521.8 | learning rate 1.393E-05 | lm loss 5.763522E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.17 | backward: 366.01 | optimizer: 5.27 | batch generator: 1.17 | data loader: 0.48
10.0.2.18:  iteration      854/    9375 | elapsed time per iteration (ms): 556.7 | learning rate 1.395E-05 | lm loss 5.752784E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.01 | backward: 392.21 | optimizer: 5.17 | batch generator: 1.38 | data loader: 0.59
10.0.2.18:  iteration      855/    9375 | elapsed time per iteration (ms): 525.5 | learning rate 1.397E-05 | lm loss 5.761825E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.71 | backward: 365.43 | optimizer: 5.17 | batch generator: 1.16 | data loader: 0.46
10.0.2.18:  iteration      856/    9375 | elapsed time per iteration (ms): 506.7 | learning rate 1.398E-05 | lm loss 5.763588E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.21 | backward: 350.27 | optimizer: 5.17 | batch generator: 1.17 | data loader: 0.48
10.0.2.18:  iteration      857/    9375 | elapsed time per iteration (ms): 521.9 | learning rate 1.400E-05 | lm loss 5.783032E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.44 | backward: 365.96 | optimizer: 5.21 | batch generator: 1.13 | data loader: 0.39
10.0.2.18:  iteration      858/    9375 | elapsed time per iteration (ms): 519.8 | learning rate 1.402E-05 | lm loss 5.757602E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.84 | backward: 362.76 | optimizer: 5.21 | batch generator: 1.33 | data loader: 0.58
10.0.2.18:  iteration      859/    9375 | elapsed time per iteration (ms): 500.9 | learning rate 1.403E-05 | lm loss 5.771239E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.32 | backward: 344.45 | optimizer: 5.18 | batch generator: 1.26 | data loader: 0.45
10.0.2.18:  iteration      860/    9375 | elapsed time per iteration (ms): 518.9 | learning rate 1.405E-05 | lm loss 5.777769E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.71 | backward: 361.10 | optimizer: 5.17 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration      861/    9375 | elapsed time per iteration (ms): 560.6 | learning rate 1.407E-05 | lm loss 5.808474E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.11 | backward: 393.50 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.41
10.0.2.18:  iteration      862/    9375 | elapsed time per iteration (ms): 502.8 | learning rate 1.408E-05 | lm loss 5.763196E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.96 | backward: 345.74 | optimizer: 5.18 | batch generator: 1.22 | data loader: 0.51
10.0.2.18:  iteration      863/    9375 | elapsed time per iteration (ms): 494.6 | learning rate 1.410E-05 | lm loss 5.700799E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.95 | backward: 335.69 | optimizer: 5.21 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      864/    9375 | elapsed time per iteration (ms): 514.8 | learning rate 1.412E-05 | lm loss 5.754524E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.47 | backward: 358.20 | optimizer: 5.17 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      865/    9375 | elapsed time per iteration (ms): 522.0 | learning rate 1.413E-05 | lm loss 5.842633E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.58 | backward: 361.10 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      866/    9375 | elapsed time per iteration (ms): 518.0 | learning rate 1.415E-05 | lm loss 5.769575E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.98 | backward: 369.23 | optimizer: 5.24 | batch generator: 1.20 | data loader: 0.49
10.0.2.18:  iteration      867/    9375 | elapsed time per iteration (ms): 510.9 | learning rate 1.417E-05 | lm loss 5.742096E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.95 | backward: 353.31 | optimizer: 5.21 | batch generator: 1.29 | data loader: 0.44
10.0.2.18:  iteration      868/    9375 | elapsed time per iteration (ms): 514.0 | learning rate 1.418E-05 | lm loss 5.727411E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.05 | backward: 354.99 | optimizer: 5.19 | batch generator: 1.24 | data loader: 0.47
10.0.2.18:  iteration      869/    9375 | elapsed time per iteration (ms): 521.3 | learning rate 1.420E-05 | lm loss 5.767460E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.03 | backward: 363.96 | optimizer: 5.20 | batch generator: 1.11 | data loader: 0.37
10.0.2.18:  iteration      870/    9375 | elapsed time per iteration (ms): 504.4 | learning rate 1.422E-05 | lm loss 5.757476E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.18 | backward: 348.95 | optimizer: 5.17 | batch generator: 1.22 | data loader: 0.51
10.0.2.18:  iteration      871/    9375 | elapsed time per iteration (ms): 548.8 | learning rate 1.423E-05 | lm loss 5.750638E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.39 | backward: 387.55 | optimizer: 5.19 | batch generator: 1.17 | data loader: 0.47
10.0.2.18:  iteration      872/    9375 | elapsed time per iteration (ms): 558.5 | learning rate 1.425E-05 | lm loss 5.705276E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.83 | backward: 402.76 | optimizer: 5.19 | batch generator: 1.13 | data loader: 0.39
10.0.2.18:  iteration      873/    9375 | elapsed time per iteration (ms): 586.4 | learning rate 1.427E-05 | lm loss 5.753233E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.26 | backward: 415.54 | optimizer: 5.21 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      874/    9375 | elapsed time per iteration (ms): 519.5 | learning rate 1.428E-05 | lm loss 5.790900E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.82 | backward: 364.82 | optimizer: 5.20 | batch generator: 1.25 | data loader: 0.55
10.0.2.18:  iteration      875/    9375 | elapsed time per iteration (ms): 528.2 | learning rate 1.430E-05 | lm loss 5.758031E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.84 | backward: 367.68 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.42
10.0.2.18:  iteration      876/    9375 | elapsed time per iteration (ms): 486.3 | learning rate 1.432E-05 | lm loss 5.727855E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.43 | backward: 327.75 | optimizer: 5.19 | batch generator: 1.20 | data loader: 0.51
10.0.2.18:  iteration      877/    9375 | elapsed time per iteration (ms): 509.7 | learning rate 1.433E-05 | lm loss 5.737204E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.47 | backward: 349.58 | optimizer: 5.30 | batch generator: 1.19 | data loader: 0.51
10.0.2.18:  iteration      878/    9375 | elapsed time per iteration (ms): 525.2 | learning rate 1.435E-05 | lm loss 5.760999E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.68 | backward: 362.55 | optimizer: 5.20 | batch generator: 1.28 | data loader: 0.45
10.0.2.18:  iteration      879/    9375 | elapsed time per iteration (ms): 565.8 | learning rate 1.437E-05 | lm loss 5.720943E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.60 | backward: 403.02 | optimizer: 5.27 | batch generator: 1.20 | data loader: 0.43
10.0.2.18:  iteration      880/    9375 | elapsed time per iteration (ms): 602.4 | learning rate 1.438E-05 | lm loss 5.755288E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.78 | backward: 448.03 | optimizer: 5.18 | batch generator: 1.30 | data loader: 0.57
10.0.2.18:  iteration      881/    9375 | elapsed time per iteration (ms): 564.4 | learning rate 1.440E-05 | lm loss 5.726395E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.03 | backward: 412.08 | optimizer: 5.23 | batch generator: 1.24 | data loader: 0.46
10.0.2.18:  iteration      882/    9375 | elapsed time per iteration (ms): 497.4 | learning rate 1.442E-05 | lm loss 5.747977E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.26 | backward: 343.53 | optimizer: 5.21 | batch generator: 1.30 | data loader: 0.48
10.0.2.18:  iteration      883/    9375 | elapsed time per iteration (ms): 504.7 | learning rate 1.443E-05 | lm loss 5.716280E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.21 | backward: 345.18 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      884/    9375 | elapsed time per iteration (ms): 510.4 | learning rate 1.445E-05 | lm loss 5.742446E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.42 | backward: 354.10 | optimizer: 5.20 | batch generator: 1.23 | data loader: 0.53
10.0.2.18:  iteration      885/    9375 | elapsed time per iteration (ms): 529.1 | learning rate 1.447E-05 | lm loss 5.671596E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.81 | backward: 369.63 | optimizer: 5.19 | batch generator: 1.20 | data loader: 0.52
10.0.2.18:  iteration      886/    9375 | elapsed time per iteration (ms): 528.1 | learning rate 1.448E-05 | lm loss 5.745055E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.08 | backward: 370.45 | optimizer: 5.19 | batch generator: 1.18 | data loader: 0.49
10.0.2.18:  iteration      887/    9375 | elapsed time per iteration (ms): 526.2 | learning rate 1.450E-05 | lm loss 5.749550E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 131.11 | backward: 374.45 | optimizer: 5.20 | batch generator: 1.13 | data loader: 0.45
10.0.2.18:  iteration      888/    9375 | elapsed time per iteration (ms): 549.9 | learning rate 1.452E-05 | lm loss 5.771502E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.37 | backward: 401.87 | optimizer: 5.24 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      889/    9375 | elapsed time per iteration (ms): 528.7 | learning rate 1.453E-05 | lm loss 5.768999E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.50 | backward: 374.77 | optimizer: 5.20 | batch generator: 1.22 | data loader: 0.51
10.0.2.18:  iteration      890/    9375 | elapsed time per iteration (ms): 520.2 | learning rate 1.455E-05 | lm loss 5.704323E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.81 | backward: 361.79 | optimizer: 5.20 | batch generator: 1.20 | data loader: 0.51
10.0.2.18:  iteration      891/    9375 | elapsed time per iteration (ms): 524.0 | learning rate 1.457E-05 | lm loss 5.733466E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.56 | backward: 380.56 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.40
10.0.2.18:  iteration      892/    9375 | elapsed time per iteration (ms): 586.9 | learning rate 1.458E-05 | lm loss 5.764814E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.60 | backward: 419.84 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.40
10.0.2.18:  iteration      893/    9375 | elapsed time per iteration (ms): 511.4 | learning rate 1.460E-05 | lm loss 5.725600E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.81 | backward: 374.03 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      894/    9375 | elapsed time per iteration (ms): 556.7 | learning rate 1.462E-05 | lm loss 5.785594E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.03 | backward: 404.82 | optimizer: 5.22 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      895/    9375 | elapsed time per iteration (ms): 523.4 | learning rate 1.463E-05 | lm loss 5.704314E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.59 | backward: 369.66 | optimizer: 5.21 | batch generator: 1.23 | data loader: 0.42
10.0.2.18:  iteration      896/    9375 | elapsed time per iteration (ms): 516.2 | learning rate 1.465E-05 | lm loss 5.785524E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.55 | backward: 368.96 | optimizer: 5.17 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration      897/    9375 | elapsed time per iteration (ms): 514.5 | learning rate 1.467E-05 | lm loss 5.766585E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.34 | backward: 362.81 | optimizer: 5.28 | batch generator: 1.15 | data loader: 0.46
10.0.2.18:  iteration      898/    9375 | elapsed time per iteration (ms): 508.2 | learning rate 1.468E-05 | lm loss 5.758442E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.89 | backward: 361.66 | optimizer: 5.19 | batch generator: 1.48 | data loader: 0.72
10.0.2.18:  iteration      899/    9375 | elapsed time per iteration (ms): 517.1 | learning rate 1.470E-05 | lm loss 5.709730E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.34 | backward: 360.75 | optimizer: 5.22 | batch generator: 1.20 | data loader: 0.51
10.0.2.18:  iteration      900/    9375 | elapsed time per iteration (ms): 536.6 | learning rate 1.472E-05 | lm loss 5.715746E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.48 | backward: 383.80 | optimizer: 5.20 | batch generator: 1.30 | data loader: 0.48
10.0.2.18:  iteration      901/    9375 | elapsed time per iteration (ms): 535.4 | learning rate 1.473E-05 | lm loss 5.731656E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.43 | backward: 380.56 | optimizer: 5.18 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      902/    9375 | elapsed time per iteration (ms): 537.8 | learning rate 1.475E-05 | lm loss 5.714380E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.05 | backward: 386.85 | optimizer: 5.19 | batch generator: 1.12 | data loader: 0.38
10.0.2.18:  iteration      903/    9375 | elapsed time per iteration (ms): 531.7 | learning rate 1.477E-05 | lm loss 5.700026E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.94 | backward: 376.58 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.40
10.0.2.18:  iteration      904/    9375 | elapsed time per iteration (ms): 508.6 | learning rate 1.478E-05 | lm loss 5.751028E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.20 | backward: 356.66 | optimizer: 5.20 | batch generator: 1.15 | data loader: 0.46
10.0.2.18:  iteration      905/    9375 | elapsed time per iteration (ms): 525.7 | learning rate 1.480E-05 | lm loss 5.758438E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.68 | backward: 364.33 | optimizer: 5.22 | batch generator: 1.17 | data loader: 0.46
10.0.2.18:  iteration      906/    9375 | elapsed time per iteration (ms): 533.1 | learning rate 1.482E-05 | lm loss 5.698318E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.99 | backward: 375.23 | optimizer: 5.19 | batch generator: 1.17 | data loader: 0.47
10.0.2.18:  iteration      907/    9375 | elapsed time per iteration (ms): 501.8 | learning rate 1.483E-05 | lm loss 5.693871E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.75 | backward: 342.21 | optimizer: 5.18 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      908/    9375 | elapsed time per iteration (ms): 506.6 | learning rate 1.485E-05 | lm loss 5.738786E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.42 | backward: 344.97 | optimizer: 5.20 | batch generator: 1.15 | data loader: 0.40
10.0.2.18:  iteration      909/    9375 | elapsed time per iteration (ms): 529.6 | learning rate 1.487E-05 | lm loss 5.692784E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.51 | backward: 368.76 | optimizer: 5.16 | batch generator: 1.18 | data loader: 0.44
10.0.2.18:  iteration      910/    9375 | elapsed time per iteration (ms): 525.8 | learning rate 1.488E-05 | lm loss 5.732353E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.06 | backward: 369.98 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.42
10.0.2.18:  iteration      911/    9375 | elapsed time per iteration (ms): 514.7 | learning rate 1.490E-05 | lm loss 5.723594E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.03 | backward: 356.19 | optimizer: 5.17 | batch generator: 1.15 | data loader: 0.42
10.0.2.18:  iteration      912/    9375 | elapsed time per iteration (ms): 524.3 | learning rate 1.492E-05 | lm loss 5.753226E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.46 | backward: 368.24 | optimizer: 5.20 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      913/    9375 | elapsed time per iteration (ms): 516.5 | learning rate 1.493E-05 | lm loss 5.721163E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.05 | backward: 364.91 | optimizer: 5.18 | batch generator: 1.20 | data loader: 0.43
10.0.2.18:  iteration      914/    9375 | elapsed time per iteration (ms): 510.6 | learning rate 1.495E-05 | lm loss 5.709498E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.82 | backward: 377.37 | optimizer: 5.16 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      915/    9375 | elapsed time per iteration (ms): 538.0 | learning rate 1.497E-05 | lm loss 5.683906E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.44 | backward: 379.96 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.40
10.0.2.18:  iteration      916/    9375 | elapsed time per iteration (ms): 522.9 | learning rate 1.498E-05 | lm loss 5.660851E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.24 | backward: 362.40 | optimizer: 5.24 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      917/    9375 | elapsed time per iteration (ms): 502.5 | learning rate 1.500E-05 | lm loss 5.728487E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.86 | backward: 358.34 | optimizer: 5.18 | batch generator: 1.32 | data loader: 0.59
10.0.2.18:  iteration      918/    9375 | elapsed time per iteration (ms): 495.0 | learning rate 1.502E-05 | lm loss 5.729394E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.44 | backward: 350.95 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.41
10.0.2.18:  iteration      919/    9375 | elapsed time per iteration (ms): 500.1 | learning rate 1.503E-05 | lm loss 5.700997E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.21 | backward: 352.45 | optimizer: 5.24 | batch generator: 1.14 | data loader: 0.41
10.0.2.18:  iteration      920/    9375 | elapsed time per iteration (ms): 529.6 | learning rate 1.505E-05 | lm loss 5.732298E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.07 | backward: 374.85 | optimizer: 5.20 | batch generator: 1.40 | data loader: 0.61
10.0.2.18:  iteration      921/    9375 | elapsed time per iteration (ms): 486.4 | learning rate 1.507E-05 | lm loss 5.662453E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.18 | backward: 324.85 | optimizer: 5.18 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      922/    9375 | elapsed time per iteration (ms): 542.4 | learning rate 1.508E-05 | lm loss 5.756836E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.60 | backward: 381.91 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.39
10.0.2.18:  iteration      923/    9375 | elapsed time per iteration (ms): 516.3 | learning rate 1.510E-05 | lm loss 5.734300E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.67 | backward: 366.26 | optimizer: 5.16 | batch generator: 1.20 | data loader: 0.44
10.0.2.18:  iteration      924/    9375 | elapsed time per iteration (ms): 496.4 | learning rate 1.512E-05 | lm loss 5.663846E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.51 | backward: 349.89 | optimizer: 5.21 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      925/    9375 | elapsed time per iteration (ms): 521.1 | learning rate 1.513E-05 | lm loss 5.757483E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.33 | backward: 375.24 | optimizer: 5.17 | batch generator: 1.20 | data loader: 0.41
10.0.2.18:  iteration      926/    9375 | elapsed time per iteration (ms): 510.6 | learning rate 1.515E-05 | lm loss 5.706955E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.73 | backward: 367.14 | optimizer: 5.17 | batch generator: 1.16 | data loader: 0.40
10.0.2.18:  iteration      927/    9375 | elapsed time per iteration (ms): 505.4 | learning rate 1.517E-05 | lm loss 5.745415E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.13 | backward: 350.15 | optimizer: 5.17 | batch generator: 1.17 | data loader: 0.47
10.0.2.18:  iteration      928/    9375 | elapsed time per iteration (ms): 520.9 | learning rate 1.518E-05 | lm loss 5.718356E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.22 | backward: 361.28 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.47
10.0.2.18:  iteration      929/    9375 | elapsed time per iteration (ms): 511.7 | learning rate 1.520E-05 | lm loss 5.697922E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.32 | backward: 362.14 | optimizer: 5.17 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      930/    9375 | elapsed time per iteration (ms): 527.4 | learning rate 1.522E-05 | lm loss 5.733720E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.08 | backward: 368.04 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      931/    9375 | elapsed time per iteration (ms): 535.0 | learning rate 1.523E-05 | lm loss 5.682624E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 133.80 | backward: 376.38 | optimizer: 5.28 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration      932/    9375 | elapsed time per iteration (ms): 556.4 | learning rate 1.525E-05 | lm loss 5.674345E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.34 | backward: 407.05 | optimizer: 5.23 | batch generator: 1.38 | data loader: 0.64
10.0.2.18:  iteration      933/    9375 | elapsed time per iteration (ms): 492.3 | learning rate 1.527E-05 | lm loss 5.685786E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.39 | backward: 340.80 | optimizer: 5.20 | batch generator: 1.27 | data loader: 0.43
10.0.2.18:  iteration      934/    9375 | elapsed time per iteration (ms): 531.5 | learning rate 1.528E-05 | lm loss 5.715224E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.31 | backward: 383.01 | optimizer: 5.23 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      935/    9375 | elapsed time per iteration (ms): 527.5 | learning rate 1.530E-05 | lm loss 5.685170E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.17 | backward: 373.72 | optimizer: 5.24 | batch generator: 1.14 | data loader: 0.41
10.0.2.18:  iteration      936/    9375 | elapsed time per iteration (ms): 538.5 | learning rate 1.532E-05 | lm loss 5.704504E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.99 | backward: 392.45 | optimizer: 5.19 | batch generator: 1.31 | data loader: 0.57
10.0.2.18:  iteration      937/    9375 | elapsed time per iteration (ms): 524.0 | learning rate 1.533E-05 | lm loss 5.652425E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.58 | backward: 368.34 | optimizer: 5.20 | batch generator: 1.15 | data loader: 0.41
10.0.2.18:  iteration      938/    9375 | elapsed time per iteration (ms): 536.1 | learning rate 1.535E-05 | lm loss 5.720606E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.15 | backward: 391.40 | optimizer: 5.18 | batch generator: 1.22 | data loader: 0.43
10.0.2.18:  iteration      939/    9375 | elapsed time per iteration (ms): 536.7 | learning rate 1.537E-05 | lm loss 5.748894E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 98.70 | backward: 384.94 | optimizer: 5.17 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      940/    9375 | elapsed time per iteration (ms): 553.6 | learning rate 1.538E-05 | lm loss 5.695425E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.14 | backward: 406.63 | optimizer: 5.23 | batch generator: 1.18 | data loader: 0.49
10.0.2.18:  iteration      941/    9375 | elapsed time per iteration (ms): 529.4 | learning rate 1.540E-05 | lm loss 5.709076E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.21 | backward: 377.15 | optimizer: 5.21 | batch generator: 1.23 | data loader: 0.45
10.0.2.18:  iteration      942/    9375 | elapsed time per iteration (ms): 536.4 | learning rate 1.542E-05 | lm loss 5.694031E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.19 | backward: 383.20 | optimizer: 5.19 | batch generator: 1.16 | data loader: 0.41
10.0.2.18:  iteration      943/    9375 | elapsed time per iteration (ms): 540.6 | learning rate 1.543E-05 | lm loss 5.699721E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.06 | backward: 391.03 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      944/    9375 | elapsed time per iteration (ms): 530.0 | learning rate 1.545E-05 | lm loss 5.657995E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.89 | backward: 378.63 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.43
10.0.2.18:  iteration      945/    9375 | elapsed time per iteration (ms): 551.4 | learning rate 1.547E-05 | lm loss 5.679719E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.87 | backward: 397.47 | optimizer: 5.16 | batch generator: 1.17 | data loader: 0.46
10.0.2.18:  iteration      946/    9375 | elapsed time per iteration (ms): 503.5 | learning rate 1.548E-05 | lm loss 5.713656E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.70 | backward: 352.80 | optimizer: 5.16 | batch generator: 1.25 | data loader: 0.53
10.0.2.18:  iteration      947/    9375 | elapsed time per iteration (ms): 489.3 | learning rate 1.550E-05 | lm loss 5.758747E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.51 | backward: 342.52 | optimizer: 5.22 | batch generator: 1.16 | data loader: 0.46
10.0.2.18:  iteration      948/    9375 | elapsed time per iteration (ms): 517.7 | learning rate 1.552E-05 | lm loss 5.650019E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.42 | backward: 373.23 | optimizer: 5.23 | batch generator: 1.18 | data loader: 0.50
10.0.2.18:  iteration      949/    9375 | elapsed time per iteration (ms): 581.2 | learning rate 1.553E-05 | lm loss 5.664987E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.34 | backward: 437.90 | optimizer: 5.20 | batch generator: 1.13 | data loader: 0.40
10.0.2.18:  iteration      950/    9375 | elapsed time per iteration (ms): 549.5 | learning rate 1.555E-05 | lm loss 5.684431E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.93 | backward: 398.18 | optimizer: 5.20 | batch generator: 1.15 | data loader: 0.41
10.0.2.18:  iteration      951/    9375 | elapsed time per iteration (ms): 546.1 | learning rate 1.557E-05 | lm loss 5.671322E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.96 | backward: 395.38 | optimizer: 5.19 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      952/    9375 | elapsed time per iteration (ms): 528.2 | learning rate 1.558E-05 | lm loss 5.714948E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.66 | backward: 373.94 | optimizer: 5.16 | batch generator: 1.17 | data loader: 0.48
10.0.2.18:  iteration      953/    9375 | elapsed time per iteration (ms): 542.2 | learning rate 1.560E-05 | lm loss 5.744163E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.06 | backward: 389.25 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.47
10.0.2.18:  iteration      954/    9375 | elapsed time per iteration (ms): 578.1 | learning rate 1.562E-05 | lm loss 5.695823E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.35 | backward: 424.03 | optimizer: 5.20 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      955/    9375 | elapsed time per iteration (ms): 527.4 | learning rate 1.563E-05 | lm loss 5.674356E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.94 | backward: 372.83 | optimizer: 5.20 | batch generator: 1.14 | data loader: 0.41
10.0.2.18:  iteration      956/    9375 | elapsed time per iteration (ms): 515.3 | learning rate 1.565E-05 | lm loss 5.710337E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.97 | backward: 361.24 | optimizer: 5.16 | batch generator: 1.26 | data loader: 0.47
10.0.2.18:  iteration      957/    9375 | elapsed time per iteration (ms): 584.5 | learning rate 1.567E-05 | lm loss 5.722796E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.09 | backward: 417.51 | optimizer: 5.23 | batch generator: 1.16 | data loader: 0.47
10.0.2.18:  iteration      958/    9375 | elapsed time per iteration (ms): 526.9 | learning rate 1.568E-05 | lm loss 5.693627E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.95 | backward: 372.55 | optimizer: 5.18 | batch generator: 1.31 | data loader: 0.58
10.0.2.18:  iteration      959/    9375 | elapsed time per iteration (ms): 532.1 | learning rate 1.570E-05 | lm loss 5.677079E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.80 | backward: 384.58 | optimizer: 5.18 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      960/    9375 | elapsed time per iteration (ms): 519.2 | learning rate 1.572E-05 | lm loss 5.638476E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.57 | backward: 369.30 | optimizer: 5.23 | batch generator: 1.16 | data loader: 0.42
10.0.2.18:  iteration      961/    9375 | elapsed time per iteration (ms): 530.5 | learning rate 1.573E-05 | lm loss 5.660712E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.65 | backward: 384.41 | optimizer: 5.21 | batch generator: 1.29 | data loader: 0.56
10.0.2.18:  iteration      962/    9375 | elapsed time per iteration (ms): 502.6 | learning rate 1.575E-05 | lm loss 5.650852E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.36 | backward: 365.51 | optimizer: 5.20 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      963/    9375 | elapsed time per iteration (ms): 550.7 | learning rate 1.577E-05 | lm loss 5.688628E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.62 | backward: 402.98 | optimizer: 5.20 | batch generator: 1.21 | data loader: 0.50
10.0.2.18:  iteration      964/    9375 | elapsed time per iteration (ms): 513.7 | learning rate 1.578E-05 | lm loss 5.629019E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.06 | backward: 359.25 | optimizer: 5.22 | batch generator: 1.19 | data loader: 0.50
10.0.2.18:  iteration      965/    9375 | elapsed time per iteration (ms): 505.1 | learning rate 1.580E-05 | lm loss 5.746914E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.60 | backward: 360.63 | optimizer: 5.17 | batch generator: 1.23 | data loader: 0.54
10.0.2.18:  iteration      966/    9375 | elapsed time per iteration (ms): 515.7 | learning rate 1.582E-05 | lm loss 5.662359E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.88 | backward: 353.61 | optimizer: 5.21 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      967/    9375 | elapsed time per iteration (ms): 565.3 | learning rate 1.583E-05 | lm loss 5.693946E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.84 | backward: 405.74 | optimizer: 5.17 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration      968/    9375 | elapsed time per iteration (ms): 554.2 | learning rate 1.585E-05 | lm loss 5.708674E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.04 | backward: 399.71 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.40
10.0.2.18:  iteration      969/    9375 | elapsed time per iteration (ms): 549.0 | learning rate 1.587E-05 | lm loss 5.654940E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.18 | backward: 395.46 | optimizer: 5.21 | batch generator: 1.15 | data loader: 0.40
10.0.2.18:  iteration      970/    9375 | elapsed time per iteration (ms): 554.7 | learning rate 1.588E-05 | lm loss 5.629885E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.97 | backward: 402.98 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.48
10.0.2.18:  iteration      971/    9375 | elapsed time per iteration (ms): 521.0 | learning rate 1.590E-05 | lm loss 5.688769E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.84 | backward: 368.82 | optimizer: 5.23 | batch generator: 1.16 | data loader: 0.48
10.0.2.18:  iteration      972/    9375 | elapsed time per iteration (ms): 548.5 | learning rate 1.592E-05 | lm loss 5.729674E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 143.55 | backward: 387.77 | optimizer: 5.19 | batch generator: 1.30 | data loader: 0.46
10.0.2.18:  iteration      973/    9375 | elapsed time per iteration (ms): 506.6 | learning rate 1.593E-05 | lm loss 5.676009E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.88 | backward: 357.59 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.39
10.0.2.18:  iteration      974/    9375 | elapsed time per iteration (ms): 495.0 | learning rate 1.595E-05 | lm loss 5.677903E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.10 | backward: 338.09 | optimizer: 5.21 | batch generator: 1.16 | data loader: 0.46
10.0.2.18:  iteration      975/    9375 | elapsed time per iteration (ms): 533.6 | learning rate 1.597E-05 | lm loss 5.644245E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.23 | backward: 364.73 | optimizer: 5.21 | batch generator: 1.12 | data loader: 0.38
10.0.2.18:  iteration      976/    9375 | elapsed time per iteration (ms): 503.6 | learning rate 1.598E-05 | lm loss 5.645972E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.28 | backward: 348.87 | optimizer: 5.23 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      977/    9375 | elapsed time per iteration (ms): 510.4 | learning rate 1.600E-05 | lm loss 5.634608E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.71 | backward: 349.89 | optimizer: 5.20 | batch generator: 1.23 | data loader: 0.51
10.0.2.18:  iteration      978/    9375 | elapsed time per iteration (ms): 482.4 | learning rate 1.602E-05 | lm loss 5.693207E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.70 | backward: 335.68 | optimizer: 5.23 | batch generator: 1.19 | data loader: 0.44
10.0.2.18:  iteration      979/    9375 | elapsed time per iteration (ms): 528.3 | learning rate 1.603E-05 | lm loss 5.693369E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.53 | backward: 357.30 | optimizer: 5.26 | batch generator: 1.23 | data loader: 0.51
10.0.2.18:  iteration      980/    9375 | elapsed time per iteration (ms): 537.3 | learning rate 1.605E-05 | lm loss 5.702072E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 127.69 | backward: 376.09 | optimizer: 5.26 | batch generator: 2.21 | data loader: 0.90
10.0.2.18:  iteration      981/    9375 | elapsed time per iteration (ms): 486.3 | learning rate 1.607E-05 | lm loss 5.675206E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 91.25 | backward: 340.14 | optimizer: 5.19 | batch generator: 1.32 | data loader: 0.59
10.0.2.18:  iteration      982/    9375 | elapsed time per iteration (ms): 508.5 | learning rate 1.608E-05 | lm loss 5.674167E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.38 | backward: 348.62 | optimizer: 5.19 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      983/    9375 | elapsed time per iteration (ms): 504.6 | learning rate 1.610E-05 | lm loss 5.680130E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.00 | backward: 349.65 | optimizer: 5.25 | batch generator: 1.11 | data loader: 0.39
10.0.2.18:  iteration      984/    9375 | elapsed time per iteration (ms): 531.3 | learning rate 1.612E-05 | lm loss 5.623521E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.57 | backward: 371.34 | optimizer: 5.19 | batch generator: 1.28 | data loader: 0.45
10.0.2.18:  iteration      985/    9375 | elapsed time per iteration (ms): 577.7 | learning rate 1.613E-05 | lm loss 5.673043E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.48 | backward: 423.72 | optimizer: 5.17 | batch generator: 1.12 | data loader: 0.38
10.0.2.18:  iteration      986/    9375 | elapsed time per iteration (ms): 580.1 | learning rate 1.615E-05 | lm loss 5.698656E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 123.35 | backward: 424.76 | optimizer: 5.19 | batch generator: 1.10 | data loader: 0.38
10.0.2.18:  iteration      987/    9375 | elapsed time per iteration (ms): 574.0 | learning rate 1.617E-05 | lm loss 5.673083E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.91 | backward: 404.87 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.47
10.0.2.18:  iteration      988/    9375 | elapsed time per iteration (ms): 527.9 | learning rate 1.618E-05 | lm loss 5.653414E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.95 | backward: 369.80 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.46
10.0.2.18:  iteration      989/    9375 | elapsed time per iteration (ms): 561.5 | learning rate 1.620E-05 | lm loss 5.693580E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.81 | backward: 399.41 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration      990/    9375 | elapsed time per iteration (ms): 516.9 | learning rate 1.622E-05 | lm loss 5.679962E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.66 | backward: 348.83 | optimizer: 5.19 | batch generator: 1.22 | data loader: 0.52
10.0.2.18:  iteration      991/    9375 | elapsed time per iteration (ms): 537.7 | learning rate 1.623E-05 | lm loss 5.667896E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.87 | backward: 377.29 | optimizer: 5.19 | batch generator: 1.10 | data loader: 0.38
10.0.2.18:  iteration      992/    9375 | elapsed time per iteration (ms): 515.6 | learning rate 1.625E-05 | lm loss 5.707198E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.43 | backward: 360.40 | optimizer: 5.20 | batch generator: 1.17 | data loader: 0.40
10.0.2.18:  iteration      993/    9375 | elapsed time per iteration (ms): 517.8 | learning rate 1.627E-05 | lm loss 5.667963E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.63 | backward: 359.43 | optimizer: 5.17 | batch generator: 1.21 | data loader: 0.51
10.0.2.18:  iteration      994/    9375 | elapsed time per iteration (ms): 524.3 | learning rate 1.628E-05 | lm loss 5.645539E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 86.61 | backward: 365.85 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      995/    9375 | elapsed time per iteration (ms): 595.2 | learning rate 1.630E-05 | lm loss 5.652884E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.32 | backward: 436.31 | optimizer: 5.21 | batch generator: 1.13 | data loader: 0.46
10.0.2.18:  iteration      996/    9375 | elapsed time per iteration (ms): 563.5 | learning rate 1.632E-05 | lm loss 5.638840E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.17 | backward: 410.08 | optimizer: 5.19 | batch generator: 1.25 | data loader: 0.46
10.0.2.18:  iteration      997/    9375 | elapsed time per iteration (ms): 560.4 | learning rate 1.633E-05 | lm loss 5.625296E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.59 | backward: 408.29 | optimizer: 5.18 | batch generator: 1.12 | data loader: 0.39
10.0.2.18:  iteration      998/    9375 | elapsed time per iteration (ms): 546.6 | learning rate 1.635E-05 | lm loss 5.673867E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 126.45 | backward: 391.61 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.49
10.0.2.18:  iteration      999/    9375 | elapsed time per iteration (ms): 548.7 | learning rate 1.637E-05 | lm loss 5.655247E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.26 | backward: 393.48 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.45
10.0.2.18:  iteration     1000/    9375 | elapsed time per iteration (ms): 539.8 | learning rate 1.638E-05 | lm loss 5.652378E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.55 | backward: 385.31 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.48
10.0.2.18: ----------------------------------------------------------------------------------------------------
10.0.2.18: ------------------------------------------------------------------------------------------------------------
10.0.2.18:  validation loss at iteration 1000 | LM loss: 5.648075E+00 | LM PPL: 2.837447E+02 | BERT loss: 5.648075E+00
10.0.2.18: ------------------------------------------------------------------------------------------------------------
10.0.2.18:  iteration     1001/    9375 | elapsed time per iteration (ms): 14499.6 | learning rate 1.640E-05 | lm loss 5.726662E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 131.34 | backward: 418.20 | optimizer: 5.20 | batch generator: 526.75 | data loader: 428.58
10.0.2.18:  iteration     1002/    9375 | elapsed time per iteration (ms): 506.7 | learning rate 1.642E-05 | lm loss 5.626323E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 125.56 | backward: 352.44 | optimizer: 5.20 | batch generator: 1.14 | data loader: 0.38
10.0.2.18:  iteration     1003/    9375 | elapsed time per iteration (ms): 531.7 | learning rate 1.643E-05 | lm loss 5.727354E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.13 | backward: 371.54 | optimizer: 5.23 | batch generator: 1.25 | data loader: 0.52
10.0.2.18:  iteration     1004/    9375 | elapsed time per iteration (ms): 510.5 | learning rate 1.645E-05 | lm loss 5.694461E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 88.91 | backward: 349.88 | optimizer: 5.19 | batch generator: 1.24 | data loader: 0.51
10.0.2.18:  iteration     1005/    9375 | elapsed time per iteration (ms): 536.2 | learning rate 1.647E-05 | lm loss 5.676534E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.19 | backward: 377.27 | optimizer: 5.20 | batch generator: 1.14 | data loader: 0.45
10.0.2.18:  iteration     1006/    9375 | elapsed time per iteration (ms): 519.1 | learning rate 1.648E-05 | lm loss 5.666128E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 129.39 | backward: 363.94 | optimizer: 5.24 | batch generator: 1.18 | data loader: 0.48
10.0.2.18:  iteration     1007/    9375 | elapsed time per iteration (ms): 533.2 | learning rate 1.650E-05 | lm loss 5.646711E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.40 | backward: 377.58 | optimizer: 5.18 | batch generator: 1.25 | data loader: 0.53
10.0.2.18:  iteration     1008/    9375 | elapsed time per iteration (ms): 535.3 | learning rate 1.652E-05 | lm loss 5.649112E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 140.98 | backward: 380.06 | optimizer: 5.16 | batch generator: 1.16 | data loader: 0.35
10.0.2.18:  iteration     1009/    9375 | elapsed time per iteration (ms): 524.5 | learning rate 1.653E-05 | lm loss 5.648921E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.48 | backward: 365.31 | optimizer: 5.19 | batch generator: 1.10 | data loader: 0.37
10.0.2.18:  iteration     1010/    9375 | elapsed time per iteration (ms): 536.6 | learning rate 1.655E-05 | lm loss 5.629846E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.47 | backward: 372.71 | optimizer: 5.18 | batch generator: 1.17 | data loader: 0.48
10.0.2.18:  iteration     1011/    9375 | elapsed time per iteration (ms): 497.5 | learning rate 1.657E-05 | lm loss 5.652058E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.33 | backward: 344.29 | optimizer: 5.22 | batch generator: 1.15 | data loader: 0.47
10.0.2.18:  iteration     1012/    9375 | elapsed time per iteration (ms): 508.0 | learning rate 1.658E-05 | lm loss 5.626637E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.56 | backward: 348.55 | optimizer: 5.18 | batch generator: 1.28 | data loader: 0.46
10.0.2.18:  iteration     1013/    9375 | elapsed time per iteration (ms): 522.6 | learning rate 1.660E-05 | lm loss 5.690144E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 89.36 | backward: 365.94 | optimizer: 5.20 | batch generator: 1.18 | data loader: 0.48
10.0.2.18:  iteration     1014/    9375 | elapsed time per iteration (ms): 529.3 | learning rate 1.662E-05 | lm loss 5.642645E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 90.79 | backward: 355.79 | optimizer: 5.19 | batch generator: 1.20 | data loader: 0.49
10.0.2.18:  iteration     1015/    9375 | elapsed time per iteration (ms): 518.9 | learning rate 1.663E-05 | lm loss 5.658276E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 128.26 | backward: 363.51 | optimizer: 5.19 | batch generator: 1.09 | data loader: 0.37
10.0.2.18:  iteration     1016/    9375 | elapsed time per iteration (ms): 513.5 | learning rate 1.665E-05 | lm loss 5.678878E+00 | loss scale 65536.0 |
10.0.2.18: time (ms) | forward: 87.05 | backward: 369.46 | optimizer: 5.21 | batch generator: 1.13 | data loader: 0.35
10.0.2.18:  iteration     1017/    9375 | elapsed time per iteration (ms): 525.5 | learning rate 1.667E-05 | lm loss 5.665318E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.89 | backward: 376.33 | optimizer: 5.21 | batch generator: 1.08 | data loader: 0.35
10.0.2.18:  iteration     1018/    9375 | elapsed time per iteration (ms): 482.5 | learning rate 1.668E-05 | lm loss 5.681392E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.42 | backward: 335.41 | optimizer: 5.21 | batch generator: 1.11 | data loader: 0.44
10.0.2.18:  iteration     1019/    9375 | elapsed time per iteration (ms): 520.9 | learning rate 1.670E-05 | lm loss 5.662083E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.26 | backward: 366.95 | optimizer: 5.21 | batch generator: 1.09 | data loader: 0.43
10.0.2.18:  iteration     1020/    9375 | elapsed time per iteration (ms): 506.0 | learning rate 1.672E-05 | lm loss 5.634439E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 128.29 | backward: 354.97 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.42
10.0.2.18:  iteration     1021/    9375 | elapsed time per iteration (ms): 527.9 | learning rate 1.673E-05 | lm loss 5.664094E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.13 | backward: 369.01 | optimizer: 5.18 | batch generator: 1.11 | data loader: 0.37
10.0.2.18:  iteration     1022/    9375 | elapsed time per iteration (ms): 516.5 | learning rate 1.675E-05 | lm loss 5.634037E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.16 | backward: 360.42 | optimizer: 5.18 | batch generator: 1.14 | data loader: 0.45
10.0.2.18:  iteration     1023/    9375 | elapsed time per iteration (ms): 514.9 | learning rate 1.677E-05 | lm loss 5.660142E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.45 | backward: 356.74 | optimizer: 5.18 | batch generator: 1.10 | data loader: 0.43
10.0.2.18:  iteration     1024/    9375 | elapsed time per iteration (ms): 528.7 | learning rate 1.678E-05 | lm loss 5.630933E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 90.27 | backward: 369.91 | optimizer: 5.15 | batch generator: 1.12 | data loader: 0.44
10.0.2.18:  iteration     1025/    9375 | elapsed time per iteration (ms): 516.3 | learning rate 1.680E-05 | lm loss 5.666376E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 88.89 | backward: 346.53 | optimizer: 5.20 | batch generator: 1.12 | data loader: 0.36
10.0.2.18:  iteration     1026/    9375 | elapsed time per iteration (ms): 517.0 | learning rate 1.682E-05 | lm loss 5.647177E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.48 | backward: 357.81 | optimizer: 5.19 | batch generator: 1.22 | data loader: 0.43
10.0.2.18:  iteration     1027/    9375 | elapsed time per iteration (ms): 521.3 | learning rate 1.683E-05 | lm loss 5.608481E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 90.00 | backward: 365.91 | optimizer: 5.17 | batch generator: 1.15 | data loader: 0.45
10.0.2.18:  iteration     1028/    9375 | elapsed time per iteration (ms): 513.7 | learning rate 1.685E-05 | lm loss 5.632827E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.47 | backward: 361.62 | optimizer: 5.19 | batch generator: 1.14 | data loader: 0.39
10.0.2.18:  iteration     1029/    9375 | elapsed time per iteration (ms): 532.0 | learning rate 1.687E-05 | lm loss 5.696007E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.28 | backward: 385.45 | optimizer: 5.22 | batch generator: 1.15 | data loader: 0.39
10.0.2.18:  iteration     1030/    9375 | elapsed time per iteration (ms): 523.9 | learning rate 1.688E-05 | lm loss 5.641587E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.00 | backward: 373.93 | optimizer: 5.18 | batch generator: 1.18 | data loader: 0.49
10.0.2.18:  iteration     1031/    9375 | elapsed time per iteration (ms): 544.5 | learning rate 1.690E-05 | lm loss 5.626934E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 91.14 | backward: 380.36 | optimizer: 5.20 | batch generator: 1.09 | data loader: 0.36
10.0.2.18:  iteration     1032/    9375 | elapsed time per iteration (ms): 582.2 | learning rate 1.692E-05 | lm loss 5.664256E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.36 | backward: 417.03 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.38
10.0.2.18:  iteration     1033/    9375 | elapsed time per iteration (ms): 510.0 | learning rate 1.693E-05 | lm loss 5.592611E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.48 | backward: 358.64 | optimizer: 5.18 | batch generator: 1.12 | data loader: 0.45
10.0.2.18:  iteration     1034/    9375 | elapsed time per iteration (ms): 512.3 | learning rate 1.695E-05 | lm loss 5.653074E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 88.87 | backward: 366.15 | optimizer: 5.20 | batch generator: 1.10 | data loader: 0.43
10.0.2.18:  iteration     1035/    9375 | elapsed time per iteration (ms): 548.8 | learning rate 1.697E-05 | lm loss 5.633727E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 125.92 | backward: 400.69 | optimizer: 5.19 | batch generator: 1.09 | data loader: 0.36
10.0.2.18:  iteration     1036/    9375 | elapsed time per iteration (ms): 529.6 | learning rate 1.698E-05 | lm loss 5.639802E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.39 | backward: 374.62 | optimizer: 5.18 | batch generator: 1.11 | data loader: 0.43
10.0.2.18:  iteration     1037/    9375 | elapsed time per iteration (ms): 527.5 | learning rate 1.700E-05 | lm loss 5.691641E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.26 | backward: 373.47 | optimizer: 5.23 | batch generator: 1.09 | data loader: 0.36
10.0.2.18:  iteration     1038/    9375 | elapsed time per iteration (ms): 529.0 | learning rate 1.702E-05 | lm loss 5.615540E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 126.01 | backward: 385.41 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.40
10.0.2.18:  iteration     1039/    9375 | elapsed time per iteration (ms): 573.0 | learning rate 1.703E-05 | lm loss 5.637734E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 88.69 | backward: 424.79 | optimizer: 5.19 | batch generator: 1.08 | data loader: 0.42
10.0.2.18:  iteration     1040/    9375 | elapsed time per iteration (ms): 588.8 | learning rate 1.705E-05 | lm loss 5.635653E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 90.85 | backward: 434.25 | optimizer: 5.19 | batch generator: 1.19 | data loader: 0.48
10.0.2.18:  iteration     1041/    9375 | elapsed time per iteration (ms): 570.6 | learning rate 1.707E-05 | lm loss 5.628895E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 126.02 | backward: 419.43 | optimizer: 5.19 | batch generator: 1.17 | data loader: 0.40
10.0.2.18:  iteration     1042/    9375 | elapsed time per iteration (ms): 563.5 | learning rate 1.708E-05 | lm loss 5.650515E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 127.80 | backward: 412.42 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.44
10.0.2.18:  iteration     1043/    9375 | elapsed time per iteration (ms): 520.2 | learning rate 1.710E-05 | lm loss 5.656822E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 126.08 | backward: 369.40 | optimizer: 5.20 | batch generator: 1.09 | data loader: 0.43
10.0.2.18:  iteration     1044/    9375 | elapsed time per iteration (ms): 537.3 | learning rate 1.712E-05 | lm loss 5.588185E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 90.60 | backward: 387.39 | optimizer: 5.18 | batch generator: 1.10 | data loader: 0.43
10.0.2.18:  iteration     1045/    9375 | elapsed time per iteration (ms): 527.2 | learning rate 1.713E-05 | lm loss 5.643806E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.31 | backward: 378.94 | optimizer: 5.18 | batch generator: 1.13 | data loader: 0.44
10.0.2.18:  iteration     1046/    9375 | elapsed time per iteration (ms): 519.5 | learning rate 1.715E-05 | lm loss 5.662527E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 88.88 | backward: 365.09 | optimizer: 5.19 | batch generator: 1.11 | data loader: 0.43
10.0.2.18:  iteration     1047/    9375 | elapsed time per iteration (ms): 539.7 | learning rate 1.717E-05 | lm loss 5.656878E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 88.95 | backward: 395.22 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.50
10.0.2.18:  iteration     1048/    9375 | elapsed time per iteration (ms): 507.1 | learning rate 1.718E-05 | lm loss 5.667428E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.96 | backward: 355.99 | optimizer: 5.21 | batch generator: 1.15 | data loader: 0.39
10.0.2.18:  iteration     1049/    9375 | elapsed time per iteration (ms): 555.9 | learning rate 1.720E-05 | lm loss 5.666023E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 128.34 | backward: 395.41 | optimizer: 5.18 | batch generator: 1.19 | data loader: 0.39
10.0.2.18:  iteration     1050/    9375 | elapsed time per iteration (ms): 494.9 | learning rate 1.722E-05 | lm loss 5.649209E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.19 | backward: 341.27 | optimizer: 5.21 | batch generator: 1.10 | data loader: 0.36
10.0.2.18:  iteration     1051/    9375 | elapsed time per iteration (ms): 535.4 | learning rate 1.723E-05 | lm loss 5.650738E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.05 | backward: 376.05 | optimizer: 5.19 | batch generator: 1.12 | data loader: 0.44
10.0.2.18:  iteration     1052/    9375 | elapsed time per iteration (ms): 487.0 | learning rate 1.725E-05 | lm loss 5.638360E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 88.24 | backward: 341.90 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.39
10.0.2.18:  iteration     1053/    9375 | elapsed time per iteration (ms): 545.1 | learning rate 1.727E-05 | lm loss 5.650389E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.23 | backward: 385.80 | optimizer: 5.17 | batch generator: 1.11 | data loader: 0.36
10.0.2.18:  iteration     1054/    9375 | elapsed time per iteration (ms): 535.1 | learning rate 1.728E-05 | lm loss 5.645760E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.97 | backward: 371.40 | optimizer: 5.17 | batch generator: 1.11 | data loader: 0.43
10.0.2.18:  iteration     1055/    9375 | elapsed time per iteration (ms): 554.1 | learning rate 1.730E-05 | lm loss 5.603381E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.08 | backward: 398.70 | optimizer: 5.20 | batch generator: 1.11 | data loader: 0.43
10.0.2.18:  iteration     1056/    9375 | elapsed time per iteration (ms): 571.4 | learning rate 1.732E-05 | lm loss 5.645770E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 128.07 | backward: 414.13 | optimizer: 5.26 | batch generator: 1.12 | data loader: 0.44
10.0.2.18:  iteration     1057/    9375 | elapsed time per iteration (ms): 574.8 | learning rate 1.733E-05 | lm loss 5.616781E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 128.49 | backward: 406.14 | optimizer: 5.20 | batch generator: 1.34 | data loader: 0.47
10.0.2.18:  iteration     1058/    9375 | elapsed time per iteration (ms): 557.7 | learning rate 1.735E-05 | lm loss 5.675859E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 126.15 | backward: 407.39 | optimizer: 5.17 | batch generator: 1.18 | data loader: 0.48
10.0.2.18:  iteration     1059/    9375 | elapsed time per iteration (ms): 575.9 | learning rate 1.737E-05 | lm loss 5.601868E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.53 | backward: 422.32 | optimizer: 5.17 | batch generator: 1.12 | data loader: 0.44
10.0.2.18:  iteration     1060/    9375 | elapsed time per iteration (ms): 585.2 | learning rate 1.738E-05 | lm loss 5.641892E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 125.34 | backward: 430.39 | optimizer: 5.21 | batch generator: 1.09 | data loader: 0.36
10.0.2.18:  iteration     1061/    9375 | elapsed time per iteration (ms): 529.9 | learning rate 1.740E-05 | lm loss 5.657746E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 90.09 | backward: 376.21 | optimizer: 5.16 | batch generator: 1.15 | data loader: 0.40
10.0.2.18:  iteration     1062/    9375 | elapsed time per iteration (ms): 533.5 | learning rate 1.742E-05 | lm loss 5.660419E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 88.89 | backward: 371.67 | optimizer: 5.19 | batch generator: 1.11 | data loader: 0.43
10.0.2.18:  iteration     1063/    9375 | elapsed time per iteration (ms): 523.1 | learning rate 1.743E-05 | lm loss 5.644154E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 126.24 | backward: 362.03 | optimizer: 5.17 | batch generator: 1.11 | data loader: 0.36
10.0.2.18:  iteration     1064/    9375 | elapsed time per iteration (ms): 557.3 | learning rate 1.745E-05 | lm loss 5.636559E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 86.75 | backward: 391.24 | optimizer: 5.18 | batch generator: 1.06 | data loader: 0.35
10.0.2.18:  iteration     1065/    9375 | elapsed time per iteration (ms): 539.2 | learning rate 1.747E-05 | lm loss 5.650054E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.47 | backward: 363.28 | optimizer: 5.19 | batch generator: 1.08 | data loader: 0.36
10.0.2.18:  iteration     1066/    9375 | elapsed time per iteration (ms): 527.6 | learning rate 1.748E-05 | lm loss 5.644429E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.28 | backward: 364.69 | optimizer: 5.15 | batch generator: 1.23 | data loader: 0.47
10.0.2.18:  iteration     1067/    9375 | elapsed time per iteration (ms): 501.5 | learning rate 1.750E-05 | lm loss 5.627742E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 90.86 | backward: 345.07 | optimizer: 5.18 | batch generator: 1.11 | data loader: 0.43
10.0.2.18:  iteration     1068/    9375 | elapsed time per iteration (ms): 519.7 | learning rate 1.752E-05 | lm loss 5.612917E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 127.94 | backward: 362.87 | optimizer: 5.19 | batch generator: 1.10 | data loader: 0.43
10.0.2.18:  iteration     1069/    9375 | elapsed time per iteration (ms): 505.1 | learning rate 1.753E-05 | lm loss 5.620791E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 125.46 | backward: 345.93 | optimizer: 5.22 | batch generator: 1.09 | data loader: 0.36
10.0.2.18:  iteration     1070/    9375 | elapsed time per iteration (ms): 526.7 | learning rate 1.755E-05 | lm loss 5.657053E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.24 | backward: 366.30 | optimizer: 5.19 | batch generator: 1.20 | data loader: 0.41
10.0.2.18:  iteration     1071/    9375 | elapsed time per iteration (ms): 529.8 | learning rate 1.757E-05 | lm loss 5.568910E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.78 | backward: 376.52 | optimizer: 5.19 | batch generator: 1.09 | data loader: 0.36
10.0.2.18:  iteration     1072/    9375 | elapsed time per iteration (ms): 499.8 | learning rate 1.758E-05 | lm loss 5.650948E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 123.44 | backward: 344.83 | optimizer: 5.18 | batch generator: 1.15 | data loader: 0.38
10.0.2.18:  iteration     1073/    9375 | elapsed time per iteration (ms): 503.9 | learning rate 1.760E-05 | lm loss 5.626442E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.25 | backward: 342.40 | optimizer: 5.23 | batch generator: 1.11 | data loader: 0.43
10.0.2.18:  iteration     1074/    9375 | elapsed time per iteration (ms): 529.1 | learning rate 1.762E-05 | lm loss 5.635063E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.83 | backward: 371.68 | optimizer: 5.17 | batch generator: 1.26 | data loader: 0.52
10.0.2.18:  iteration     1075/    9375 | elapsed time per iteration (ms): 546.8 | learning rate 1.763E-05 | lm loss 5.703180E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.24 | backward: 392.19 | optimizer: 5.18 | batch generator: 1.08 | data loader: 0.35
10.0.2.18:  iteration     1076/    9375 | elapsed time per iteration (ms): 540.3 | learning rate 1.765E-05 | lm loss 5.646931E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 125.52 | backward: 386.29 | optimizer: 5.17 | batch generator: 1.10 | data loader: 0.36
10.0.2.18:  iteration     1077/    9375 | elapsed time per iteration (ms): 660.9 | learning rate 1.767E-05 | lm loss 5.616276E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 128.55 | backward: 384.43 | optimizer: 5.19 | batch generator: 1.10 | data loader: 0.36
10.0.2.18:  iteration     1078/    9375 | elapsed time per iteration (ms): 544.0 | learning rate 1.768E-05 | lm loss 5.611061E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.66 | backward: 392.69 | optimizer: 5.21 | batch generator: 1.14 | data loader: 0.46
10.0.2.18:  iteration     1079/    9375 | elapsed time per iteration (ms): 542.4 | learning rate 1.770E-05 | lm loss 5.623601E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 90.72 | backward: 394.31 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.41
10.0.2.18:  iteration     1080/    9375 | elapsed time per iteration (ms): 571.9 | learning rate 1.772E-05 | lm loss 5.619745E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 90.18 | backward: 417.87 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.39
10.0.2.18:  iteration     1081/    9375 | elapsed time per iteration (ms): 524.9 | learning rate 1.773E-05 | lm loss 5.599020E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.59 | backward: 367.86 | optimizer: 5.19 | batch generator: 1.15 | data loader: 0.39
10.0.2.18:  iteration     1082/    9375 | elapsed time per iteration (ms): 576.3 | learning rate 1.775E-05 | lm loss 5.602462E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 125.85 | backward: 425.49 | optimizer: 5.18 | batch generator: 1.16 | data loader: 0.39
10.0.2.18:  iteration     1083/    9375 | elapsed time per iteration (ms): 497.1 | learning rate 1.777E-05 | lm loss 5.627211E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 125.99 | backward: 342.11 | optimizer: 5.16 | batch generator: 1.11 | data loader: 0.43
10.0.2.18:  iteration     1084/    9375 | elapsed time per iteration (ms): 497.0 | learning rate 1.778E-05 | lm loss 5.595583E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 89.64 | backward: 337.78 | optimizer: 5.22 | batch generator: 1.11 | data loader: 0.44
10.0.2.18:  iteration     1085/    9375 | elapsed time per iteration (ms): 517.9 | learning rate 1.780E-05 | lm loss 5.621048E+00 | loss scale 131072.0 |
10.0.2.18: time (ms) | forward: 90.39 | backward: 358.46 | optimizer: 5.20 | batch generator: 1.10 | data loader: 0.43
10.0.2.18:  